ansible-playbook 2.10.2
  config file = None
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.6/dist-packages/ansible
  executable location = /usr/local/bin/ansible-playbook
  python version = 3.6.9 (default, Oct  8 2020, 12:12:24) [GCC 8.4.0]
No config file found; using defaults
host_list declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
script declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
auto declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
Parsed /etc/ansible/hosts inventory source with ini plugin

PLAYBOOK: site.yaml ************************************************************
16 plays in platforms/shared/configuration/site.yaml

PLAY [all] *********************************************************************
META: ran handlers
META: ran handlers
META: ran handlers

PLAY [ansible_provisioners] ****************************************************

TASK [Gathering Facts] *********************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:7
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682758.929462-15602-166467848534250 `" && echo ansible-tmp-1604682758.929462-15602-166467848534250="` echo /root/.ansible/tmp/ansible-tmp-1604682758.929462-15602-166467848534250 `" ) && sleep 0'
<localhost> Attempting python interpreter discovery
<localhost> EXEC /bin/sh -c 'echo PLATFORM; uname; echo FOUND; command -v '"'"'/usr/bin/python'"'"'; command -v '"'"'python3.7'"'"'; command -v '"'"'python3.6'"'"'; command -v '"'"'python3.5'"'"'; command -v '"'"'python2.7'"'"'; command -v '"'"'python2.6'"'"'; command -v '"'"'/usr/libexec/platform-python'"'"'; command -v '"'"'/usr/bin/python3'"'"'; command -v '"'"'python'"'"'; echo ENDFOUND && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3.6 && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/setup.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp8mojs6ot TO /root/.ansible/tmp/ansible-tmp-1604682758.929462-15602-166467848534250/AnsiballZ_setup.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682758.929462-15602-166467848534250/ /root/.ansible/tmp/ansible-tmp-1604682758.929462-15602-166467848534250/AnsiballZ_setup.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682758.929462-15602-166467848534250/AnsiballZ_setup.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682758.929462-15602-166467848534250/ > /dev/null 2>&1 && sleep 0'
ok: [localhost]
META: ran handlers

TASK [include_role : setup/kubectl] ********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:10

TASK [setup/kubectl : register temporary directory] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682759.8533363-15654-260688779346471 `" && echo ansible-tmp-1604682759.8533363-15654-260688779346471="` echo /root/.ansible/tmp/ansible-tmp-1604682759.8533363-15654-260688779346471 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpb_1snqxb TO /root/.ansible/tmp/ansible-tmp-1604682759.8533363-15654-260688779346471/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682759.8533363-15654-260688779346471/ /root/.ansible/tmp/ansible-tmp-1604682759.8533363-15654-260688779346471/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682759.8533363-15654-260688779346471/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682759.8533363-15654-260688779346471/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.s3a4tekg",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/kubectl : check kubectl] *******************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682760.1726155-15680-12967626018383 `" && echo ansible-tmp-1604682760.1726155-15680-12967626018383="` echo /root/.ansible/tmp/ansible-tmp-1604682760.1726155-15680-12967626018383 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp99_9tkoj TO /root/.ansible/tmp/ansible-tmp-1604682760.1726155-15680-12967626018383/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682760.1726155-15680-12967626018383/ /root/.ansible/tmp/ansible-tmp-1604682760.1726155-15680-12967626018383/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682760.1726155-15680-12967626018383/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682760.1726155-15680-12967626018383/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/kubectl"
        }
    },
    "stat": {
        "atime": 1603618462.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 83992,
        "charset": "binary",
        "checksum": "fe0bcf142cabb39a09ab46440d797bd85d7fa838",
        "ctime": 1604239658.6170657,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126502,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618462.0,
        "nlink": 1,
        "path": "/root/bin/kubectl",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 43003904,
        "uid": 0,
        "version": "1156023499",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/kubectl : Download kubectl binary] *********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : Unarchive kubernetes-client] *****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : create bin directory] ************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:33
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : Copy kubectl binary to destination directory] ************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:41
skipping: [localhost] => (item=kubectl)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "kubectl",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : Test kubectl installation] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:55
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682760.6614451-15716-131792888627460 `" && echo ansible-tmp-1604682760.6614451-15716-131792888627460="` echo /root/.ansible/tmp/ansible-tmp-1604682760.6614451-15716-131792888627460 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmperku5ieq TO /root/.ansible/tmp/ansible-tmp-1604682760.6614451-15716-131792888627460/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682760.6614451-15716-131792888627460/ /root/.ansible/tmp/ansible-tmp-1604682760.6614451-15716-131792888627460/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682760.6614451-15716-131792888627460/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682760.6614451-15716-131792888627460/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "kubectl",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.048970",
    "end": "2020-11-06 17:12:40.983835",
    "invocation": {
        "module_args": {
            "_raw_params": "kubectl version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:12:40.934865",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client Version: v1.19.0",
    "stdout_lines": [
        "Client Version: v1.19.0"
    ]
}

TASK [setup/kubectl : register temporary directory] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682761.0283766-15747-55301591943925 `" && echo ansible-tmp-1604682761.0283766-15747-55301591943925="` echo /root/.ansible/tmp/ansible-tmp-1604682761.0283766-15747-55301591943925 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpafqlt6xq TO /root/.ansible/tmp/ansible-tmp-1604682761.0283766-15747-55301591943925/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682761.0283766-15747-55301591943925/ /root/.ansible/tmp/ansible-tmp-1604682761.0283766-15747-55301591943925/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682761.0283766-15747-55301591943925/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682761.0283766-15747-55301591943925/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.s5fcyp99",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/kubectl : check kubectl] *******************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682761.2039695-15773-89325679162212 `" && echo ansible-tmp-1604682761.2039695-15773-89325679162212="` echo /root/.ansible/tmp/ansible-tmp-1604682761.2039695-15773-89325679162212 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpff53c89q TO /root/.ansible/tmp/ansible-tmp-1604682761.2039695-15773-89325679162212/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682761.2039695-15773-89325679162212/ /root/.ansible/tmp/ansible-tmp-1604682761.2039695-15773-89325679162212/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682761.2039695-15773-89325679162212/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682761.2039695-15773-89325679162212/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/kubectl"
        }
    },
    "stat": {
        "atime": 1603618462.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 83992,
        "charset": "binary",
        "checksum": "fe0bcf142cabb39a09ab46440d797bd85d7fa838",
        "ctime": 1604239658.6170657,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126502,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618462.0,
        "nlink": 1,
        "path": "/root/bin/kubectl",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 43003904,
        "uid": 0,
        "version": "1156023499",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/kubectl : Download kubectl binary] *********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : Unarchive kubernetes-client] *****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : create bin directory] ************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:33
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : Copy kubectl binary to destination directory] ************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:41
skipping: [localhost] => (item=kubectl)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "kubectl",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : Test kubectl installation] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:55
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682761.5848932-15809-272237711802579 `" && echo ansible-tmp-1604682761.5848932-15809-272237711802579="` echo /root/.ansible/tmp/ansible-tmp-1604682761.5848932-15809-272237711802579 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpye6ustlf TO /root/.ansible/tmp/ansible-tmp-1604682761.5848932-15809-272237711802579/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682761.5848932-15809-272237711802579/ /root/.ansible/tmp/ansible-tmp-1604682761.5848932-15809-272237711802579/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682761.5848932-15809-272237711802579/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682761.5848932-15809-272237711802579/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "kubectl",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.049410",
    "end": "2020-11-06 17:12:41.763438",
    "invocation": {
        "module_args": {
            "_raw_params": "kubectl version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:12:41.714028",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client Version: v1.19.0",
    "stdout_lines": [
        "Client Version: v1.19.0"
    ]
}

TASK [include_role : setup/helm] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:20

TASK [setup/helm : register temporary directory] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682761.8904536-15843-110534434665744 `" && echo ansible-tmp-1604682761.8904536-15843-110534434665744="` echo /root/.ansible/tmp/ansible-tmp-1604682761.8904536-15843-110534434665744 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpk2essjn1 TO /root/.ansible/tmp/ansible-tmp-1604682761.8904536-15843-110534434665744/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682761.8904536-15843-110534434665744/ /root/.ansible/tmp/ansible-tmp-1604682761.8904536-15843-110534434665744/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682761.8904536-15843-110534434665744/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682761.8904536-15843-110534434665744/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.8xe3_wf3",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/helm : check helm] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682762.0777855-15869-264240285653549 `" && echo ansible-tmp-1604682762.0777855-15869-264240285653549="` echo /root/.ansible/tmp/ansible-tmp-1604682762.0777855-15869-264240285653549 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp6goehidt TO /root/.ansible/tmp/ansible-tmp-1604682762.0777855-15869-264240285653549/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682762.0777855-15869-264240285653549/ /root/.ansible/tmp/ansible-tmp-1604682762.0777855-15869-264240285653549/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682762.0777855-15869-264240285653549/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682762.0777855-15869-264240285653549/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/helm"
        }
    },
    "stat": {
        "atime": 1603618464.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 78000,
        "charset": "binary",
        "checksum": "5820860e398793a3b0b54449e9b6f9a4a0f35cb9",
        "ctime": 1604239659.0090716,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126511,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618464.0,
        "nlink": 1,
        "path": "/root/bin/helm",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 39936000,
        "uid": 0,
        "version": "2759632516",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/helm : Install helm] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Unzip helm archive] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:37
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Move helm binaries] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:47
skipping: [localhost] => (item=helm)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "helm",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Test helm installation] *************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:58
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682762.4111912-15905-61482563770799 `" && echo ansible-tmp-1604682762.4111912-15905-61482563770799="` echo /root/.ansible/tmp/ansible-tmp-1604682762.4111912-15905-61482563770799 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp1n974lvt TO /root/.ansible/tmp/ansible-tmp-1604682762.4111912-15905-61482563770799/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682762.4111912-15905-61482563770799/ /root/.ansible/tmp/ansible-tmp-1604682762.4111912-15905-61482563770799/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682762.4111912-15905-61482563770799/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682762.4111912-15905-61482563770799/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "helm",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.056003",
    "end": "2020-11-06 17:12:42.596580",
    "invocation": {
        "module_args": {
            "_raw_params": "helm version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:12:42.540577",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client: v2.16.12+g47f0b88",
    "stdout_lines": [
        "Client: v2.16.12+g47f0b88"
    ]
}

TASK [setup/helm : register temporary directory] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682762.6413934-15936-238519700455237 `" && echo ansible-tmp-1604682762.6413934-15936-238519700455237="` echo /root/.ansible/tmp/ansible-tmp-1604682762.6413934-15936-238519700455237 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpleqb6mcc TO /root/.ansible/tmp/ansible-tmp-1604682762.6413934-15936-238519700455237/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682762.6413934-15936-238519700455237/ /root/.ansible/tmp/ansible-tmp-1604682762.6413934-15936-238519700455237/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682762.6413934-15936-238519700455237/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682762.6413934-15936-238519700455237/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.0nyhs9d3",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/helm : check helm] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682762.817433-15962-96982725301921 `" && echo ansible-tmp-1604682762.817433-15962-96982725301921="` echo /root/.ansible/tmp/ansible-tmp-1604682762.817433-15962-96982725301921 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmps5a3pqnn TO /root/.ansible/tmp/ansible-tmp-1604682762.817433-15962-96982725301921/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682762.817433-15962-96982725301921/ /root/.ansible/tmp/ansible-tmp-1604682762.817433-15962-96982725301921/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682762.817433-15962-96982725301921/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682762.817433-15962-96982725301921/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/helm"
        }
    },
    "stat": {
        "atime": 1603618464.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 78000,
        "charset": "binary",
        "checksum": "5820860e398793a3b0b54449e9b6f9a4a0f35cb9",
        "ctime": 1604239659.0090716,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126511,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618464.0,
        "nlink": 1,
        "path": "/root/bin/helm",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 39936000,
        "uid": 0,
        "version": "2759632516",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/helm : Install helm] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Unzip helm archive] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:37
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Move helm binaries] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:47
skipping: [localhost] => (item=helm)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "helm",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Test helm installation] *************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:58
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682763.1504517-15998-66506372819439 `" && echo ansible-tmp-1604682763.1504517-15998-66506372819439="` echo /root/.ansible/tmp/ansible-tmp-1604682763.1504517-15998-66506372819439 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp7zff0s17 TO /root/.ansible/tmp/ansible-tmp-1604682763.1504517-15998-66506372819439/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682763.1504517-15998-66506372819439/ /root/.ansible/tmp/ansible-tmp-1604682763.1504517-15998-66506372819439/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682763.1504517-15998-66506372819439/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682763.1504517-15998-66506372819439/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "helm",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.051278",
    "end": "2020-11-06 17:12:43.330510",
    "invocation": {
        "module_args": {
            "_raw_params": "helm version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:12:43.279232",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client: v2.16.12+g47f0b88",
    "stdout_lines": [
        "Client: v2.16.12+g47f0b88"
    ]
}

TASK [include_role : setup/vault] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:30

TASK [setup/vault : register temporary directory] ******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/vault/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682763.4303-16031-257055577144907 `" && echo ansible-tmp-1604682763.4303-16031-257055577144907="` echo /root/.ansible/tmp/ansible-tmp-1604682763.4303-16031-257055577144907 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp_rp2ymtr TO /root/.ansible/tmp/ansible-tmp-1604682763.4303-16031-257055577144907/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682763.4303-16031-257055577144907/ /root/.ansible/tmp/ansible-tmp-1604682763.4303-16031-257055577144907/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682763.4303-16031-257055577144907/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682763.4303-16031-257055577144907/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.gqvwdon6",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/vault : check vault] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/vault/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682763.6084306-16057-43232499398290 `" && echo ansible-tmp-1604682763.6084306-16057-43232499398290="` echo /root/.ansible/tmp/ansible-tmp-1604682763.6084306-16057-43232499398290 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpe4zpppnm TO /root/.ansible/tmp/ansible-tmp-1604682763.6084306-16057-43232499398290/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682763.6084306-16057-43232499398290/ /root/.ansible/tmp/ansible-tmp-1604682763.6084306-16057-43232499398290/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682763.6084306-16057-43232499398290/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682763.6084306-16057-43232499398290/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/vault"
        }
    },
    "stat": {
        "atime": 1603618466.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 270632,
        "charset": "binary",
        "checksum": "b1cacaa735c4406d1f47a6937e9329a38a842ede",
        "ctime": 1604239660.105088,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126520,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618466.0,
        "nlink": 1,
        "path": "/root/bin/vault",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 138561023,
        "uid": 0,
        "version": "2790310722",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/vault : Install vault client] **************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/vault/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/vault : create bin directory] **************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/vault/tasks/main.yaml:26
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/vault : Unzip vault archive] ***************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/vault/tasks/main.yaml:34
skipping: [localhost] => (item=vault)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "vault",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/vault : Test vault installation] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/vault/tasks/main.yaml:46
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682764.0607877-16091-277779078761350 `" && echo ansible-tmp-1604682764.0607877-16091-277779078761350="` echo /root/.ansible/tmp/ansible-tmp-1604682764.0607877-16091-277779078761350 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp3ice_myk TO /root/.ansible/tmp/ansible-tmp-1604682764.0607877-16091-277779078761350/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682764.0607877-16091-277779078761350/ /root/.ansible/tmp/ansible-tmp-1604682764.0607877-16091-277779078761350/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682764.0607877-16091-277779078761350/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682764.0607877-16091-277779078761350/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "vault",
        "version"
    ],
    "delta": "0:00:00.030139",
    "end": "2020-11-06 17:12:44.220967",
    "invocation": {
        "module_args": {
            "_raw_params": "vault version",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:12:44.190828",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Vault v1.5.5 (f5d1ddb3750e7c28e25036e1ef26a4c02379fc01)",
    "stdout_lines": [
        "Vault v1.5.5 (f5d1ddb3750e7c28e25036e1ef26a4c02379fc01)"
    ]
}

TASK [include_role : setup/aws-cli] ********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:40
skipping: [localhost] => (item={'organization': None, 'name': 'supplychain', 'country': 'UK', 'state': 'London', 'location': 'London', 'subject': 'O=Orderer,L=51.50/-0.13/London,C=GB', 'type': 'orderer', 'external_url_suffix': 'supplychain-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.supplychain-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'gorilla', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'consensus': {'name': 'raft', 'type': 'broker', 'replicas': 4, 'grpc': {'port': 9092}}, 'orderers': [{'orderer': None, 'name': 'orderer3', 'type': 'orderer', 'consensus': 'raft', 'grpc': {'port': 7050}}]}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.supplychain-net:7054"
        },
        "cloud_provider": "azure",
        "country": "UK",
        "external_url_suffix": "supplychain-net.svc.cluster.local",
        "gitops": {
            "branch": "gorilla",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "supplychain",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net",
                "type": "ca"
            },
            "consensus": {
                "grpc": {
                    "port": 9092
                },
                "name": "raft",
                "replicas": 4,
                "type": "broker"
            },
            "orderers": [
                {
                    "consensus": "raft",
                    "grpc": {
                        "port": 7050
                    },
                    "name": "orderer3",
                    "orderer": null,
                    "type": "orderer"
                }
            ]
        },
        "state": "London",
        "subject": "O=Orderer,L=51.50/-0.13/London,C=GB",
        "type": "orderer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'organization': None, 'name': 'carrier', 'country': 'GB', 'state': 'London', 'location': 'London', 'subject': 'O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB', 'type': 'peer', 'external_url_suffix': 'carrier-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.carrier-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'gorilla', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'peers': [{'peer': None, 'name': 'peer0', 'type': 'anchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer0.carrier-net.svc.cluster.local:7051', 'cli': 'enabled', 'grpc': {'port': 7051}, 'events': {'port': 7053}, 'couchdb': {'port': 5984}, 'restserver': {'targetPort': 20001, 'port': 20001}, 'expressapi': {'targetPort': 3000, 'port': 3000}}, {'peer': None, 'name': 'peer1', 'type': 'nonanchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer1.carrier-net.svc.cluster.local:7061', 'cli': 'enabled', 'grpc': {'port': 7061}, 'events': {'port': 7063}, 'couchdb': {'port': 5994}, 'restserver': {'targetPort': 20011, 'port': 20011}, 'expressapi': {'targetPort': 3010, 'port': 3010}}]}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.carrier-net:7054"
        },
        "cloud_provider": "azure",
        "country": "GB",
        "external_url_suffix": "carrier-net.svc.cluster.local",
        "gitops": {
            "branch": "gorilla",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "carrier",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net",
                "type": "ca"
            },
            "peers": [
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5984
                    },
                    "events": {
                        "port": 7053
                    },
                    "expressapi": {
                        "port": 3000,
                        "targetPort": 3000
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7051
                    },
                    "name": "peer0",
                    "peer": null,
                    "peerAddress": "peer0.carrier-net.svc.cluster.local:7051",
                    "restserver": {
                        "port": 20001,
                        "targetPort": 20001
                    },
                    "type": "anchor"
                },
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5994
                    },
                    "events": {
                        "port": 7063
                    },
                    "expressapi": {
                        "port": 3010,
                        "targetPort": 3010
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7061
                    },
                    "name": "peer1",
                    "peer": null,
                    "peerAddress": "peer1.carrier-net.svc.cluster.local:7061",
                    "restserver": {
                        "port": 20011,
                        "targetPort": 20011
                    },
                    "type": "nonanchor"
                }
            ]
        },
        "state": "London",
        "subject": "O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB",
        "type": "peer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [include_role : setup/aws-auth] *******************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:49
skipping: [localhost] => (item={'organization': None, 'name': 'supplychain', 'country': 'UK', 'state': 'London', 'location': 'London', 'subject': 'O=Orderer,L=51.50/-0.13/London,C=GB', 'type': 'orderer', 'external_url_suffix': 'supplychain-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.supplychain-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'gorilla', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'consensus': {'name': 'raft', 'type': 'broker', 'replicas': 4, 'grpc': {'port': 9092}}, 'orderers': [{'orderer': None, 'name': 'orderer3', 'type': 'orderer', 'consensus': 'raft', 'grpc': {'port': 7050}}]}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.supplychain-net:7054"
        },
        "cloud_provider": "azure",
        "country": "UK",
        "external_url_suffix": "supplychain-net.svc.cluster.local",
        "gitops": {
            "branch": "gorilla",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "supplychain",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net",
                "type": "ca"
            },
            "consensus": {
                "grpc": {
                    "port": 9092
                },
                "name": "raft",
                "replicas": 4,
                "type": "broker"
            },
            "orderers": [
                {
                    "consensus": "raft",
                    "grpc": {
                        "port": 7050
                    },
                    "name": "orderer3",
                    "orderer": null,
                    "type": "orderer"
                }
            ]
        },
        "state": "London",
        "subject": "O=Orderer,L=51.50/-0.13/London,C=GB",
        "type": "orderer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'organization': None, 'name': 'carrier', 'country': 'GB', 'state': 'London', 'location': 'London', 'subject': 'O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB', 'type': 'peer', 'external_url_suffix': 'carrier-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.carrier-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'gorilla', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'peers': [{'peer': None, 'name': 'peer0', 'type': 'anchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer0.carrier-net.svc.cluster.local:7051', 'cli': 'enabled', 'grpc': {'port': 7051}, 'events': {'port': 7053}, 'couchdb': {'port': 5984}, 'restserver': {'targetPort': 20001, 'port': 20001}, 'expressapi': {'targetPort': 3000, 'port': 3000}}, {'peer': None, 'name': 'peer1', 'type': 'nonanchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer1.carrier-net.svc.cluster.local:7061', 'cli': 'enabled', 'grpc': {'port': 7061}, 'events': {'port': 7063}, 'couchdb': {'port': 5994}, 'restserver': {'targetPort': 20011, 'port': 20011}, 'expressapi': {'targetPort': 3010, 'port': 3010}}]}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.carrier-net:7054"
        },
        "cloud_provider": "azure",
        "country": "GB",
        "external_url_suffix": "carrier-net.svc.cluster.local",
        "gitops": {
            "branch": "gorilla",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "carrier",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net",
                "type": "ca"
            },
            "peers": [
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5984
                    },
                    "events": {
                        "port": 7053
                    },
                    "expressapi": {
                        "port": 3000,
                        "targetPort": 3000
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7051
                    },
                    "name": "peer0",
                    "peer": null,
                    "peerAddress": "peer0.carrier-net.svc.cluster.local:7051",
                    "restserver": {
                        "port": 20001,
                        "targetPort": 20001
                    },
                    "type": "anchor"
                },
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5994
                    },
                    "events": {
                        "port": 7063
                    },
                    "expressapi": {
                        "port": 3010,
                        "targetPort": 3010
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7061
                    },
                    "name": "peer1",
                    "peer": null,
                    "peerAddress": "peer1.carrier-net.svc.cluster.local:7061",
                    "restserver": {
                        "port": 20011,
                        "targetPort": 20011
                    },
                    "type": "nonanchor"
                }
            ]
        },
        "state": "London",
        "subject": "O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB",
        "type": "peer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [include_role : setup/tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:63
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s to community.kubernetes.k8s
redirecting (type: modules) ansible.builtin.k8s to community.kubernetes.k8s
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s to community.kubernetes.k8s
redirecting (type: modules) ansible.builtin.k8s to community.kubernetes.k8s

TASK [setup/tiller : Check if Tiller is already installed in the Kubernetes clusters] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682764.4644523-16131-13623060954299 `" && echo ansible-tmp-1604682764.4644523-16131-13623060954299="` echo /root/.ansible/tmp/ansible-tmp-1604682764.4644523-16131-13623060954299 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpvl41zfb_ TO /root/.ansible/tmp/ansible-tmp-1604682764.4644523-16131-13623060954299/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682764.4644523-16131-13623060954299/ /root/.ansible/tmp/ansible-tmp-1604682764.4644523-16131-13623060954299/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682764.4644523-16131-13623060954299/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682764.4644523-16131-13623060954299/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Create service account for Tiller] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:14
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Apply Tiller RBAC definintion] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Setup tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:47
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Wait for tiller to be ready] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:55
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682765.499386-16172-142272760423947 `" && echo ansible-tmp-1604682765.499386-16172-142272760423947="` echo /root/.ansible/tmp/ansible-tmp-1604682765.499386-16172-142272760423947 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp0h4zc6yk TO /root/.ansible/tmp/ansible-tmp-1604682765.499386-16172-142272760423947/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682765.499386-16172-142272760423947/ /root/.ansible/tmp/ansible-tmp-1604682765.499386-16172-142272760423947/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682765.499386-16172-142272760423947/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682765.499386-16172-142272760423947/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Check if Tiller is already installed in the Kubernetes clusters] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682766.1228833-16201-99014240651533 `" && echo ansible-tmp-1604682766.1228833-16201-99014240651533="` echo /root/.ansible/tmp/ansible-tmp-1604682766.1228833-16201-99014240651533 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmph6juiqa0 TO /root/.ansible/tmp/ansible-tmp-1604682766.1228833-16201-99014240651533/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682766.1228833-16201-99014240651533/ /root/.ansible/tmp/ansible-tmp-1604682766.1228833-16201-99014240651533/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682766.1228833-16201-99014240651533/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682766.1228833-16201-99014240651533/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Create service account for Tiller] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:14
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Apply Tiller RBAC definintion] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Setup tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:47
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Wait for tiller to be ready] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:55

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682766.9254112-16241-6277141236769 `" && echo ansible-tmp-1604682766.9254112-16241-6277141236769="` echo /root/.ansible/tmp/ansible-tmp-1604682766.9254112-16241-6277141236769 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp7_5badz3 TO /root/.ansible/tmp/ansible-tmp-1604682766.9254112-16241-6277141236769/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682766.9254112-16241-6277141236769/ /root/.ansible/tmp/ansible-tmp-1604682766.9254112-16241-6277141236769/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682766.9254112-16241-6277141236769/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682766.9254112-16241-6277141236769/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}
META: ran handlers
META: ran handlers

PLAY [ansible_provisioners] ****************************************************
META: ran handlers

TASK [include_role : setup/flux] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/kubernetes-env-setup.yaml:11
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s to community.kubernetes.k8s
redirecting (type: modules) ansible.builtin.k8s to community.kubernetes.k8s
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [aws-cli : register temporary directory] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : check aws cli] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : download aws cli] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : extract aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:34
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : install aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:44
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : configuring aws] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:52
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-auth : register temporary directory] *********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check aws-authenticator] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-auth : create bin directory] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Install aws-authenticator] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:24
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-auth : Test Kubernetes connection] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:35
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [helm : register temporary directory] *************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682767.9923832-16297-253306502032168 `" && echo ansible-tmp-1604682767.9923832-16297-253306502032168="` echo /root/.ansible/tmp/ansible-tmp-1604682767.9923832-16297-253306502032168 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp87nwui_y TO /root/.ansible/tmp/ansible-tmp-1604682767.9923832-16297-253306502032168/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682767.9923832-16297-253306502032168/ /root/.ansible/tmp/ansible-tmp-1604682767.9923832-16297-253306502032168/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682767.9923832-16297-253306502032168/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682767.9923832-16297-253306502032168/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.xu349wgp",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [check helm] **************************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682768.1709158-16323-134037189808527 `" && echo ansible-tmp-1604682768.1709158-16323-134037189808527="` echo /root/.ansible/tmp/ansible-tmp-1604682768.1709158-16323-134037189808527 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp3eo28ozv TO /root/.ansible/tmp/ansible-tmp-1604682768.1709158-16323-134037189808527/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682768.1709158-16323-134037189808527/ /root/.ansible/tmp/ansible-tmp-1604682768.1709158-16323-134037189808527/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682768.1709158-16323-134037189808527/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682768.1709158-16323-134037189808527/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/helm"
        }
    },
    "stat": {
        "atime": 1603618464.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 78000,
        "charset": "binary",
        "checksum": "5820860e398793a3b0b54449e9b6f9a4a0f35cb9",
        "ctime": 1604239659.0090716,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126511,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618464.0,
        "nlink": 1,
        "path": "/root/bin/helm",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 39936000,
        "uid": 0,
        "version": "2759632516",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [Install helm] ************************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Unzip helm archive] ******************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:37
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Move helm binaries] ******************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:47
skipping: [localhost] => (item=helm)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "helm",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Test helm installation] **************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:58
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682768.5305226-16359-220376007952421 `" && echo ansible-tmp-1604682768.5305226-16359-220376007952421="` echo /root/.ansible/tmp/ansible-tmp-1604682768.5305226-16359-220376007952421 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpj0iakgnu TO /root/.ansible/tmp/ansible-tmp-1604682768.5305226-16359-220376007952421/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682768.5305226-16359-220376007952421/ /root/.ansible/tmp/ansible-tmp-1604682768.5305226-16359-220376007952421/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682768.5305226-16359-220376007952421/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682768.5305226-16359-220376007952421/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "helm",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.053852",
    "end": "2020-11-06 17:12:48.715733",
    "invocation": {
        "module_args": {
            "_raw_params": "helm version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:12:48.661881",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client: v2.16.12+g47f0b88",
    "stdout_lines": [
        "Client: v2.16.12+g47f0b88"
    ]
}

TASK [kubectl : register temporary directory] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682768.76705-16390-240509220263821 `" && echo ansible-tmp-1604682768.76705-16390-240509220263821="` echo /root/.ansible/tmp/ansible-tmp-1604682768.76705-16390-240509220263821 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpxgj8vp_p TO /root/.ansible/tmp/ansible-tmp-1604682768.76705-16390-240509220263821/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682768.76705-16390-240509220263821/ /root/.ansible/tmp/ansible-tmp-1604682768.76705-16390-240509220263821/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682768.76705-16390-240509220263821/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682768.76705-16390-240509220263821/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.jb34bfus",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [check kubectl] ***********************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682768.945161-16416-27408436514526 `" && echo ansible-tmp-1604682768.945161-16416-27408436514526="` echo /root/.ansible/tmp/ansible-tmp-1604682768.945161-16416-27408436514526 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp82klz79q TO /root/.ansible/tmp/ansible-tmp-1604682768.945161-16416-27408436514526/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682768.945161-16416-27408436514526/ /root/.ansible/tmp/ansible-tmp-1604682768.945161-16416-27408436514526/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682768.945161-16416-27408436514526/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682768.945161-16416-27408436514526/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/kubectl"
        }
    },
    "stat": {
        "atime": 1603618462.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 83992,
        "charset": "binary",
        "checksum": "fe0bcf142cabb39a09ab46440d797bd85d7fa838",
        "ctime": 1604239658.6170657,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126502,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618462.0,
        "nlink": 1,
        "path": "/root/bin/kubectl",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 43003904,
        "uid": 0,
        "version": "1156023499",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [Download kubectl binary] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [kubectl : Unarchive kubernetes-client] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [kubectl : create bin directory] ******************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:33
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Copy kubectl binary to destination directory] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:41
skipping: [localhost] => (item=kubectl)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "kubectl",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Test kubectl installation] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:55
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682769.3176117-16452-46694272332927 `" && echo ansible-tmp-1604682769.3176117-16452-46694272332927="` echo /root/.ansible/tmp/ansible-tmp-1604682769.3176117-16452-46694272332927 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp7_bd4tdb TO /root/.ansible/tmp/ansible-tmp-1604682769.3176117-16452-46694272332927/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682769.3176117-16452-46694272332927/ /root/.ansible/tmp/ansible-tmp-1604682769.3176117-16452-46694272332927/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682769.3176117-16452-46694272332927/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682769.3176117-16452-46694272332927/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "kubectl",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.048287",
    "end": "2020-11-06 17:12:49.496242",
    "invocation": {
        "module_args": {
            "_raw_params": "kubectl version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:12:49.447955",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client Version: v1.19.0",
    "stdout_lines": [
        "Client Version: v1.19.0"
    ]
}

TASK [setup/tiller : Check if Tiller is already installed in the Kubernetes clusters] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682769.5615244-16483-52583172370239 `" && echo ansible-tmp-1604682769.5615244-16483-52583172370239="` echo /root/.ansible/tmp/ansible-tmp-1604682769.5615244-16483-52583172370239 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp_lhnllk2 TO /root/.ansible/tmp/ansible-tmp-1604682769.5615244-16483-52583172370239/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682769.5615244-16483-52583172370239/ /root/.ansible/tmp/ansible-tmp-1604682769.5615244-16483-52583172370239/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682769.5615244-16483-52583172370239/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682769.5615244-16483-52583172370239/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Create service account for Tiller] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:14
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Apply Tiller RBAC definintion] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Setup tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:47
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Wait for tiller to be ready] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:55
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682770.422053-16523-135880991945237 `" && echo ansible-tmp-1604682770.422053-16523-135880991945237="` echo /root/.ansible/tmp/ansible-tmp-1604682770.422053-16523-135880991945237 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpy5f8hjyj TO /root/.ansible/tmp/ansible-tmp-1604682770.422053-16523-135880991945237/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682770.422053-16523-135880991945237/ /root/.ansible/tmp/ansible-tmp-1604682770.422053-16523-135880991945237/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682770.422053-16523-135880991945237/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682770.422053-16523-135880991945237/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/flux : Check if Flux is running] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682771.0440822-16551-136936130899423 `" && echo ansible-tmp-1604682771.0440822-16551-136936130899423="` echo /root/.ansible/tmp/ansible-tmp-1604682771.0440822-16551-136936130899423 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpcoqwc9zq TO /root/.ansible/tmp/ansible-tmp-1604682771.0440822-16551-136936130899423/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682771.0440822-16551-136936130899423/ /root/.ansible/tmp/ansible-tmp-1604682771.0440822-16551-136936130899423/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682771.0440822-16551-136936130899423/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682771.0440822-16551-136936130899423/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = flux",
                "release = flux-dev"
            ],
            "name": null,
            "namespace": "default",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": []
}

TASK [setup/flux : Get ssh known hosts] ****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:17
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682771.6504765-16579-26788384252146 `" && echo ansible-tmp-1604682771.6504765-16579-26788384252146="` echo /root/.ansible/tmp/ansible-tmp-1604682771.6504765-16579-26788384252146 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp9cesfqa3 TO /root/.ansible/tmp/ansible-tmp-1604682771.6504765-16579-26788384252146/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682771.6504765-16579-26788384252146/ /root/.ansible/tmp/ansible-tmp-1604682771.6504765-16579-26788384252146/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682771.6504765-16579-26788384252146/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682771.6504765-16579-26788384252146/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "cmd": "ssh-keyscan github.com > flux_known_hosts\nchmod -R 777 flux_known_hosts\n",
    "delta": "0:00:01.525944",
    "end": "2020-11-06 17:12:53.306395",
    "invocation": {
        "module_args": {
            "_raw_params": "ssh-keyscan github.com > flux_known_hosts\nchmod -R 777 flux_known_hosts\n",
            "_uses_shell": true,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:12:51.780451",
    "stderr": "# github.com:22 SSH-2.0-babeld-17f526ba\n# github.com:22 SSH-2.0-babeld-17f526ba\n# github.com:22 SSH-2.0-babeld-17f526ba",
    "stderr_lines": [
        "# github.com:22 SSH-2.0-babeld-17f526ba",
        "# github.com:22 SSH-2.0-babeld-17f526ba",
        "# github.com:22 SSH-2.0-babeld-17f526ba"
    ],
    "stdout": "",
    "stdout_lines": []
}

TASK [setup/flux : Helm repo add] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:23
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682773.3614264-16608-215754135781168 `" && echo ansible-tmp-1604682773.3614264-16608-215754135781168="` echo /root/.ansible/tmp/ansible-tmp-1604682773.3614264-16608-215754135781168 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpmz3brszp TO /root/.ansible/tmp/ansible-tmp-1604682773.3614264-16608-215754135781168/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682773.3614264-16608-215754135781168/ /root/.ansible/tmp/ansible-tmp-1604682773.3614264-16608-215754135781168/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682773.3614264-16608-215754135781168/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682773.3614264-16608-215754135781168/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "cmd": "helm init --client-only && helm repo add fluxcd https://fluxcd.github.io/flux\n",
    "delta": "0:00:00.277812",
    "end": "2020-11-06 17:12:53.769954",
    "invocation": {
        "module_args": {
            "_raw_params": "helm init --client-only && helm repo add fluxcd https://fluxcd.github.io/flux\n",
            "_uses_shell": true,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:12:53.492142",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "$HELM_HOME has been configured at /root/.helm.\nNot installing Tiller due to 'client-only' flag having been set\n\"fluxcd\" has been added to your repositories",
    "stdout_lines": [
        "$HELM_HOME has been configured at /root/.helm.",
        "Not installing Tiller due to 'client-only' flag having been set",
        "\"fluxcd\" has been added to your repositories"
    ]
}

TASK [setup/flux : Install flux] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:30
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682773.8403614-16646-31572304277203 `" && echo ansible-tmp-1604682773.8403614-16646-31572304277203="` echo /root/.ansible/tmp/ansible-tmp-1604682773.8403614-16646-31572304277203 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpm42udy4p TO /root/.ansible/tmp/ansible-tmp-1604682773.8403614-16646-31572304277203/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682773.8403614-16646-31572304277203/ /root/.ansible/tmp/ansible-tmp-1604682773.8403614-16646-31572304277203/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682773.8403614-16646-31572304277203/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682773.8403614-16646-31572304277203/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "cmd": "KUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl create secret generic git-auth-dev --from-file=identity=/Users/s0s0dit/project/blockchain-automation-framework/build/gitops --namespace default\nKUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl apply -f /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/../../../platforms/shared/charts/flux-helm-release-crd.yaml --context=\"fabric-aks-dev1\"\nKUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml helm upgrade --install --set rbac.create=true --set helmOperator.create=true --set git.timeout=200s --set git.pollInterval=2m --set git.url='ssh://git@github.com/bafsunsu/blockchain-automation-framework.git' --set git.secretName=git-auth-dev --set git.branch=gorilla --set git.label='sync-dev' --set git.path=\"platforms/hyperledger-fabric/releases/dev\" --set-file ssh.known_hosts=flux_known_hosts --set registry.insecureHosts=\"index.docker.io/hyperledgerlabs\" --namespace default flux-dev --version \"0.15.0\" fluxcd/flux --kube-context=\"fabric-aks-dev1\"\n",
    "delta": "0:00:01.918381",
    "end": "2020-11-06 17:12:55.890877",
    "invocation": {
        "module_args": {
            "_raw_params": "KUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl create secret generic git-auth-dev --from-file=identity=/Users/s0s0dit/project/blockchain-automation-framework/build/gitops --namespace default\nKUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl apply -f /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/../../../platforms/shared/charts/flux-helm-release-crd.yaml --context=\"fabric-aks-dev1\"\nKUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml helm upgrade --install --set rbac.create=true --set helmOperator.create=true --set git.timeout=200s --set git.pollInterval=2m --set git.url='ssh://git@github.com/bafsunsu/blockchain-automation-framework.git' --set git.secretName=git-auth-dev --set git.branch=gorilla --set git.label='sync-dev' --set git.path=\"platforms/hyperledger-fabric/releases/dev\" --set-file ssh.known_hosts=flux_known_hosts --set registry.insecureHosts=\"index.docker.io/hyperledgerlabs\" --namespace default flux-dev --version \"0.15.0\" fluxcd/flux --kube-context=\"fabric-aks-dev1\"\n",
            "_uses_shell": true,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:12:53.972496",
    "stderr": "Error from server (AlreadyExists): secrets \"git-auth-dev\" already exists",
    "stderr_lines": [
        "Error from server (AlreadyExists): secrets \"git-auth-dev\" already exists"
    ],
    "stdout": "customresourcedefinition.apiextensions.k8s.io/helmreleases.flux.weave.works unchanged\nRelease \"flux-dev\" does not exist. Installing it now.\nNAME:   flux-dev\nLAST DEPLOYED: Fri Nov  6 17:12:55 2020\nNAMESPACE: default\nSTATUS: DEPLOYED\n\nRESOURCES:\n==> v1/ConfigMap\nNAME                  DATA  AGE\nflux-dev-kube-config  1     0s\nflux-dev-ssh-config   1     0s\n\n==> v1/Deployment\nNAME                    READY  UP-TO-DATE  AVAILABLE  AGE\nflux-dev                0/1    1           0          0s\nflux-dev-helm-operator  0/1    1           0          0s\nflux-dev-memcached      0/1    1           0          0s\n\n==> v1/Pod(related)\nNAME                                     READY  STATUS             RESTARTS  AGE\nflux-dev-794c97d9cc-5fvjl                0/1    ContainerCreating  0         0s\nflux-dev-helm-operator-745dc7fb99-q5d64  0/1    ContainerCreating  0         0s\nflux-dev-memcached-5f689bfdb9-8ft2h      0/1    ContainerCreating  0         0s\n\n==> v1/Service\nNAME                TYPE       CLUSTER-IP    EXTERNAL-IP  PORT(S)    AGE\nflux-dev            ClusterIP  10.0.60.221   <none>       3030/TCP   0s\nflux-dev-memcached  ClusterIP  10.0.119.183  <none>       11211/TCP  0s\n\n==> v1/ServiceAccount\nNAME      SECRETS  AGE\nflux-dev  1        0s\n\n==> v1beta1/ClusterRole\nNAME      AGE\nflux-dev  0s\n\n==> v1beta1/ClusterRoleBinding\nNAME      AGE\nflux-dev  0s\n\n\nNOTES:\nGet the Git deploy key by either (a) running\n\n  kubectl -n default logs deployment/flux-dev | grep identity.pub | cut -d '\"' -f2\n\nor by (b) installing fluxctl through\nhttps://docs.fluxcd.io/en/latest/references/fluxctl.html#installing-fluxctl\nand running:\n\n  fluxctl identity --k8s-fwd-ns default",
    "stdout_lines": [
        "customresourcedefinition.apiextensions.k8s.io/helmreleases.flux.weave.works unchanged",
        "Release \"flux-dev\" does not exist. Installing it now.",
        "NAME:   flux-dev",
        "LAST DEPLOYED: Fri Nov  6 17:12:55 2020",
        "NAMESPACE: default",
        "STATUS: DEPLOYED",
        "",
        "RESOURCES:",
        "==> v1/ConfigMap",
        "NAME                  DATA  AGE",
        "flux-dev-kube-config  1     0s",
        "flux-dev-ssh-config   1     0s",
        "",
        "==> v1/Deployment",
        "NAME                    READY  UP-TO-DATE  AVAILABLE  AGE",
        "flux-dev                0/1    1           0          0s",
        "flux-dev-helm-operator  0/1    1           0          0s",
        "flux-dev-memcached      0/1    1           0          0s",
        "",
        "==> v1/Pod(related)",
        "NAME                                     READY  STATUS             RESTARTS  AGE",
        "flux-dev-794c97d9cc-5fvjl                0/1    ContainerCreating  0         0s",
        "flux-dev-helm-operator-745dc7fb99-q5d64  0/1    ContainerCreating  0         0s",
        "flux-dev-memcached-5f689bfdb9-8ft2h      0/1    ContainerCreating  0         0s",
        "",
        "==> v1/Service",
        "NAME                TYPE       CLUSTER-IP    EXTERNAL-IP  PORT(S)    AGE",
        "flux-dev            ClusterIP  10.0.60.221   <none>       3030/TCP   0s",
        "flux-dev-memcached  ClusterIP  10.0.119.183  <none>       11211/TCP  0s",
        "",
        "==> v1/ServiceAccount",
        "NAME      SECRETS  AGE",
        "flux-dev  1        0s",
        "",
        "==> v1beta1/ClusterRole",
        "NAME      AGE",
        "flux-dev  0s",
        "",
        "==> v1beta1/ClusterRoleBinding",
        "NAME      AGE",
        "flux-dev  0s",
        "",
        "",
        "NOTES:",
        "Get the Git deploy key by either (a) running",
        "",
        "  kubectl -n default logs deployment/flux-dev | grep identity.pub | cut -d '\"' -f2",
        "",
        "or by (b) installing fluxctl through",
        "https://docs.fluxcd.io/en/latest/references/fluxctl.html#installing-fluxctl",
        "and running:",
        "",
        "  fluxctl identity --k8s-fwd-ns default"
    ]
}

TASK [wait for pods to come up] ************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:40
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [check/helm_component : Wait for Pod flux in default] *********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod flux in default] *********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682776.0969095-16694-62341143960128 `" && echo ansible-tmp-1604682776.0969095-16694-62341143960128="` echo /root/.ansible/tmp/ansible-tmp-1604682776.0969095-16694-62341143960128 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpfd__35ax TO /root/.ansible/tmp/ansible-tmp-1604682776.0969095-16694-62341143960128/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682776.0969095-16694-62341143960128/ /root/.ansible/tmp/ansible-tmp-1604682776.0969095-16694-62341143960128/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682776.0969095-16694-62341143960128/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682776.0969095-16694-62341143960128/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for Pod flux in default (20 retries left).Result was: {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = flux",
                "release = flux-dev"
            ],
            "name": null,
            "namespace": "default",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682806.752897-16694-182685969681012 `" && echo ansible-tmp-1604682806.752897-16694-182685969681012="` echo /root/.ansible/tmp/ansible-tmp-1604682806.752897-16694-182685969681012 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpkzf_zjbr TO /root/.ansible/tmp/ansible-tmp-1604682806.752897-16694-182685969681012/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682806.752897-16694-182685969681012/ /root/.ansible/tmp/ansible-tmp-1604682806.752897-16694-182685969681012/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682806.752897-16694-182685969681012/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682806.752897-16694-182685969681012/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 2,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = flux",
                "release = flux-dev"
            ],
            "name": null,
            "namespace": "default",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-11-06T17:12:55Z",
                "generateName": "flux-dev-794c97d9cc-",
                "labels": {
                    "app": "flux",
                    "pod-template-hash": "794c97d9cc",
                    "release": "flux-dev"
                },
                "name": "flux-dev-794c97d9cc-5fvjl",
                "namespace": "default",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "flux-dev-794c97d9cc",
                        "uid": "30515c8e-97ff-4646-b529-ba8293607965"
                    }
                ],
                "resourceVersion": "2491791",
                "selfLink": "/api/v1/namespaces/default/pods/flux-dev-794c97d9cc-5fvjl",
                "uid": "f2d33374-d826-4be8-b940-7a869af52d6b"
            },
            "spec": {
                "containers": [
                    {
                        "args": [
                            "--log-format=fmt",
                            "--ssh-keygen-dir=/var/fluxd/keygen",
                            "--k8s-secret-name=git-auth-dev",
                            "--memcached-hostname=flux-dev-memcached",
                            "--sync-state=git",
                            "--memcached-service=",
                            "--git-url=ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
                            "--git-branch=gorilla",
                            "--git-path=platforms/hyperledger-fabric/releases/dev",
                            "--git-readonly=false",
                            "--git-user=Weave Flux",
                            "--git-email=support@weave.works",
                            "--git-set-author=false",
                            "--git-poll-interval=2m",
                            "--git-timeout=200s",
                            "--sync-interval=2m",
                            "--git-ci-skip=false",
                            "--git-label=sync-dev",
                            "--registry-poll-interval=5m",
                            "--registry-rps=200",
                            "--registry-burst=125",
                            "--registry-trace=false",
                            "--registry-insecure-host=index.docker.io/hyperledgerlabs"
                        ],
                        "env": [
                            {
                                "name": "KUBECONFIG",
                                "value": "/root/.kubectl/config"
                            }
                        ],
                        "image": "docker.io/fluxcd/flux:1.15.0",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/api/flux/v6/identity.pub",
                                "port": 3030,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 5,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 5
                        },
                        "name": "flux",
                        "ports": [
                            {
                                "containerPort": 3030,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/api/flux/v6/identity.pub",
                                "port": 3030,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 5,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 5
                        },
                        "resources": {
                            "requests": {
                                "cpu": "50m",
                                "memory": "64Mi"
                            }
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/root/.kubectl",
                                "name": "kubedir"
                            },
                            {
                                "mountPath": "/root/.ssh",
                                "name": "sshdir",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/etc/fluxd/ssh",
                                "name": "git-key",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/var/fluxd/keygen",
                                "name": "git-keygen"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "flux-dev-token-kqjvw",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000001",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "flux-dev",
                "serviceAccountName": "flux-dev",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "configMap": {
                            "defaultMode": 420,
                            "name": "flux-dev-kube-config"
                        },
                        "name": "kubedir"
                    },
                    {
                        "configMap": {
                            "defaultMode": 384,
                            "name": "flux-dev-ssh-config"
                        },
                        "name": "sshdir"
                    },
                    {
                        "name": "git-key",
                        "secret": {
                            "defaultMode": 256,
                            "secretName": "git-auth-dev"
                        }
                    },
                    {
                        "emptyDir": {
                            "medium": "Memory"
                        },
                        "name": "git-keygen"
                    },
                    {
                        "name": "flux-dev-token-kqjvw",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "flux-dev-token-kqjvw"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:12:55Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:13:03Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:13:03Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:12:55Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://82881e33452125f85f66eeb115abf465486acc13b248ce4f2aa9ed24c6e28d4c",
                        "image": "fluxcd/flux:1.15.0",
                        "imageID": "docker-pullable://fluxcd/flux@sha256:ba4bd9ed8ea13ba4aa94d97b6ca285b6f3831fc5861369110dc19f238ac13201",
                        "lastState": {},
                        "name": "flux",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-11-06T17:12:56Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.35",
                "phase": "Running",
                "podIP": "10.1.0.59",
                "podIPs": [
                    {
                        "ip": "10.1.0.59"
                    }
                ],
                "qosClass": "Burstable",
                "startTime": "2020-11-06T17:12:55Z"
            }
        }
    ]
}

TASK [setup/flux : Get ssh key] ************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:54
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682807.4515145-16748-17594280301918 `" && echo ansible-tmp-1604682807.4515145-16748-17594280301918="` echo /root/.ansible/tmp/ansible-tmp-1604682807.4515145-16748-17594280301918 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmplnh9593w TO /root/.ansible/tmp/ansible-tmp-1604682807.4515145-16748-17594280301918/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682807.4515145-16748-17594280301918/ /root/.ansible/tmp/ansible-tmp-1604682807.4515145-16748-17594280301918/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682807.4515145-16748-17594280301918/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682807.4515145-16748-17594280301918/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": "KUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl -n default logs deployment/flux-dev | grep identity.pub | cut -d '\"' -f2\n",
    "delta": "0:00:00.148427",
    "end": "2020-11-06 17:13:27.729655",
    "invocation": {
        "module_args": {
            "_raw_params": "KUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl -n default logs deployment/flux-dev | grep identity.pub | cut -d '\"' -f2\n",
            "_uses_shell": true,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:13:27.581228",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC8ImoOJkm9nhYVB2d6wbBVNW526Q3nEQoeBG0tQTTbQ5F6bFIkfraDGKKxqpRZRPwiSTkcxUbGeWV1xpbX4kuG3NKn8MwFm1LBilEnp8m9t48ID9cIfLe4WESE4KCqmXPXjMK/OFa1Yo1JRd9P/PHVK4mJK1syXAZl0XKhK9gujrStC/EOsRaB/6ToyQeOPPfeWqL/EO8P6a5T1CFerUBc+Mw4lnFa8XEP7ab4q3xZbmuZ+oGt6sFR+/Jzu8kYJAY1j0ASqBU0DbJbUvvDnpEr7sM3DHTLHj3Mu0K3d4qyc+eaSMono+6BJZIi5JfT3ymgJ5Xwa3W87w5zPgYd+/LVF/wnChgeYYAzCfHZagFQTzxS/wEuWjvNouTf2TbVbgdFRCKPQ9BTTQB+Hrlm8kzqhduNsWlQO9puWd6Zn/A8B+rcae0hrJdKrF7A8NA5N5N/cR9kiri6rJ4m8kJWvrG+zTEBHWcqtDvRj0Yqf29m0XP2IjERFfCwe5W5efIkEk0=",
    "stdout_lines": [
        "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC8ImoOJkm9nhYVB2d6wbBVNW526Q3nEQoeBG0tQTTbQ5F6bFIkfraDGKKxqpRZRPwiSTkcxUbGeWV1xpbX4kuG3NKn8MwFm1LBilEnp8m9t48ID9cIfLe4WESE4KCqmXPXjMK/OFa1Yo1JRd9P/PHVK4mJK1syXAZl0XKhK9gujrStC/EOsRaB/6ToyQeOPPfeWqL/EO8P6a5T1CFerUBc+Mw4lnFa8XEP7ab4q3xZbmuZ+oGt6sFR+/Jzu8kYJAY1j0ASqBU0DbJbUvvDnpEr7sM3DHTLHj3Mu0K3d4qyc+eaSMono+6BJZIi5JfT3ymgJ5Xwa3W87w5zPgYd+/LVF/wnChgeYYAzCfHZagFQTzxS/wEuWjvNouTf2TbVbgdFRCKPQ9BTTQB+Hrlm8kzqhduNsWlQO9puWd6Zn/A8B+rcae0hrJdKrF7A8NA5N5N/cR9kiri6rJ4m8kJWvrG+zTEBHWcqtDvRj0Yqf29m0XP2IjERFfCwe5W5efIkEk0="
    ]
}

TASK [setup/flux : Output ssh key] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:60
ok: [localhost] => {
    "ssh_key.stdout": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC8ImoOJkm9nhYVB2d6wbBVNW526Q3nEQoeBG0tQTTbQ5F6bFIkfraDGKKxqpRZRPwiSTkcxUbGeWV1xpbX4kuG3NKn8MwFm1LBilEnp8m9t48ID9cIfLe4WESE4KCqmXPXjMK/OFa1Yo1JRd9P/PHVK4mJK1syXAZl0XKhK9gujrStC/EOsRaB/6ToyQeOPPfeWqL/EO8P6a5T1CFerUBc+Mw4lnFa8XEP7ab4q3xZbmuZ+oGt6sFR+/Jzu8kYJAY1j0ASqBU0DbJbUvvDnpEr7sM3DHTLHj3Mu0K3d4qyc+eaSMono+6BJZIi5JfT3ymgJ5Xwa3W87w5zPgYd+/LVF/wnChgeYYAzCfHZagFQTzxS/wEuWjvNouTf2TbVbgdFRCKPQ9BTTQB+Hrlm8kzqhduNsWlQO9puWd6Zn/A8B+rcae0hrJdKrF7A8NA5N5N/cR9kiri6rJ4m8kJWvrG+zTEBHWcqtDvRj0Yqf29m0XP2IjERFfCwe5W5efIkEk0="
}

TASK [aws-cli : register temporary directory] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : check aws cli] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : download aws cli] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : extract aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:34
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : install aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:44
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : configuring aws] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:52
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-auth : register temporary directory] *********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check aws-authenticator] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-auth : create bin directory] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Install aws-authenticator] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:24
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-auth : Test Kubernetes connection] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:35
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [helm : register temporary directory] *************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682808.1100607-16808-141366918357416 `" && echo ansible-tmp-1604682808.1100607-16808-141366918357416="` echo /root/.ansible/tmp/ansible-tmp-1604682808.1100607-16808-141366918357416 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp8vnguiik TO /root/.ansible/tmp/ansible-tmp-1604682808.1100607-16808-141366918357416/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682808.1100607-16808-141366918357416/ /root/.ansible/tmp/ansible-tmp-1604682808.1100607-16808-141366918357416/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682808.1100607-16808-141366918357416/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682808.1100607-16808-141366918357416/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.gztddt7x",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [check helm] **************************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682808.288643-16834-151081159189237 `" && echo ansible-tmp-1604682808.288643-16834-151081159189237="` echo /root/.ansible/tmp/ansible-tmp-1604682808.288643-16834-151081159189237 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp1fwn9v_2 TO /root/.ansible/tmp/ansible-tmp-1604682808.288643-16834-151081159189237/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682808.288643-16834-151081159189237/ /root/.ansible/tmp/ansible-tmp-1604682808.288643-16834-151081159189237/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682808.288643-16834-151081159189237/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682808.288643-16834-151081159189237/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/helm"
        }
    },
    "stat": {
        "atime": 1603618464.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 78000,
        "charset": "binary",
        "checksum": "5820860e398793a3b0b54449e9b6f9a4a0f35cb9",
        "ctime": 1604239659.0090716,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126511,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618464.0,
        "nlink": 1,
        "path": "/root/bin/helm",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 39936000,
        "uid": 0,
        "version": "2759632516",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [Install helm] ************************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Unzip helm archive] ******************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:37
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Move helm binaries] ******************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:47
skipping: [localhost] => (item=helm)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "helm",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Test helm installation] **************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:58
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682808.6479905-16870-131966905655313 `" && echo ansible-tmp-1604682808.6479905-16870-131966905655313="` echo /root/.ansible/tmp/ansible-tmp-1604682808.6479905-16870-131966905655313 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpysvsfyrg TO /root/.ansible/tmp/ansible-tmp-1604682808.6479905-16870-131966905655313/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682808.6479905-16870-131966905655313/ /root/.ansible/tmp/ansible-tmp-1604682808.6479905-16870-131966905655313/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682808.6479905-16870-131966905655313/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682808.6479905-16870-131966905655313/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "helm",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.051152",
    "end": "2020-11-06 17:13:28.832203",
    "invocation": {
        "module_args": {
            "_raw_params": "helm version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:13:28.781051",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client: v2.16.12+g47f0b88",
    "stdout_lines": [
        "Client: v2.16.12+g47f0b88"
    ]
}

TASK [kubectl : register temporary directory] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682808.88618-16901-23653021069707 `" && echo ansible-tmp-1604682808.88618-16901-23653021069707="` echo /root/.ansible/tmp/ansible-tmp-1604682808.88618-16901-23653021069707 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpi3lj_4mo TO /root/.ansible/tmp/ansible-tmp-1604682808.88618-16901-23653021069707/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682808.88618-16901-23653021069707/ /root/.ansible/tmp/ansible-tmp-1604682808.88618-16901-23653021069707/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682808.88618-16901-23653021069707/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682808.88618-16901-23653021069707/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.bn1hx_lp",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [check kubectl] ***********************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682809.0664527-16927-55549080217843 `" && echo ansible-tmp-1604682809.0664527-16927-55549080217843="` echo /root/.ansible/tmp/ansible-tmp-1604682809.0664527-16927-55549080217843 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp0p1ua5l8 TO /root/.ansible/tmp/ansible-tmp-1604682809.0664527-16927-55549080217843/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682809.0664527-16927-55549080217843/ /root/.ansible/tmp/ansible-tmp-1604682809.0664527-16927-55549080217843/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682809.0664527-16927-55549080217843/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682809.0664527-16927-55549080217843/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/kubectl"
        }
    },
    "stat": {
        "atime": 1603618462.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 83992,
        "charset": "binary",
        "checksum": "fe0bcf142cabb39a09ab46440d797bd85d7fa838",
        "ctime": 1604239658.6170657,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126502,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618462.0,
        "nlink": 1,
        "path": "/root/bin/kubectl",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 43003904,
        "uid": 0,
        "version": "1156023499",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [Download kubectl binary] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [kubectl : Unarchive kubernetes-client] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [kubectl : create bin directory] ******************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:33
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Copy kubectl binary to destination directory] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:41
skipping: [localhost] => (item=kubectl)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "kubectl",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Test kubectl installation] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:55
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682809.4367473-16963-257098655796850 `" && echo ansible-tmp-1604682809.4367473-16963-257098655796850="` echo /root/.ansible/tmp/ansible-tmp-1604682809.4367473-16963-257098655796850 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmphxehjz3d TO /root/.ansible/tmp/ansible-tmp-1604682809.4367473-16963-257098655796850/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682809.4367473-16963-257098655796850/ /root/.ansible/tmp/ansible-tmp-1604682809.4367473-16963-257098655796850/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682809.4367473-16963-257098655796850/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682809.4367473-16963-257098655796850/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "kubectl",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.049468",
    "end": "2020-11-06 17:13:29.616836",
    "invocation": {
        "module_args": {
            "_raw_params": "kubectl version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:13:29.567368",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client Version: v1.19.0",
    "stdout_lines": [
        "Client Version: v1.19.0"
    ]
}

TASK [setup/tiller : Check if Tiller is already installed in the Kubernetes clusters] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682809.676916-16994-72272394661744 `" && echo ansible-tmp-1604682809.676916-16994-72272394661744="` echo /root/.ansible/tmp/ansible-tmp-1604682809.676916-16994-72272394661744 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpacfeph6u TO /root/.ansible/tmp/ansible-tmp-1604682809.676916-16994-72272394661744/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682809.676916-16994-72272394661744/ /root/.ansible/tmp/ansible-tmp-1604682809.676916-16994-72272394661744/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682809.676916-16994-72272394661744/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682809.676916-16994-72272394661744/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Create service account for Tiller] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:14
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Apply Tiller RBAC definintion] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Setup tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:47
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Wait for tiller to be ready] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:55

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682810.524937-17034-108242891892834 `" && echo ansible-tmp-1604682810.524937-17034-108242891892834="` echo /root/.ansible/tmp/ansible-tmp-1604682810.524937-17034-108242891892834 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpr6e33z_0 TO /root/.ansible/tmp/ansible-tmp-1604682810.524937-17034-108242891892834/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682810.524937-17034-108242891892834/ /root/.ansible/tmp/ansible-tmp-1604682810.524937-17034-108242891892834/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682810.524937-17034-108242891892834/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682810.524937-17034-108242891892834/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/flux : Check if Flux is running] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682811.1632092-17062-121583372984898 `" && echo ansible-tmp-1604682811.1632092-17062-121583372984898="` echo /root/.ansible/tmp/ansible-tmp-1604682811.1632092-17062-121583372984898 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpkgc5yv1d TO /root/.ansible/tmp/ansible-tmp-1604682811.1632092-17062-121583372984898/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682811.1632092-17062-121583372984898/ /root/.ansible/tmp/ansible-tmp-1604682811.1632092-17062-121583372984898/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682811.1632092-17062-121583372984898/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682811.1632092-17062-121583372984898/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = flux",
                "release = flux-dev"
            ],
            "name": null,
            "namespace": "default",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-11-06T17:12:55Z",
                "generateName": "flux-dev-794c97d9cc-",
                "labels": {
                    "app": "flux",
                    "pod-template-hash": "794c97d9cc",
                    "release": "flux-dev"
                },
                "name": "flux-dev-794c97d9cc-5fvjl",
                "namespace": "default",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "flux-dev-794c97d9cc",
                        "uid": "30515c8e-97ff-4646-b529-ba8293607965"
                    }
                ],
                "resourceVersion": "2491791",
                "selfLink": "/api/v1/namespaces/default/pods/flux-dev-794c97d9cc-5fvjl",
                "uid": "f2d33374-d826-4be8-b940-7a869af52d6b"
            },
            "spec": {
                "containers": [
                    {
                        "args": [
                            "--log-format=fmt",
                            "--ssh-keygen-dir=/var/fluxd/keygen",
                            "--k8s-secret-name=git-auth-dev",
                            "--memcached-hostname=flux-dev-memcached",
                            "--sync-state=git",
                            "--memcached-service=",
                            "--git-url=ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
                            "--git-branch=gorilla",
                            "--git-path=platforms/hyperledger-fabric/releases/dev",
                            "--git-readonly=false",
                            "--git-user=Weave Flux",
                            "--git-email=support@weave.works",
                            "--git-set-author=false",
                            "--git-poll-interval=2m",
                            "--git-timeout=200s",
                            "--sync-interval=2m",
                            "--git-ci-skip=false",
                            "--git-label=sync-dev",
                            "--registry-poll-interval=5m",
                            "--registry-rps=200",
                            "--registry-burst=125",
                            "--registry-trace=false",
                            "--registry-insecure-host=index.docker.io/hyperledgerlabs"
                        ],
                        "env": [
                            {
                                "name": "KUBECONFIG",
                                "value": "/root/.kubectl/config"
                            }
                        ],
                        "image": "docker.io/fluxcd/flux:1.15.0",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/api/flux/v6/identity.pub",
                                "port": 3030,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 5,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 5
                        },
                        "name": "flux",
                        "ports": [
                            {
                                "containerPort": 3030,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/api/flux/v6/identity.pub",
                                "port": 3030,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 5,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 5
                        },
                        "resources": {
                            "requests": {
                                "cpu": "50m",
                                "memory": "64Mi"
                            }
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/root/.kubectl",
                                "name": "kubedir"
                            },
                            {
                                "mountPath": "/root/.ssh",
                                "name": "sshdir",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/etc/fluxd/ssh",
                                "name": "git-key",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/var/fluxd/keygen",
                                "name": "git-keygen"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "flux-dev-token-kqjvw",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000001",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "flux-dev",
                "serviceAccountName": "flux-dev",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "configMap": {
                            "defaultMode": 420,
                            "name": "flux-dev-kube-config"
                        },
                        "name": "kubedir"
                    },
                    {
                        "configMap": {
                            "defaultMode": 384,
                            "name": "flux-dev-ssh-config"
                        },
                        "name": "sshdir"
                    },
                    {
                        "name": "git-key",
                        "secret": {
                            "defaultMode": 256,
                            "secretName": "git-auth-dev"
                        }
                    },
                    {
                        "emptyDir": {
                            "medium": "Memory"
                        },
                        "name": "git-keygen"
                    },
                    {
                        "name": "flux-dev-token-kqjvw",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "flux-dev-token-kqjvw"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:12:55Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:13:03Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:13:03Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:12:55Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://82881e33452125f85f66eeb115abf465486acc13b248ce4f2aa9ed24c6e28d4c",
                        "image": "fluxcd/flux:1.15.0",
                        "imageID": "docker-pullable://fluxcd/flux@sha256:ba4bd9ed8ea13ba4aa94d97b6ca285b6f3831fc5861369110dc19f238ac13201",
                        "lastState": {},
                        "name": "flux",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-11-06T17:12:56Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.35",
                "phase": "Running",
                "podIP": "10.1.0.59",
                "podIPs": [
                    {
                        "ip": "10.1.0.59"
                    }
                ],
                "qosClass": "Burstable",
                "startTime": "2020-11-06T17:12:55Z"
            }
        }
    ]
}

TASK [setup/flux : Get ssh known hosts] ****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:17
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/flux : Helm repo add] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:23
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/flux : Install flux] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:30
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [wait for pods to come up] ************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:40
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/flux : Get ssh key] ************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:54
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682811.932792-17098-212039951565992 `" && echo ansible-tmp-1604682811.932792-17098-212039951565992="` echo /root/.ansible/tmp/ansible-tmp-1604682811.932792-17098-212039951565992 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp8fv8utwh TO /root/.ansible/tmp/ansible-tmp-1604682811.932792-17098-212039951565992/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682811.932792-17098-212039951565992/ /root/.ansible/tmp/ansible-tmp-1604682811.932792-17098-212039951565992/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682811.932792-17098-212039951565992/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682811.932792-17098-212039951565992/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": "KUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl -n default logs deployment/flux-dev | grep identity.pub | cut -d '\"' -f2\n",
    "delta": "0:00:00.179522",
    "end": "2020-11-06 17:13:32.242800",
    "invocation": {
        "module_args": {
            "_raw_params": "KUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl -n default logs deployment/flux-dev | grep identity.pub | cut -d '\"' -f2\n",
            "_uses_shell": true,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:13:32.063278",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC8ImoOJkm9nhYVB2d6wbBVNW526Q3nEQoeBG0tQTTbQ5F6bFIkfraDGKKxqpRZRPwiSTkcxUbGeWV1xpbX4kuG3NKn8MwFm1LBilEnp8m9t48ID9cIfLe4WESE4KCqmXPXjMK/OFa1Yo1JRd9P/PHVK4mJK1syXAZl0XKhK9gujrStC/EOsRaB/6ToyQeOPPfeWqL/EO8P6a5T1CFerUBc+Mw4lnFa8XEP7ab4q3xZbmuZ+oGt6sFR+/Jzu8kYJAY1j0ASqBU0DbJbUvvDnpEr7sM3DHTLHj3Mu0K3d4qyc+eaSMono+6BJZIi5JfT3ymgJ5Xwa3W87w5zPgYd+/LVF/wnChgeYYAzCfHZagFQTzxS/wEuWjvNouTf2TbVbgdFRCKPQ9BTTQB+Hrlm8kzqhduNsWlQO9puWd6Zn/A8B+rcae0hrJdKrF7A8NA5N5N/cR9kiri6rJ4m8kJWvrG+zTEBHWcqtDvRj0Yqf29m0XP2IjERFfCwe5W5efIkEk0=",
    "stdout_lines": [
        "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC8ImoOJkm9nhYVB2d6wbBVNW526Q3nEQoeBG0tQTTbQ5F6bFIkfraDGKKxqpRZRPwiSTkcxUbGeWV1xpbX4kuG3NKn8MwFm1LBilEnp8m9t48ID9cIfLe4WESE4KCqmXPXjMK/OFa1Yo1JRd9P/PHVK4mJK1syXAZl0XKhK9gujrStC/EOsRaB/6ToyQeOPPfeWqL/EO8P6a5T1CFerUBc+Mw4lnFa8XEP7ab4q3xZbmuZ+oGt6sFR+/Jzu8kYJAY1j0ASqBU0DbJbUvvDnpEr7sM3DHTLHj3Mu0K3d4qyc+eaSMono+6BJZIi5JfT3ymgJ5Xwa3W87w5zPgYd+/LVF/wnChgeYYAzCfHZagFQTzxS/wEuWjvNouTf2TbVbgdFRCKPQ9BTTQB+Hrlm8kzqhduNsWlQO9puWd6Zn/A8B+rcae0hrJdKrF7A8NA5N5N/cR9kiri6rJ4m8kJWvrG+zTEBHWcqtDvRj0Yqf29m0XP2IjERFfCwe5W5efIkEk0="
    ]
}

TASK [setup/flux : Output ssh key] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:60
ok: [localhost] => {
    "ssh_key.stdout": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC8ImoOJkm9nhYVB2d6wbBVNW526Q3nEQoeBG0tQTTbQ5F6bFIkfraDGKKxqpRZRPwiSTkcxUbGeWV1xpbX4kuG3NKn8MwFm1LBilEnp8m9t48ID9cIfLe4WESE4KCqmXPXjMK/OFa1Yo1JRd9P/PHVK4mJK1syXAZl0XKhK9gujrStC/EOsRaB/6ToyQeOPPfeWqL/EO8P6a5T1CFerUBc+Mw4lnFa8XEP7ab4q3xZbmuZ+oGt6sFR+/Jzu8kYJAY1j0ASqBU0DbJbUvvDnpEr7sM3DHTLHj3Mu0K3d4qyc+eaSMono+6BJZIi5JfT3ymgJ5Xwa3W87w5zPgYd+/LVF/wnChgeYYAzCfHZagFQTzxS/wEuWjvNouTf2TbVbgdFRCKPQ9BTTQB+Hrlm8kzqhduNsWlQO9puWd6Zn/A8B+rcae0hrJdKrF7A8NA5N5N/cR9kiri6rJ4m8kJWvrG+zTEBHWcqtDvRj0Yqf29m0XP2IjERFfCwe5W5efIkEk0="
}

TASK [Prepare nodes and clients ports for ambassador] **************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/kubernetes-env-setup.yaml:22
skipping: [localhost] => (item={'organization': None, 'name': 'supplychain', 'country': 'UK', 'state': 'London', 'location': 'London', 'subject': 'O=Orderer,L=51.50/-0.13/London,C=GB', 'type': 'orderer', 'external_url_suffix': 'supplychain-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.supplychain-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'gorilla', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'consensus': {'name': 'raft', 'type': 'broker', 'replicas': 4, 'grpc': {'port': 9092}}, 'orderers': [{'orderer': None, 'name': 'orderer3', 'type': 'orderer', 'consensus': 'raft', 'grpc': {'port': 7050}}]}})  => {
    "ansible_loop_var": "organizationItem",
    "changed": false,
    "organizationItem": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.supplychain-net:7054"
        },
        "cloud_provider": "azure",
        "country": "UK",
        "external_url_suffix": "supplychain-net.svc.cluster.local",
        "gitops": {
            "branch": "gorilla",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "supplychain",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net",
                "type": "ca"
            },
            "consensus": {
                "grpc": {
                    "port": 9092
                },
                "name": "raft",
                "replicas": 4,
                "type": "broker"
            },
            "orderers": [
                {
                    "consensus": "raft",
                    "grpc": {
                        "port": 7050
                    },
                    "name": "orderer3",
                    "orderer": null,
                    "type": "orderer"
                }
            ]
        },
        "state": "London",
        "subject": "O=Orderer,L=51.50/-0.13/London,C=GB",
        "type": "orderer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'organization': None, 'name': 'carrier', 'country': 'GB', 'state': 'London', 'location': 'London', 'subject': 'O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB', 'type': 'peer', 'external_url_suffix': 'carrier-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.carrier-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'gorilla', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'peers': [{'peer': None, 'name': 'peer0', 'type': 'anchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer0.carrier-net.svc.cluster.local:7051', 'cli': 'enabled', 'grpc': {'port': 7051}, 'events': {'port': 7053}, 'couchdb': {'port': 5984}, 'restserver': {'targetPort': 20001, 'port': 20001}, 'expressapi': {'targetPort': 3000, 'port': 3000}}, {'peer': None, 'name': 'peer1', 'type': 'nonanchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer1.carrier-net.svc.cluster.local:7061', 'cli': 'enabled', 'grpc': {'port': 7061}, 'events': {'port': 7063}, 'couchdb': {'port': 5994}, 'restserver': {'targetPort': 20011, 'port': 20011}, 'expressapi': {'targetPort': 3010, 'port': 3010}}]}})  => {
    "ansible_loop_var": "organizationItem",
    "changed": false,
    "organizationItem": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.carrier-net:7054"
        },
        "cloud_provider": "azure",
        "country": "GB",
        "external_url_suffix": "carrier-net.svc.cluster.local",
        "gitops": {
            "branch": "gorilla",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "carrier",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net",
                "type": "ca"
            },
            "peers": [
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5984
                    },
                    "events": {
                        "port": 7053
                    },
                    "expressapi": {
                        "port": 3000,
                        "targetPort": 3000
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7051
                    },
                    "name": "peer0",
                    "peer": null,
                    "peerAddress": "peer0.carrier-net.svc.cluster.local:7051",
                    "restserver": {
                        "port": 20001,
                        "targetPort": 20001
                    },
                    "type": "anchor"
                },
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5994
                    },
                    "events": {
                        "port": 7063
                    },
                    "expressapi": {
                        "port": 3010,
                        "targetPort": 3010
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7061
                    },
                    "name": "peer1",
                    "peer": null,
                    "peerAddress": "peer1.carrier-net.svc.cluster.local:7061",
                    "restserver": {
                        "port": 20011,
                        "targetPort": 20011
                    },
                    "type": "nonanchor"
                }
            ]
        },
        "state": "London",
        "subject": "O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB",
        "type": "peer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [include_role : setup/ambassador] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/kubernetes-env-setup.yaml:31
skipping: [localhost] => (item={'organization': None, 'name': 'supplychain', 'country': 'UK', 'state': 'London', 'location': 'London', 'subject': 'O=Orderer,L=51.50/-0.13/London,C=GB', 'type': 'orderer', 'external_url_suffix': 'supplychain-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.supplychain-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'gorilla', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'consensus': {'name': 'raft', 'type': 'broker', 'replicas': 4, 'grpc': {'port': 9092}}, 'orderers': [{'orderer': None, 'name': 'orderer3', 'type': 'orderer', 'consensus': 'raft', 'grpc': {'port': 7050}}]}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.supplychain-net:7054"
        },
        "cloud_provider": "azure",
        "country": "UK",
        "external_url_suffix": "supplychain-net.svc.cluster.local",
        "gitops": {
            "branch": "gorilla",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "supplychain",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net",
                "type": "ca"
            },
            "consensus": {
                "grpc": {
                    "port": 9092
                },
                "name": "raft",
                "replicas": 4,
                "type": "broker"
            },
            "orderers": [
                {
                    "consensus": "raft",
                    "grpc": {
                        "port": 7050
                    },
                    "name": "orderer3",
                    "orderer": null,
                    "type": "orderer"
                }
            ]
        },
        "state": "London",
        "subject": "O=Orderer,L=51.50/-0.13/London,C=GB",
        "type": "orderer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'organization': None, 'name': 'carrier', 'country': 'GB', 'state': 'London', 'location': 'London', 'subject': 'O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB', 'type': 'peer', 'external_url_suffix': 'carrier-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.carrier-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'gorilla', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'peers': [{'peer': None, 'name': 'peer0', 'type': 'anchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer0.carrier-net.svc.cluster.local:7051', 'cli': 'enabled', 'grpc': {'port': 7051}, 'events': {'port': 7053}, 'couchdb': {'port': 5984}, 'restserver': {'targetPort': 20001, 'port': 20001}, 'expressapi': {'targetPort': 3000, 'port': 3000}}, {'peer': None, 'name': 'peer1', 'type': 'nonanchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer1.carrier-net.svc.cluster.local:7061', 'cli': 'enabled', 'grpc': {'port': 7061}, 'events': {'port': 7063}, 'couchdb': {'port': 5994}, 'restserver': {'targetPort': 20011, 'port': 20011}, 'expressapi': {'targetPort': 3010, 'port': 3010}}]}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.carrier-net:7054"
        },
        "cloud_provider": "azure",
        "country": "GB",
        "external_url_suffix": "carrier-net.svc.cluster.local",
        "gitops": {
            "branch": "gorilla",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "carrier",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net",
                "type": "ca"
            },
            "peers": [
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5984
                    },
                    "events": {
                        "port": 7053
                    },
                    "expressapi": {
                        "port": 3000,
                        "targetPort": 3000
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7051
                    },
                    "name": "peer0",
                    "peer": null,
                    "peerAddress": "peer0.carrier-net.svc.cluster.local:7051",
                    "restserver": {
                        "port": 20001,
                        "targetPort": 20001
                    },
                    "type": "anchor"
                },
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5994
                    },
                    "events": {
                        "port": 7063
                    },
                    "expressapi": {
                        "port": 3010,
                        "targetPort": 3010
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7061
                    },
                    "name": "peer1",
                    "peer": null,
                    "peerAddress": "peer1.carrier-net.svc.cluster.local:7061",
                    "restserver": {
                        "port": 20011,
                        "targetPort": 20011
                    },
                    "type": "nonanchor"
                }
            ]
        },
        "state": "London",
        "subject": "O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB",
        "type": "peer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [include_role : setup/haproxy-ingress] ************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/kubernetes-env-setup.yaml:45
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [aws-cli : register temporary directory] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : check aws cli] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : download aws cli] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : extract aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:34
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : install aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:44
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : configuring aws] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:52
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : register temporary directory] ***************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : check aws-authenticator] ********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : create bin directory] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : Install aws-authenticator] ******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:24
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : Test Kubernetes connection] *****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:35
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : register temporary directory] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682812.902259-17164-227910659602448 `" && echo ansible-tmp-1604682812.902259-17164-227910659602448="` echo /root/.ansible/tmp/ansible-tmp-1604682812.902259-17164-227910659602448 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp07qb65fq TO /root/.ansible/tmp/ansible-tmp-1604682812.902259-17164-227910659602448/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682812.902259-17164-227910659602448/ /root/.ansible/tmp/ansible-tmp-1604682812.902259-17164-227910659602448/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682812.902259-17164-227910659602448/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682812.902259-17164-227910659602448/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.ohpv4fie",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/helm : check helm] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682813.0845182-17190-143718501017468 `" && echo ansible-tmp-1604682813.0845182-17190-143718501017468="` echo /root/.ansible/tmp/ansible-tmp-1604682813.0845182-17190-143718501017468 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpkzk08vpi TO /root/.ansible/tmp/ansible-tmp-1604682813.0845182-17190-143718501017468/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682813.0845182-17190-143718501017468/ /root/.ansible/tmp/ansible-tmp-1604682813.0845182-17190-143718501017468/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682813.0845182-17190-143718501017468/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682813.0845182-17190-143718501017468/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/helm"
        }
    },
    "stat": {
        "atime": 1603618464.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 78000,
        "charset": "binary",
        "checksum": "5820860e398793a3b0b54449e9b6f9a4a0f35cb9",
        "ctime": 1604239659.0090716,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126511,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618464.0,
        "nlink": 1,
        "path": "/root/bin/helm",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 39936000,
        "uid": 0,
        "version": "2759632516",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/helm : Install helm] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Unzip helm archive] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:37
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Move helm binaries] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:47
skipping: [localhost] => (item=helm)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "helm",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Test helm installation] *************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:58
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682813.4542975-17226-106391519259113 `" && echo ansible-tmp-1604682813.4542975-17226-106391519259113="` echo /root/.ansible/tmp/ansible-tmp-1604682813.4542975-17226-106391519259113 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpdb61_gmc TO /root/.ansible/tmp/ansible-tmp-1604682813.4542975-17226-106391519259113/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682813.4542975-17226-106391519259113/ /root/.ansible/tmp/ansible-tmp-1604682813.4542975-17226-106391519259113/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682813.4542975-17226-106391519259113/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682813.4542975-17226-106391519259113/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "helm",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.052741",
    "end": "2020-11-06 17:13:33.637772",
    "invocation": {
        "module_args": {
            "_raw_params": "helm version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:13:33.585031",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client: v2.16.12+g47f0b88",
    "stdout_lines": [
        "Client: v2.16.12+g47f0b88"
    ]
}

TASK [setup/tiller : Check if Tiller is already installed in the Kubernetes clusters] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682813.700489-17257-59494182538284 `" && echo ansible-tmp-1604682813.700489-17257-59494182538284="` echo /root/.ansible/tmp/ansible-tmp-1604682813.700489-17257-59494182538284 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmph0crvgf_ TO /root/.ansible/tmp/ansible-tmp-1604682813.700489-17257-59494182538284/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682813.700489-17257-59494182538284/ /root/.ansible/tmp/ansible-tmp-1604682813.700489-17257-59494182538284/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682813.700489-17257-59494182538284/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682813.700489-17257-59494182538284/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Create service account for Tiller] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:14
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Apply Tiller RBAC definintion] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Setup tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:47
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Wait for tiller to be ready] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:55

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682814.5209303-17297-151163877783390 `" && echo ansible-tmp-1604682814.5209303-17297-151163877783390="` echo /root/.ansible/tmp/ansible-tmp-1604682814.5209303-17297-151163877783390 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpf8_3fk0p TO /root/.ansible/tmp/ansible-tmp-1604682814.5209303-17297-151163877783390/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682814.5209303-17297-151163877783390/ /root/.ansible/tmp/ansible-tmp-1604682814.5209303-17297-151163877783390/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682814.5209303-17297-151163877783390/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682814.5209303-17297-151163877783390/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/haproxy-ingress : Check if haproxy is already installed] ***********
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682815.1521626-17325-43610625198021 `" && echo ansible-tmp-1604682815.1521626-17325-43610625198021="` echo /root/.ansible/tmp/ansible-tmp-1604682815.1521626-17325-43610625198021 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmppvtiuql3 TO /root/.ansible/tmp/ansible-tmp-1604682815.1521626-17325-43610625198021/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682815.1521626-17325-43610625198021/ /root/.ansible/tmp/ansible-tmp-1604682815.1521626-17325-43610625198021/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682815.1521626-17325-43610625198021/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682815.1521626-17325-43610625198021/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "run = haproxy-ingress"
            ],
            "name": null,
            "namespace": "ingress-controller",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-6ksdw",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106895",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-6ksdw",
                "uid": "8563bc8d-1403-4bd4-aee2-7951da46957d"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000002"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4176a8d9672284d4518d9c6472735301169dbef1f5f96e8543488e1d8cc80b9e",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.66",
                "podIPs": [
                    {
                        "ip": "10.1.0.66"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-cp4vl",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106892",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-cp4vl",
                "uid": "a4be4342-5781-4905-83af-ff731371aca9"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000000"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000000",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4d1866dac0c6f40ce0ecaa88085357e276165bd48a61d29224c7e7e34dee4054",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.4",
                "phase": "Running",
                "podIP": "10.1.0.4",
                "podIPs": [
                    {
                        "ip": "10.1.0.4"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-rwks2",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106888",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-rwks2",
                "uid": "d50d75fe-0b73-48e7-9523-365002cc2784"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000001"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000001",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4ea1edbd8c67e0e8a562d94639105dd6b0066370c17eb29f212680cbd72e578d",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.35",
                "phase": "Running",
                "podIP": "10.1.0.35",
                "podIPs": [
                    {
                        "ip": "10.1.0.35"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        }
    ]
}

TASK [setup/haproxy-ingress : Install HAProxy Ingress controller] **************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/haproxy-ingress : Enable external DNS] *****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:24
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/haproxy-ingress : Disable TLS1.0 for the AWS] **********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:33
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [wait for pods to come up] ************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:42
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [check/helm_component : Wait for Pod flux in ingress-controller] **********
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod flux in ingress-controller] **********
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682816.0066516-17365-112967373044107 `" && echo ansible-tmp-1604682816.0066516-17365-112967373044107="` echo /root/.ansible/tmp/ansible-tmp-1604682816.0066516-17365-112967373044107 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpxrdz0arm TO /root/.ansible/tmp/ansible-tmp-1604682816.0066516-17365-112967373044107/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682816.0066516-17365-112967373044107/ /root/.ansible/tmp/ansible-tmp-1604682816.0066516-17365-112967373044107/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682816.0066516-17365-112967373044107/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682816.0066516-17365-112967373044107/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "run = haproxy-ingress"
            ],
            "name": null,
            "namespace": "ingress-controller",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-6ksdw",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106895",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-6ksdw",
                "uid": "8563bc8d-1403-4bd4-aee2-7951da46957d"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000002"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4176a8d9672284d4518d9c6472735301169dbef1f5f96e8543488e1d8cc80b9e",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.66",
                "podIPs": [
                    {
                        "ip": "10.1.0.66"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-cp4vl",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106892",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-cp4vl",
                "uid": "a4be4342-5781-4905-83af-ff731371aca9"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000000"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000000",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4d1866dac0c6f40ce0ecaa88085357e276165bd48a61d29224c7e7e34dee4054",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.4",
                "phase": "Running",
                "podIP": "10.1.0.4",
                "podIPs": [
                    {
                        "ip": "10.1.0.4"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-rwks2",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106888",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-rwks2",
                "uid": "d50d75fe-0b73-48e7-9523-365002cc2784"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000001"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000001",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4ea1edbd8c67e0e8a562d94639105dd6b0066370c17eb29f212680cbd72e578d",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.35",
                "phase": "Running",
                "podIP": "10.1.0.35",
                "podIPs": [
                    {
                        "ip": "10.1.0.35"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        }
    ]
}

TASK [aws-cli : register temporary directory] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : check aws cli] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : download aws cli] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : extract aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:34
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : install aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:44
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : configuring aws] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:52
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : register temporary directory] ***************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : check aws-authenticator] ********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : create bin directory] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : Install aws-authenticator] ******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:24
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : Test Kubernetes connection] *****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:35
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : register temporary directory] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682816.9348903-17417-199525135123014 `" && echo ansible-tmp-1604682816.9348903-17417-199525135123014="` echo /root/.ansible/tmp/ansible-tmp-1604682816.9348903-17417-199525135123014 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpzeyj4siv TO /root/.ansible/tmp/ansible-tmp-1604682816.9348903-17417-199525135123014/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682816.9348903-17417-199525135123014/ /root/.ansible/tmp/ansible-tmp-1604682816.9348903-17417-199525135123014/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682816.9348903-17417-199525135123014/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682816.9348903-17417-199525135123014/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.tkn6o3iv",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/helm : check helm] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682817.1170213-17443-32158698873269 `" && echo ansible-tmp-1604682817.1170213-17443-32158698873269="` echo /root/.ansible/tmp/ansible-tmp-1604682817.1170213-17443-32158698873269 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp11ak_72f TO /root/.ansible/tmp/ansible-tmp-1604682817.1170213-17443-32158698873269/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682817.1170213-17443-32158698873269/ /root/.ansible/tmp/ansible-tmp-1604682817.1170213-17443-32158698873269/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682817.1170213-17443-32158698873269/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682817.1170213-17443-32158698873269/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/helm"
        }
    },
    "stat": {
        "atime": 1603618464.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 78000,
        "charset": "binary",
        "checksum": "5820860e398793a3b0b54449e9b6f9a4a0f35cb9",
        "ctime": 1604239659.0090716,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126511,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618464.0,
        "nlink": 1,
        "path": "/root/bin/helm",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 39936000,
        "uid": 0,
        "version": "2759632516",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/helm : Install helm] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Unzip helm archive] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:37
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Move helm binaries] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:47
skipping: [localhost] => (item=helm)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "helm",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Test helm installation] *************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:58
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682817.4878128-17479-264472057954942 `" && echo ansible-tmp-1604682817.4878128-17479-264472057954942="` echo /root/.ansible/tmp/ansible-tmp-1604682817.4878128-17479-264472057954942 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpe38th1z4 TO /root/.ansible/tmp/ansible-tmp-1604682817.4878128-17479-264472057954942/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682817.4878128-17479-264472057954942/ /root/.ansible/tmp/ansible-tmp-1604682817.4878128-17479-264472057954942/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682817.4878128-17479-264472057954942/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682817.4878128-17479-264472057954942/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "helm",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.049970",
    "end": "2020-11-06 17:13:37.667631",
    "invocation": {
        "module_args": {
            "_raw_params": "helm version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:13:37.617661",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client: v2.16.12+g47f0b88",
    "stdout_lines": [
        "Client: v2.16.12+g47f0b88"
    ]
}

TASK [setup/tiller : Check if Tiller is already installed in the Kubernetes clusters] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682817.7258763-17510-278648548088345 `" && echo ansible-tmp-1604682817.7258763-17510-278648548088345="` echo /root/.ansible/tmp/ansible-tmp-1604682817.7258763-17510-278648548088345 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmplo_ubdb5 TO /root/.ansible/tmp/ansible-tmp-1604682817.7258763-17510-278648548088345/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682817.7258763-17510-278648548088345/ /root/.ansible/tmp/ansible-tmp-1604682817.7258763-17510-278648548088345/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682817.7258763-17510-278648548088345/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682817.7258763-17510-278648548088345/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Create service account for Tiller] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:14
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Apply Tiller RBAC definintion] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Setup tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:47
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Wait for tiller to be ready] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:55

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682818.5763526-17550-136451720462700 `" && echo ansible-tmp-1604682818.5763526-17550-136451720462700="` echo /root/.ansible/tmp/ansible-tmp-1604682818.5763526-17550-136451720462700 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp3c_carsv TO /root/.ansible/tmp/ansible-tmp-1604682818.5763526-17550-136451720462700/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682818.5763526-17550-136451720462700/ /root/.ansible/tmp/ansible-tmp-1604682818.5763526-17550-136451720462700/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682818.5763526-17550-136451720462700/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682818.5763526-17550-136451720462700/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/haproxy-ingress : Check if haproxy is already installed] ***********
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682819.2121625-17578-32956647559109 `" && echo ansible-tmp-1604682819.2121625-17578-32956647559109="` echo /root/.ansible/tmp/ansible-tmp-1604682819.2121625-17578-32956647559109 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpdnxf__c4 TO /root/.ansible/tmp/ansible-tmp-1604682819.2121625-17578-32956647559109/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682819.2121625-17578-32956647559109/ /root/.ansible/tmp/ansible-tmp-1604682819.2121625-17578-32956647559109/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682819.2121625-17578-32956647559109/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682819.2121625-17578-32956647559109/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "run = haproxy-ingress"
            ],
            "name": null,
            "namespace": "ingress-controller",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-6ksdw",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106895",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-6ksdw",
                "uid": "8563bc8d-1403-4bd4-aee2-7951da46957d"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000002"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4176a8d9672284d4518d9c6472735301169dbef1f5f96e8543488e1d8cc80b9e",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.66",
                "podIPs": [
                    {
                        "ip": "10.1.0.66"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-cp4vl",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106892",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-cp4vl",
                "uid": "a4be4342-5781-4905-83af-ff731371aca9"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000000"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000000",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4d1866dac0c6f40ce0ecaa88085357e276165bd48a61d29224c7e7e34dee4054",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.4",
                "phase": "Running",
                "podIP": "10.1.0.4",
                "podIPs": [
                    {
                        "ip": "10.1.0.4"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-rwks2",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106888",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-rwks2",
                "uid": "d50d75fe-0b73-48e7-9523-365002cc2784"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000001"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000001",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4ea1edbd8c67e0e8a562d94639105dd6b0066370c17eb29f212680cbd72e578d",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.35",
                "phase": "Running",
                "podIP": "10.1.0.35",
                "podIPs": [
                    {
                        "ip": "10.1.0.35"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        }
    ]
}

TASK [setup/haproxy-ingress : Install HAProxy Ingress controller] **************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/haproxy-ingress : Enable external DNS] *****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:24
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/haproxy-ingress : Disable TLS1.0 for the AWS] **********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:33
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [wait for pods to come up] ************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:42

TASK [check/helm_component : Wait for Pod flux in ingress-controller] **********
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod flux in ingress-controller] **********
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682820.0442014-17618-189965629597354 `" && echo ansible-tmp-1604682820.0442014-17618-189965629597354="` echo /root/.ansible/tmp/ansible-tmp-1604682820.0442014-17618-189965629597354 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpy5d1o0xy TO /root/.ansible/tmp/ansible-tmp-1604682820.0442014-17618-189965629597354/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682820.0442014-17618-189965629597354/ /root/.ansible/tmp/ansible-tmp-1604682820.0442014-17618-189965629597354/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682820.0442014-17618-189965629597354/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682820.0442014-17618-189965629597354/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "run = haproxy-ingress"
            ],
            "name": null,
            "namespace": "ingress-controller",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-6ksdw",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106895",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-6ksdw",
                "uid": "8563bc8d-1403-4bd4-aee2-7951da46957d"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000002"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4176a8d9672284d4518d9c6472735301169dbef1f5f96e8543488e1d8cc80b9e",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.66",
                "podIPs": [
                    {
                        "ip": "10.1.0.66"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-cp4vl",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106892",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-cp4vl",
                "uid": "a4be4342-5781-4905-83af-ff731371aca9"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000000"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000000",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4d1866dac0c6f40ce0ecaa88085357e276165bd48a61d29224c7e7e34dee4054",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.4",
                "phase": "Running",
                "podIP": "10.1.0.4",
                "podIPs": [
                    {
                        "ip": "10.1.0.4"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-rwks2",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106888",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-rwks2",
                "uid": "d50d75fe-0b73-48e7-9523-365002cc2784"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000001"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000001",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4ea1edbd8c67e0e8a562d94639105dd6b0066370c17eb29f212680cbd72e578d",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.35",
                "phase": "Running",
                "podIP": "10.1.0.35",
                "podIPs": [
                    {
                        "ip": "10.1.0.35"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        }
    ]
}
META: ran handlers
META: ran handlers

PLAY [ansible_provisioners] ****************************************************
META: ran handlers

TASK [Remove build directory] **************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/deploy-network.yaml:16
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682820.6947799-17647-244799827397763 `" && echo ansible-tmp-1604682820.6947799-17647-244799827397763="` echo /root/.ansible/tmp/ansible-tmp-1604682820.6947799-17647-244799827397763 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpnmsvxx4m TO /root/.ansible/tmp/ansible-tmp-1604682820.6947799-17647-244799827397763/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682820.6947799-17647-244799827397763/ /root/.ansible/tmp/ansible-tmp-1604682820.6947799-17647-244799827397763/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682820.6947799-17647-244799827397763/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682820.6947799-17647-244799827397763/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "./build",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "absent",
            "unsafe_writes": false
        }
    },
    "path": "./build",
    "state": "absent"
}

TASK [include_role : create/namespace_vaultauth] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/deploy-network.yaml:22

TASK [Checking if the namespace supplychain-net already exists] ****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:6
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Check Namespace supplychain-net is created] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:7
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682821.2553694-17677-64586044065162 `" && echo ansible-tmp-1604682821.2553694-17677-64586044065162="` echo /root/.ansible/tmp/ansible-tmp-1604682821.2553694-17677-64586044065162 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp_phzditi TO /root/.ansible/tmp/ansible-tmp-1604682821.2553694-17677-64586044065162/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682821.2553694-17677-64586044065162/ /root/.ansible/tmp/ansible-tmp-1604682821.2553694-17677-64586044065162/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682821.2553694-17677-64586044065162/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682821.2553694-17677-64586044065162/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "Namespace",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "supplychain-net",
            "namespace": null,
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": []
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for Namespace supplychain-net] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:17
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for Namespace supplychain-net] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:32
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for Namespace supplychain-net] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:45
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create/namespace_vaultauth : Set Variable] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:17
ok: [localhost] => {
    "ansible_facts": {
        "get_namespace": {
            "changed": false,
            "failed": false,
            "resources": []
        }
    },
    "changed": false
}

TASK [Create namespaces] *******************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:24

TASK [k8_component : Ensures orderer dir exists] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682822.0561414-17715-270896261707421 `" && echo ansible-tmp-1604682822.0561414-17715-270896261707421="` echo /root/.ansible/tmp/ansible-tmp-1604682822.0561414-17715-270896261707421 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpz554qwbf TO /root/.ansible/tmp/ansible-tmp-1604682822.0561414-17715-270896261707421/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682822.0561414-17715-270896261707421/ /root/.ansible/tmp/ansible-tmp-1604682822.0561414-17715-270896261707421/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682822.0561414-17715-270896261707421/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682822.0561414-17715-270896261707421/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
            "state": "directory"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
            "state": "absent"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [k8_component : create namespace file for orderer] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:15
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686 `" && echo ansible-tmp-1604682822.2641027-17741-23409360973686="` echo /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpezmk1j2g TO /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/ /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpyzfygkpt/namespace_component.tpl TO /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/ /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/source && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/copy.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpa0let8bl TO /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/AnsiballZ_copy.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/ /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "checksum": "764a9d412ee8c0bb2dcd3c55cdb72e2d1ff9d691",
    "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/namespace.yaml",
    "diff": [],
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_original_basename": "namespace_component.tpl",
            "attributes": null,
            "backup": false,
            "checksum": "764a9d412ee8c0bb2dcd3c55cdb72e2d1ff9d691",
            "content": null,
            "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/namespace.yaml",
            "directory_mode": null,
            "follow": false,
            "force": true,
            "group": null,
            "local_follow": null,
            "mode": null,
            "owner": null,
            "remote_src": null,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/source",
            "unsafe_writes": false,
            "validate": null
        }
    },
    "md5sum": "cf1425b79e968b40d5e1e2117e221f20",
    "mode": "0644",
    "owner": "root",
    "size": 64,
    "src": "/root/.ansible/tmp/ansible-tmp-1604682822.2641027-17741-23409360973686/source",
    "state": "file",
    "uid": 0
}

TASK [Create vault reviewer service account for Organizations] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:38

TASK [k8_component : Ensures orderer dir exists] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682822.9560227-17783-271144263882356 `" && echo ansible-tmp-1604682822.9560227-17783-271144263882356="` echo /root/.ansible/tmp/ansible-tmp-1604682822.9560227-17783-271144263882356 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp5y_v1qxo TO /root/.ansible/tmp/ansible-tmp-1604682822.9560227-17783-271144263882356/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682822.9560227-17783-271144263882356/ /root/.ansible/tmp/ansible-tmp-1604682822.9560227-17783-271144263882356/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682822.9560227-17783-271144263882356/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682822.9560227-17783-271144263882356/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [k8_component : create vault-reviewer file for orderer] *******************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:15
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801 `" && echo ansible-tmp-1604682823.1574957-17809-64072236351801="` echo /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp_h8ao823 TO /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/ /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpaq84i5jy/reviewer.tpl TO /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/ /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/source && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/copy.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpczxjrsyo TO /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/AnsiballZ_copy.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/ /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "checksum": "9d128be9605e45ba4716f4ba8a39ae745f14db79",
    "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vault-reviewer.yaml",
    "diff": [],
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_original_basename": "reviewer.tpl",
            "attributes": null,
            "backup": false,
            "checksum": "9d128be9605e45ba4716f4ba8a39ae745f14db79",
            "content": null,
            "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vault-reviewer.yaml",
            "directory_mode": null,
            "follow": false,
            "force": true,
            "group": null,
            "local_follow": null,
            "mode": null,
            "owner": null,
            "remote_src": null,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/source",
            "unsafe_writes": false,
            "validate": null
        }
    },
    "md5sum": "c5daec1c3c097342e8e412880e157dd4",
    "mode": "0644",
    "owner": "root",
    "size": 97,
    "src": "/root/.ansible/tmp/ansible-tmp-1604682823.1574957-17809-64072236351801/source",
    "state": "file",
    "uid": 0
}

TASK [Create vault auth service account for Organizations] *********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:52

TASK [k8_component : Ensures orderer dir exists] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682823.555967-17851-124845635529577 `" && echo ansible-tmp-1604682823.555967-17851-124845635529577="` echo /root/.ansible/tmp/ansible-tmp-1604682823.555967-17851-124845635529577 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp6a5fv347 TO /root/.ansible/tmp/ansible-tmp-1604682823.555967-17851-124845635529577/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682823.555967-17851-124845635529577/ /root/.ansible/tmp/ansible-tmp-1604682823.555967-17851-124845635529577/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682823.555967-17851-124845635529577/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682823.555967-17851-124845635529577/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [k8_component : create vaultAuth file for orderer] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:15
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087 `" && echo ansible-tmp-1604682823.761762-17877-166835106980087="` echo /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp2xxxct42 TO /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/ /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp0hmevo11/vault_auth.tpl TO /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/ /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/source && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/copy.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpv4p42cgy TO /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/AnsiballZ_copy.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/ /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "checksum": "a1900901e2836334aa654bf71990b01c437a0557",
    "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vaultAuth.yaml",
    "diff": [],
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_original_basename": "vault_auth.tpl",
            "attributes": null,
            "backup": false,
            "checksum": "a1900901e2836334aa654bf71990b01c437a0557",
            "content": null,
            "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vaultAuth.yaml",
            "directory_mode": null,
            "follow": false,
            "force": true,
            "group": null,
            "local_follow": null,
            "mode": null,
            "owner": null,
            "remote_src": null,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/source",
            "unsafe_writes": false,
            "validate": null
        }
    },
    "md5sum": "07219cd1d901d8c368736759bd1f8b18",
    "mode": "0644",
    "owner": "root",
    "size": 93,
    "src": "/root/.ansible/tmp/ansible-tmp-1604682823.761762-17877-166835106980087/source",
    "state": "file",
    "uid": 0
}

TASK [Create clusterrolebinding for Ordrers] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:66

TASK [k8_component : Ensures orderer dir exists] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682824.1603274-17919-210646710094277 `" && echo ansible-tmp-1604682824.1603274-17919-210646710094277="` echo /root/.ansible/tmp/ansible-tmp-1604682824.1603274-17919-210646710094277 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpxb3v0wbk TO /root/.ansible/tmp/ansible-tmp-1604682824.1603274-17919-210646710094277/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682824.1603274-17919-210646710094277/ /root/.ansible/tmp/ansible-tmp-1604682824.1603274-17919-210646710094277/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682824.1603274-17919-210646710094277/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682824.1603274-17919-210646710094277/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [k8_component : create reviewer_rbac file for orderer] ********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:15
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448 `" && echo ansible-tmp-1604682824.363228-17946-99504100524448="` echo /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp881lqbiy TO /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/ /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpfwgjmzcl/reviewer_rbac.tpl TO /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/ /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/source && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/copy.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpm83e3ahf TO /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/AnsiballZ_copy.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/ /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "checksum": "a367bfe0512ceff5f1b8540d1fe765d8ddb132f1",
    "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/reviewer_rbac.yaml",
    "diff": [],
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_original_basename": "reviewer_rbac.tpl",
            "attributes": null,
            "backup": false,
            "checksum": "a367bfe0512ceff5f1b8540d1fe765d8ddb132f1",
            "content": null,
            "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/reviewer_rbac.yaml",
            "directory_mode": null,
            "follow": false,
            "force": true,
            "group": null,
            "local_follow": null,
            "mode": null,
            "owner": null,
            "remote_src": null,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/source",
            "unsafe_writes": false,
            "validate": null
        }
    },
    "md5sum": "e260abafd7db9e5d5765a4c9a8db9574",
    "mode": "0644",
    "owner": "root",
    "size": 332,
    "src": "/root/.ansible/tmp/ansible-tmp-1604682824.363228-17946-99504100524448/source",
    "state": "file",
    "uid": 0
}

TASK [Git Push] ****************************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:74

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/git_push : Check if directory: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../ exists] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/git_push/tasks/main.yaml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682824.7638972-17988-183669120919760 `" && echo ansible-tmp-1604682824.7638972-17988-183669120919760="` echo /root/.ansible/tmp/ansible-tmp-1604682824.7638972-17988-183669120919760 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpfbv7kdy1 TO /root/.ansible/tmp/ansible-tmp-1604682824.7638972-17988-183669120919760/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682824.7638972-17988-183669120919760/ /root/.ansible/tmp/ansible-tmp-1604682824.7638972-17988-183669120919760/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682824.7638972-17988-183669120919760/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682824.7638972-17988-183669120919760/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/git_push : Execute git push via shell task] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/git_push/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682824.9696503-18014-245351558340477 `" && echo ansible-tmp-1604682824.9696503-18014-245351558340477="` echo /root/.ansible/tmp/ansible-tmp-1604682824.9696503-18014-245351558340477 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmptf6a6gck TO /root/.ansible/tmp/ansible-tmp-1604682824.9696503-18014-245351558340477/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682824.9696503-18014-245351558340477/ /root/.ansible/tmp/ansible-tmp-1604682824.9696503-18014-245351558340477/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682824.9696503-18014-245351558340477/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682824.9696503-18014-245351558340477/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "cmd": "cd \"/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../\"\necho \"---------------SHOW CONTENT OF DIR---------------\"\nls -a\necho \"---------------GIT PUSH---------------\"\ngit config user.email s.unil18031992@gmail.com\ngit config user.name bafsunsu\ngit --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git add -A .\n\n# To ignore a directory add it add reset path\nreset_path=platforms/hyperledger-fabric/configuration\nif [ -n \"$reset_path\" ]; then\n    git --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git reset \"platforms/hyperledger-fabric/configuration\"\nfi  \n\ngit --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git commit -s -m \"[ci skip] Pushing deployment files for namespace, service accounts and clusterrolebinding\" || true\ngit --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git push https://bafsunsu:bafsunsu2020@github.com/bafsunsu/blockchain-automation-framework.git HEAD:gorilla\n",
    "delta": "0:00:08.626269",
    "end": "2020-11-06 17:13:53.725652",
    "invocation": {
        "module_args": {
            "_raw_params": "cd \"/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../\"\necho \"---------------SHOW CONTENT OF DIR---------------\"\nls -a\necho \"---------------GIT PUSH---------------\"\ngit config user.email s.unil18031992@gmail.com\ngit config user.name bafsunsu\ngit --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git add -A .\n\n# To ignore a directory add it add reset path\nreset_path=platforms/hyperledger-fabric/configuration\nif [ -n \"$reset_path\" ]; then\n    git --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git reset \"platforms/hyperledger-fabric/configuration\"\nfi  \n\ngit --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git commit -s -m \"[ci skip] Pushing deployment files for namespace, service accounts and clusterrolebinding\" || true\ngit --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git push https://bafsunsu:bafsunsu2020@github.com/bafsunsu/blockchain-automation-framework.git HEAD:gorilla\n",
            "_uses_shell": true,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:13:45.099383",
    "stderr": "To https://github.com/bafsunsu/blockchain-automation-framework.git\n   df629035..d02eb2e0  HEAD -> gorilla",
    "stderr_lines": [
        "To https://github.com/bafsunsu/blockchain-automation-framework.git",
        "   df629035..d02eb2e0  HEAD -> gorilla"
    ],
    "stdout": "---------------SHOW CONTENT OF DIR---------------\n.\n..\n.circleci\n.git\n.github\n.gitignore\n.travis.yml\nCODEOWNERS\nCODE_OF_CONDUCT.md\nCONTRIBUTING.md\nDockerfile\nLICENSE\nMAINTAINERS.md\nREADME.md\nautomation\nbuild\nconsole.out\ndocs\nexamples\nplatforms\nrelease-notes.md\nreset.sh\nrun.sh\n---------------GIT PUSH---------------\n[gorilla d02eb2e0] [ci skip] Pushing deployment files for namespace, service accounts and clusterrolebinding\n 5 files changed, 544 insertions(+), 1257 deletions(-)\n create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/namespace.yaml\n create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/reviewer_rbac.yaml\n create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vault-reviewer.yaml\n create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vaultAuth.yaml",
    "stdout_lines": [
        "---------------SHOW CONTENT OF DIR---------------",
        ".",
        "..",
        ".circleci",
        ".git",
        ".github",
        ".gitignore",
        ".travis.yml",
        "CODEOWNERS",
        "CODE_OF_CONDUCT.md",
        "CONTRIBUTING.md",
        "Dockerfile",
        "LICENSE",
        "MAINTAINERS.md",
        "README.md",
        "automation",
        "build",
        "console.out",
        "docs",
        "examples",
        "platforms",
        "release-notes.md",
        "reset.sh",
        "run.sh",
        "---------------GIT PUSH---------------",
        "[gorilla d02eb2e0] [ci skip] Pushing deployment files for namespace, service accounts and clusterrolebinding",
        " 5 files changed, 544 insertions(+), 1257 deletions(-)",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/namespace.yaml",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/reviewer_rbac.yaml",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vault-reviewer.yaml",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vaultAuth.yaml"
    ]
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/git_push : Output for gitpush] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/git_push/tasks/main.yaml:32
ok: [localhost] => {
    "msg": [
        "---------------SHOW CONTENT OF DIR---------------",
        ".",
        "..",
        ".circleci",
        ".git",
        ".github",
        ".gitignore",
        ".travis.yml",
        "CODEOWNERS",
        "CODE_OF_CONDUCT.md",
        "CONTRIBUTING.md",
        "Dockerfile",
        "LICENSE",
        "MAINTAINERS.md",
        "README.md",
        "automation",
        "build",
        "console.out",
        "docs",
        "examples",
        "platforms",
        "release-notes.md",
        "reset.sh",
        "run.sh",
        "---------------GIT PUSH---------------",
        "[gorilla d02eb2e0] [ci skip] Pushing deployment files for namespace, service accounts and clusterrolebinding",
        " 5 files changed, 544 insertions(+), 1257 deletions(-)",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/namespace.yaml",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/reviewer_rbac.yaml",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vault-reviewer.yaml",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vaultAuth.yaml"
    ]
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/git_push : Error for git_push] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/git_push/tasks/main.yaml:37
ok: [localhost] => {
    "msg": [
        "To https://github.com/bafsunsu/blockchain-automation-framework.git",
        "   df629035..d02eb2e0  HEAD -> gorilla"
    ]
}

TASK [Checking for the supplychain-net-role-tokenreview-binding] ***************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:90
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Check ClusterRoleBinding supplychain-net-role-tokenreview-binding is created] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:7
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ClusterRoleBinding supplychain-net-role-tokenreview-binding] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:17
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682833.9657352-18066-178634764220256 `" && echo ansible-tmp-1604682833.9657352-18066-178634764220256="` echo /root/.ansible/tmp/ansible-tmp-1604682833.9657352-18066-178634764220256 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpjrq197l0 TO /root/.ansible/tmp/ansible-tmp-1604682833.9657352-18066-178634764220256/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682833.9657352-18066-178634764220256/ /root/.ansible/tmp/ansible-tmp-1604682833.9657352-18066-178634764220256/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682833.9657352-18066-178634764220256/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682833.9657352-18066-178634764220256/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ClusterRoleBinding",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "supplychain-net-role-tokenreview-binding",
            "namespace": null,
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "rbac.authorization.k8s.io/v1",
            "kind": "ClusterRoleBinding",
            "metadata": {
                "annotations": {
                    "fluxcd.io/sync-checksum": "e8e69174d8fae5811887caa7cabb9236d45efc2d",
                    "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"rbac.authorization.k8s.io/v1beta1\",\"kind\":\"ClusterRoleBinding\",\"metadata\":{\"annotations\":{\"fluxcd.io/sync-checksum\":\"e8e69174d8fae5811887caa7cabb9236d45efc2d\"},\"labels\":{\"fluxcd.io/sync-gc-mark\":\"sha256.ELKV0kW2GiS34476-0RLg5-XmvhPpQ7_f7G3we-rJHw\"},\"name\":\"supplychain-net-role-tokenreview-binding\"},\"roleRef\":{\"apiGroup\":\"rbac.authorization.k8s.io\",\"kind\":\"ClusterRole\",\"name\":\"system:auth-delegator\"},\"subjects\":[{\"kind\":\"ServiceAccount\",\"name\":\"vault-reviewer\",\"namespace\":\"supplychain-net\"}]}\n"
                },
                "creationTimestamp": "2020-10-28T06:59:47Z",
                "labels": {
                    "fluxcd.io/sync-gc-mark": "sha256.ELKV0kW2GiS34476-0RLg5-XmvhPpQ7_f7G3we-rJHw"
                },
                "name": "supplychain-net-role-tokenreview-binding",
                "resourceVersion": "1990397",
                "selfLink": "/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/supplychain-net-role-tokenreview-binding",
                "uid": "b89aea82-0494-441d-9a22-9cf0de129356"
            },
            "roleRef": {
                "apiGroup": "rbac.authorization.k8s.io",
                "kind": "ClusterRole",
                "name": "system:auth-delegator"
            },
            "subjects": [
                {
                    "kind": "ServiceAccount",
                    "name": "vault-reviewer",
                    "namespace": "supplychain-net"
                }
            ]
        }
    ]
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ClusterRoleBinding supplychain-net-role-tokenreview-binding] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:32
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ClusterRoleBinding supplychain-net-role-tokenreview-binding] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:45
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Including the check for ServiceAccount vault-reviewer in supplychain-net] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:103
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Check ServiceAccount vault-reviewer is created] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:7
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ServiceAccount vault-reviewer] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:17
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ServiceAccount vault-reviewer] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:32
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ServiceAccount vault-reviewer] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:45
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682834.8340871-18106-12190702610983 `" && echo ansible-tmp-1604682834.8340871-18106-12190702610983="` echo /root/.ansible/tmp/ansible-tmp-1604682834.8340871-18106-12190702610983 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpcoyp5q_g TO /root/.ansible/tmp/ansible-tmp-1604682834.8340871-18106-12190702610983/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682834.8340871-18106-12190702610983/ /root/.ansible/tmp/ansible-tmp-1604682834.8340871-18106-12190702610983/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682834.8340871-18106-12190702610983/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682834.8340871-18106-12190702610983/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (20 retries left).Result was: {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682870.4468038-18106-112179132697151 `" && echo ansible-tmp-1604682870.4468038-18106-112179132697151="` echo /root/.ansible/tmp/ansible-tmp-1604682870.4468038-18106-112179132697151 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpb3w_8prq TO /root/.ansible/tmp/ansible-tmp-1604682870.4468038-18106-112179132697151/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682870.4468038-18106-112179132697151/ /root/.ansible/tmp/ansible-tmp-1604682870.4468038-18106-112179132697151/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682870.4468038-18106-112179132697151/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682870.4468038-18106-112179132697151/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (19 retries left).Result was: {
    "attempts": 2,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682906.090052-18106-29057681398634 `" && echo ansible-tmp-1604682906.090052-18106-29057681398634="` echo /root/.ansible/tmp/ansible-tmp-1604682906.090052-18106-29057681398634 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp4vjsok12 TO /root/.ansible/tmp/ansible-tmp-1604682906.090052-18106-29057681398634/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682906.090052-18106-29057681398634/ /root/.ansible/tmp/ansible-tmp-1604682906.090052-18106-29057681398634/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682906.090052-18106-29057681398634/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682906.090052-18106-29057681398634/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (18 retries left).Result was: {
    "attempts": 3,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682941.7581537-18106-264838547389109 `" && echo ansible-tmp-1604682941.7581537-18106-264838547389109="` echo /root/.ansible/tmp/ansible-tmp-1604682941.7581537-18106-264838547389109 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpjg5c8rdd TO /root/.ansible/tmp/ansible-tmp-1604682941.7581537-18106-264838547389109/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682941.7581537-18106-264838547389109/ /root/.ansible/tmp/ansible-tmp-1604682941.7581537-18106-264838547389109/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682941.7581537-18106-264838547389109/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682941.7581537-18106-264838547389109/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 4,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "ServiceAccount",
            "metadata": {
                "annotations": {
                    "fluxcd.io/sync-checksum": "1815564976fa3e9356fc8e55f0ca4c4187b7724d",
                    "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"v1\",\"kind\":\"ServiceAccount\",\"metadata\":{\"annotations\":{\"fluxcd.io/sync-checksum\":\"1815564976fa3e9356fc8e55f0ca4c4187b7724d\"},\"labels\":{\"fluxcd.io/sync-gc-mark\":\"sha256.nR0gwSfcHUhLFn2neHnc5VBkQnBX78wX83yvlm7Fyac\"},\"name\":\"vault-reviewer\",\"namespace\":\"supplychain-net\"}}\n"
                },
                "creationTimestamp": "2020-11-06T17:15:17Z",
                "labels": {
                    "fluxcd.io/sync-gc-mark": "sha256.nR0gwSfcHUhLFn2neHnc5VBkQnBX78wX83yvlm7Fyac"
                },
                "name": "vault-reviewer",
                "namespace": "supplychain-net",
                "resourceVersion": "2492142",
                "selfLink": "/api/v1/namespaces/supplychain-net/serviceaccounts/vault-reviewer",
                "uid": "7a19f095-b23f-451b-b9b8-a273525e2961"
            },
            "secrets": [
                {
                    "name": "vault-reviewer-token-m99kq"
                }
            ]
        }
    ]
}

TASK [Including the check for ServiceAccount vault-auth in supplychain-net] ****
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:115
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Check ServiceAccount vault-auth is created] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:7
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ServiceAccount vault-auth] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:17
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ServiceAccount vault-auth] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:32
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ServiceAccount vault-auth] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:45
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682942.5686038-18220-184351382430797 `" && echo ansible-tmp-1604682942.5686038-18220-184351382430797="` echo /root/.ansible/tmp/ansible-tmp-1604682942.5686038-18220-184351382430797 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpk2_rmtkf TO /root/.ansible/tmp/ansible-tmp-1604682942.5686038-18220-184351382430797/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682942.5686038-18220-184351382430797/ /root/.ansible/tmp/ansible-tmp-1604682942.5686038-18220-184351382430797/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682942.5686038-18220-184351382430797/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682942.5686038-18220-184351382430797/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-auth",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "ServiceAccount",
            "metadata": {
                "annotations": {
                    "fluxcd.io/sync-checksum": "c3d1e3a475c54a9b0e0a6e51942fe67b14347ea4",
                    "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"v1\",\"kind\":\"ServiceAccount\",\"metadata\":{\"annotations\":{\"fluxcd.io/sync-checksum\":\"c3d1e3a475c54a9b0e0a6e51942fe67b14347ea4\"},\"labels\":{\"fluxcd.io/sync-gc-mark\":\"sha256.gqsW7haM_LtBsf54n4XL-xtUvGuCWTqFoHOix48CXdA\"},\"name\":\"vault-auth\",\"namespace\":\"supplychain-net\"}}\n"
                },
                "creationTimestamp": "2020-11-06T17:15:17Z",
                "labels": {
                    "fluxcd.io/sync-gc-mark": "sha256.gqsW7haM_LtBsf54n4XL-xtUvGuCWTqFoHOix48CXdA"
                },
                "name": "vault-auth",
                "namespace": "supplychain-net",
                "resourceVersion": "2492140",
                "selfLink": "/api/v1/namespaces/supplychain-net/serviceaccounts/vault-auth",
                "uid": "c02475d5-3a49-4f24-819a-a77cfbf2775f"
            },
            "secrets": [
                {
                    "name": "vault-auth-token-f8c2f"
                }
            ]
        }
    ]
}

TASK [Checking if the namespace carrier-net already exists] ********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:6

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Check Namespace carrier-net is created] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:7
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682943.2779834-18250-195327281806781 `" && echo ansible-tmp-1604682943.2779834-18250-195327281806781="` echo /root/.ansible/tmp/ansible-tmp-1604682943.2779834-18250-195327281806781 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpzavmkqm2 TO /root/.ansible/tmp/ansible-tmp-1604682943.2779834-18250-195327281806781/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682943.2779834-18250-195327281806781/ /root/.ansible/tmp/ansible-tmp-1604682943.2779834-18250-195327281806781/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682943.2779834-18250-195327281806781/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682943.2779834-18250-195327281806781/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "Namespace",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "carrier-net",
            "namespace": null,
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": []
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for Namespace carrier-net] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:17
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for Namespace carrier-net] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:32
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for Namespace carrier-net] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:45
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create/namespace_vaultauth : Set Variable] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:17
ok: [localhost] => {
    "ansible_facts": {
        "get_namespace": {
            "changed": false,
            "failed": false,
            "resources": []
        }
    },
    "changed": false
}

TASK [Create namespaces] *******************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:24

TASK [k8_component : Ensures peer dir exists] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682944.0769083-18288-177389193123389 `" && echo ansible-tmp-1604682944.0769083-18288-177389193123389="` echo /root/.ansible/tmp/ansible-tmp-1604682944.0769083-18288-177389193123389 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp4x2wcrc7 TO /root/.ansible/tmp/ansible-tmp-1604682944.0769083-18288-177389193123389/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682944.0769083-18288-177389193123389/ /root/.ansible/tmp/ansible-tmp-1604682944.0769083-18288-177389193123389/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682944.0769083-18288-177389193123389/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682944.0769083-18288-177389193123389/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer",
            "state": "directory"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer",
            "state": "absent"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [k8_component : create namespace file for peer] ***************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:15
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019 `" && echo ansible-tmp-1604682944.2805505-18314-52047241728019="` echo /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpp9849py8 TO /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/ /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp_ydyy6_p/namespace_component.tpl TO /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/ /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/source && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/copy.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpq318ueqd TO /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/AnsiballZ_copy.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/ /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "checksum": "160f8992bcfbf52ddf8ec40b36a5efa86c32ef83",
    "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer/namespace.yaml",
    "diff": [],
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_original_basename": "namespace_component.tpl",
            "attributes": null,
            "backup": false,
            "checksum": "160f8992bcfbf52ddf8ec40b36a5efa86c32ef83",
            "content": null,
            "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer/namespace.yaml",
            "directory_mode": null,
            "follow": false,
            "force": true,
            "group": null,
            "local_follow": null,
            "mode": null,
            "owner": null,
            "remote_src": null,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/source",
            "unsafe_writes": false,
            "validate": null
        }
    },
    "md5sum": "87aff577d25e325fac79903302d07758",
    "mode": "0644",
    "owner": "root",
    "size": 60,
    "src": "/root/.ansible/tmp/ansible-tmp-1604682944.2805505-18314-52047241728019/source",
    "state": "file",
    "uid": 0
}

TASK [Create vault reviewer service account for Organizations] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:38

TASK [k8_component : Ensures peer dir exists] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682944.6774182-18356-127032310493102 `" && echo ansible-tmp-1604682944.6774182-18356-127032310493102="` echo /root/.ansible/tmp/ansible-tmp-1604682944.6774182-18356-127032310493102 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpow2j99te TO /root/.ansible/tmp/ansible-tmp-1604682944.6774182-18356-127032310493102/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682944.6774182-18356-127032310493102/ /root/.ansible/tmp/ansible-tmp-1604682944.6774182-18356-127032310493102/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682944.6774182-18356-127032310493102/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682944.6774182-18356-127032310493102/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [k8_component : create vault-reviewer file for peer] **********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:15
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069 `" && echo ansible-tmp-1604682944.8803918-18382-84323505888069="` echo /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp_wegba39 TO /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/ /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmphxn2nfc6/reviewer.tpl TO /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/ /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/source && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/copy.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpw7656qzj TO /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/AnsiballZ_copy.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/ /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "checksum": "c1efc6b2276d3bcf1ae2801acda84fad126b4e1e",
    "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer/vault-reviewer.yaml",
    "diff": [],
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_original_basename": "reviewer.tpl",
            "attributes": null,
            "backup": false,
            "checksum": "c1efc6b2276d3bcf1ae2801acda84fad126b4e1e",
            "content": null,
            "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer/vault-reviewer.yaml",
            "directory_mode": null,
            "follow": false,
            "force": true,
            "group": null,
            "local_follow": null,
            "mode": null,
            "owner": null,
            "remote_src": null,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/source",
            "unsafe_writes": false,
            "validate": null
        }
    },
    "md5sum": "9749a00045b3fd05c025cc29e7eabfb1",
    "mode": "0644",
    "owner": "root",
    "size": 93,
    "src": "/root/.ansible/tmp/ansible-tmp-1604682944.8803918-18382-84323505888069/source",
    "state": "file",
    "uid": 0
}

TASK [Create vault auth service account for Organizations] *********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:52

TASK [k8_component : Ensures peer dir exists] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682945.2781296-18424-228215283107974 `" && echo ansible-tmp-1604682945.2781296-18424-228215283107974="` echo /root/.ansible/tmp/ansible-tmp-1604682945.2781296-18424-228215283107974 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmppczhmpeh TO /root/.ansible/tmp/ansible-tmp-1604682945.2781296-18424-228215283107974/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682945.2781296-18424-228215283107974/ /root/.ansible/tmp/ansible-tmp-1604682945.2781296-18424-228215283107974/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682945.2781296-18424-228215283107974/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682945.2781296-18424-228215283107974/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [k8_component : create vaultAuth file for peer] ***************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:15
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820 `" && echo ansible-tmp-1604682945.5192785-18450-56507783651820="` echo /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmphpwz7s9g TO /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/ /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpp5rqb3_s/vault_auth.tpl TO /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/ /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/source && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/copy.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpldkxv053 TO /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/AnsiballZ_copy.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/ /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "checksum": "d39874ba996a2494812a782b78453e995845be6b",
    "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer/vaultAuth.yaml",
    "diff": [],
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_original_basename": "vault_auth.tpl",
            "attributes": null,
            "backup": false,
            "checksum": "d39874ba996a2494812a782b78453e995845be6b",
            "content": null,
            "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer/vaultAuth.yaml",
            "directory_mode": null,
            "follow": false,
            "force": true,
            "group": null,
            "local_follow": null,
            "mode": null,
            "owner": null,
            "remote_src": null,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/source",
            "unsafe_writes": false,
            "validate": null
        }
    },
    "md5sum": "603f99cf710abd04581efdc563a6074a",
    "mode": "0644",
    "owner": "root",
    "size": 89,
    "src": "/root/.ansible/tmp/ansible-tmp-1604682945.5192785-18450-56507783651820/source",
    "state": "file",
    "uid": 0
}

TASK [Create clusterrolebinding for Ordrers] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:66

TASK [k8_component : Ensures peer dir exists] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682945.917094-18492-113474145716252 `" && echo ansible-tmp-1604682945.917094-18492-113474145716252="` echo /root/.ansible/tmp/ansible-tmp-1604682945.917094-18492-113474145716252 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpb9o4mowf TO /root/.ansible/tmp/ansible-tmp-1604682945.917094-18492-113474145716252/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682945.917094-18492-113474145716252/ /root/.ansible/tmp/ansible-tmp-1604682945.917094-18492-113474145716252/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682945.917094-18492-113474145716252/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682945.917094-18492-113474145716252/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [k8_component : create reviewer_rbac file for peer] ***********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:15
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385 `" && echo ansible-tmp-1604682946.1189497-18518-43776187649385="` echo /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpnhduts51 TO /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/ /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpqe90ksgr/reviewer_rbac.tpl TO /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/ /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/source && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/copy.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpq6nvfrql TO /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/AnsiballZ_copy.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/ /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "checksum": "a78b1b2becfd8b36bd59970cbcdef0602b6f25cc",
    "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer/reviewer_rbac.yaml",
    "diff": [],
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_original_basename": "reviewer_rbac.tpl",
            "attributes": null,
            "backup": false,
            "checksum": "a78b1b2becfd8b36bd59970cbcdef0602b6f25cc",
            "content": null,
            "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/carrier/peer/reviewer_rbac.yaml",
            "directory_mode": null,
            "follow": false,
            "force": true,
            "group": null,
            "local_follow": null,
            "mode": null,
            "owner": null,
            "remote_src": null,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/source",
            "unsafe_writes": false,
            "validate": null
        }
    },
    "md5sum": "cdea783ba12108f490d72ae42abb8b05",
    "mode": "0644",
    "owner": "root",
    "size": 324,
    "src": "/root/.ansible/tmp/ansible-tmp-1604682946.1189497-18518-43776187649385/source",
    "state": "file",
    "uid": 0
}

TASK [Git Push] ****************************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:74

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/git_push : Check if directory: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../ exists] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/git_push/tasks/main.yaml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682946.509562-18560-85615411355973 `" && echo ansible-tmp-1604682946.509562-18560-85615411355973="` echo /root/.ansible/tmp/ansible-tmp-1604682946.509562-18560-85615411355973 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmpdyc3nx53 TO /root/.ansible/tmp/ansible-tmp-1604682946.509562-18560-85615411355973/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682946.509562-18560-85615411355973/ /root/.ansible/tmp/ansible-tmp-1604682946.509562-18560-85615411355973/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682946.509562-18560-85615411355973/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682946.509562-18560-85615411355973/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/git_push : Execute git push via shell task] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/git_push/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682946.7075121-18586-218407388103814 `" && echo ansible-tmp-1604682946.7075121-18586-218407388103814="` echo /root/.ansible/tmp/ansible-tmp-1604682946.7075121-18586-218407388103814 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-15593su2eaa1a/tmp_486kzn_ TO /root/.ansible/tmp/ansible-tmp-1604682946.7075121-18586-218407388103814/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682946.7075121-18586-218407388103814/ /root/.ansible/tmp/ansible-tmp-1604682946.7075121-18586-218407388103814/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682946.7075121-18586-218407388103814/AnsiballZ_command.py && sleep 0'

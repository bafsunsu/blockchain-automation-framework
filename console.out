ansible-playbook 2.10.2
  config file = None
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.6/dist-packages/ansible
  executable location = /usr/local/bin/ansible-playbook
  python version = 3.6.9 (default, Oct  8 2020, 12:12:24) [GCC 8.4.0]
No config file found; using defaults
host_list declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
script declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
auto declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
Parsed /etc/ansible/hosts inventory source with ini plugin

PLAYBOOK: site.yaml ************************************************************
16 plays in platforms/shared/configuration/site.yaml

PLAY [all] *********************************************************************
META: ran handlers
META: ran handlers
META: ran handlers

PLAY [ansible_provisioners] ****************************************************

TASK [Gathering Facts] *********************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:7
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682141.217055-10159-277734497642446 `" && echo ansible-tmp-1604682141.217055-10159-277734497642446="` echo /root/.ansible/tmp/ansible-tmp-1604682141.217055-10159-277734497642446 `" ) && sleep 0'
<localhost> Attempting python interpreter discovery
<localhost> EXEC /bin/sh -c 'echo PLATFORM; uname; echo FOUND; command -v '"'"'/usr/bin/python'"'"'; command -v '"'"'python3.7'"'"'; command -v '"'"'python3.6'"'"'; command -v '"'"'python3.5'"'"'; command -v '"'"'python2.7'"'"'; command -v '"'"'python2.6'"'"'; command -v '"'"'/usr/libexec/platform-python'"'"'; command -v '"'"'/usr/bin/python3'"'"'; command -v '"'"'python'"'"'; echo ENDFOUND && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3.6 && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/setup.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp4s0360lj TO /root/.ansible/tmp/ansible-tmp-1604682141.217055-10159-277734497642446/AnsiballZ_setup.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682141.217055-10159-277734497642446/ /root/.ansible/tmp/ansible-tmp-1604682141.217055-10159-277734497642446/AnsiballZ_setup.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682141.217055-10159-277734497642446/AnsiballZ_setup.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682141.217055-10159-277734497642446/ > /dev/null 2>&1 && sleep 0'
ok: [localhost]
META: ran handlers

TASK [include_role : setup/kubectl] ********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:10

TASK [setup/kubectl : register temporary directory] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682142.1476266-10211-10181745912933 `" && echo ansible-tmp-1604682142.1476266-10211-10181745912933="` echo /root/.ansible/tmp/ansible-tmp-1604682142.1476266-10211-10181745912933 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp2ldls28a TO /root/.ansible/tmp/ansible-tmp-1604682142.1476266-10211-10181745912933/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682142.1476266-10211-10181745912933/ /root/.ansible/tmp/ansible-tmp-1604682142.1476266-10211-10181745912933/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682142.1476266-10211-10181745912933/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682142.1476266-10211-10181745912933/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.fg97kdl_",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/kubectl : check kubectl] *******************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682142.4689224-10237-144834792027357 `" && echo ansible-tmp-1604682142.4689224-10237-144834792027357="` echo /root/.ansible/tmp/ansible-tmp-1604682142.4689224-10237-144834792027357 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpvr4bof8p TO /root/.ansible/tmp/ansible-tmp-1604682142.4689224-10237-144834792027357/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682142.4689224-10237-144834792027357/ /root/.ansible/tmp/ansible-tmp-1604682142.4689224-10237-144834792027357/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682142.4689224-10237-144834792027357/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682142.4689224-10237-144834792027357/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/kubectl"
        }
    },
    "stat": {
        "atime": 1603618462.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 83992,
        "charset": "binary",
        "checksum": "fe0bcf142cabb39a09ab46440d797bd85d7fa838",
        "ctime": 1604239658.6170657,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126502,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618462.0,
        "nlink": 1,
        "path": "/root/bin/kubectl",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 43003904,
        "uid": 0,
        "version": "1156023499",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/kubectl : Download kubectl binary] *********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : Unarchive kubernetes-client] *****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : create bin directory] ************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:33
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : Copy kubectl binary to destination directory] ************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:41
skipping: [localhost] => (item=kubectl)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "kubectl",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : Test kubectl installation] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:55
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682142.9607012-10273-135204311361674 `" && echo ansible-tmp-1604682142.9607012-10273-135204311361674="` echo /root/.ansible/tmp/ansible-tmp-1604682142.9607012-10273-135204311361674 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpoyhgvc2e TO /root/.ansible/tmp/ansible-tmp-1604682142.9607012-10273-135204311361674/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682142.9607012-10273-135204311361674/ /root/.ansible/tmp/ansible-tmp-1604682142.9607012-10273-135204311361674/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682142.9607012-10273-135204311361674/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682142.9607012-10273-135204311361674/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "kubectl",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.053459",
    "end": "2020-11-06 17:02:23.291157",
    "invocation": {
        "module_args": {
            "_raw_params": "kubectl version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:02:23.237698",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client Version: v1.19.0",
    "stdout_lines": [
        "Client Version: v1.19.0"
    ]
}

TASK [setup/kubectl : register temporary directory] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682143.341645-10304-185687418804747 `" && echo ansible-tmp-1604682143.341645-10304-185687418804747="` echo /root/.ansible/tmp/ansible-tmp-1604682143.341645-10304-185687418804747 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpjaj50owp TO /root/.ansible/tmp/ansible-tmp-1604682143.341645-10304-185687418804747/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682143.341645-10304-185687418804747/ /root/.ansible/tmp/ansible-tmp-1604682143.341645-10304-185687418804747/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682143.341645-10304-185687418804747/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682143.341645-10304-185687418804747/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.3yyudf3_",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/kubectl : check kubectl] *******************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682143.5203414-10330-135508117068460 `" && echo ansible-tmp-1604682143.5203414-10330-135508117068460="` echo /root/.ansible/tmp/ansible-tmp-1604682143.5203414-10330-135508117068460 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpwl4_cmw5 TO /root/.ansible/tmp/ansible-tmp-1604682143.5203414-10330-135508117068460/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682143.5203414-10330-135508117068460/ /root/.ansible/tmp/ansible-tmp-1604682143.5203414-10330-135508117068460/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682143.5203414-10330-135508117068460/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682143.5203414-10330-135508117068460/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/kubectl"
        }
    },
    "stat": {
        "atime": 1603618462.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 83992,
        "charset": "binary",
        "checksum": "fe0bcf142cabb39a09ab46440d797bd85d7fa838",
        "ctime": 1604239658.6170657,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126502,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618462.0,
        "nlink": 1,
        "path": "/root/bin/kubectl",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 43003904,
        "uid": 0,
        "version": "1156023499",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/kubectl : Download kubectl binary] *********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : Unarchive kubernetes-client] *****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : create bin directory] ************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:33
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : Copy kubectl binary to destination directory] ************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:41
skipping: [localhost] => (item=kubectl)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "kubectl",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/kubectl : Test kubectl installation] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:55
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682143.9129071-10366-31177500197967 `" && echo ansible-tmp-1604682143.9129071-10366-31177500197967="` echo /root/.ansible/tmp/ansible-tmp-1604682143.9129071-10366-31177500197967 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpu8oh9dtr TO /root/.ansible/tmp/ansible-tmp-1604682143.9129071-10366-31177500197967/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682143.9129071-10366-31177500197967/ /root/.ansible/tmp/ansible-tmp-1604682143.9129071-10366-31177500197967/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682143.9129071-10366-31177500197967/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682143.9129071-10366-31177500197967/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "kubectl",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.050116",
    "end": "2020-11-06 17:02:24.093285",
    "invocation": {
        "module_args": {
            "_raw_params": "kubectl version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:02:24.043169",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client Version: v1.19.0",
    "stdout_lines": [
        "Client Version: v1.19.0"
    ]
}

TASK [include_role : setup/helm] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:20

TASK [setup/helm : register temporary directory] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682144.2236848-10399-13870376300820 `" && echo ansible-tmp-1604682144.2236848-10399-13870376300820="` echo /root/.ansible/tmp/ansible-tmp-1604682144.2236848-10399-13870376300820 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmplokfba6v TO /root/.ansible/tmp/ansible-tmp-1604682144.2236848-10399-13870376300820/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682144.2236848-10399-13870376300820/ /root/.ansible/tmp/ansible-tmp-1604682144.2236848-10399-13870376300820/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682144.2236848-10399-13870376300820/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682144.2236848-10399-13870376300820/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.3l07pn7n",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/helm : check helm] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682144.406171-10425-102417712131134 `" && echo ansible-tmp-1604682144.406171-10425-102417712131134="` echo /root/.ansible/tmp/ansible-tmp-1604682144.406171-10425-102417712131134 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpr0_gyq4b TO /root/.ansible/tmp/ansible-tmp-1604682144.406171-10425-102417712131134/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682144.406171-10425-102417712131134/ /root/.ansible/tmp/ansible-tmp-1604682144.406171-10425-102417712131134/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682144.406171-10425-102417712131134/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682144.406171-10425-102417712131134/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/helm"
        }
    },
    "stat": {
        "atime": 1603618464.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 78000,
        "charset": "binary",
        "checksum": "5820860e398793a3b0b54449e9b6f9a4a0f35cb9",
        "ctime": 1604239659.0090716,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126511,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618464.0,
        "nlink": 1,
        "path": "/root/bin/helm",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 39936000,
        "uid": 0,
        "version": "2759632516",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/helm : Install helm] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Unzip helm archive] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:37
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Move helm binaries] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:47
skipping: [localhost] => (item=helm)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "helm",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Test helm installation] *************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:58
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682144.7545326-10461-13247964576005 `" && echo ansible-tmp-1604682144.7545326-10461-13247964576005="` echo /root/.ansible/tmp/ansible-tmp-1604682144.7545326-10461-13247964576005 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpvfcynzqt TO /root/.ansible/tmp/ansible-tmp-1604682144.7545326-10461-13247964576005/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682144.7545326-10461-13247964576005/ /root/.ansible/tmp/ansible-tmp-1604682144.7545326-10461-13247964576005/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682144.7545326-10461-13247964576005/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682144.7545326-10461-13247964576005/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "helm",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.056581",
    "end": "2020-11-06 17:02:24.940434",
    "invocation": {
        "module_args": {
            "_raw_params": "helm version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:02:24.883853",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client: v2.16.12+g47f0b88",
    "stdout_lines": [
        "Client: v2.16.12+g47f0b88"
    ]
}

TASK [setup/helm : register temporary directory] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682144.9871752-10492-176766793984044 `" && echo ansible-tmp-1604682144.9871752-10492-176766793984044="` echo /root/.ansible/tmp/ansible-tmp-1604682144.9871752-10492-176766793984044 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp78wrb97g TO /root/.ansible/tmp/ansible-tmp-1604682144.9871752-10492-176766793984044/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682144.9871752-10492-176766793984044/ /root/.ansible/tmp/ansible-tmp-1604682144.9871752-10492-176766793984044/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682144.9871752-10492-176766793984044/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682144.9871752-10492-176766793984044/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.5unk7d2c",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/helm : check helm] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682145.167075-10518-138106332845320 `" && echo ansible-tmp-1604682145.167075-10518-138106332845320="` echo /root/.ansible/tmp/ansible-tmp-1604682145.167075-10518-138106332845320 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpdu_4wd2j TO /root/.ansible/tmp/ansible-tmp-1604682145.167075-10518-138106332845320/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682145.167075-10518-138106332845320/ /root/.ansible/tmp/ansible-tmp-1604682145.167075-10518-138106332845320/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682145.167075-10518-138106332845320/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682145.167075-10518-138106332845320/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/helm"
        }
    },
    "stat": {
        "atime": 1603618464.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 78000,
        "charset": "binary",
        "checksum": "5820860e398793a3b0b54449e9b6f9a4a0f35cb9",
        "ctime": 1604239659.0090716,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126511,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618464.0,
        "nlink": 1,
        "path": "/root/bin/helm",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 39936000,
        "uid": 0,
        "version": "2759632516",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/helm : Install helm] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Unzip helm archive] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:37
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Move helm binaries] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:47
skipping: [localhost] => (item=helm)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "helm",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Test helm installation] *************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:58
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682145.511214-10554-195587695802279 `" && echo ansible-tmp-1604682145.511214-10554-195587695802279="` echo /root/.ansible/tmp/ansible-tmp-1604682145.511214-10554-195587695802279 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpp8iv7_27 TO /root/.ansible/tmp/ansible-tmp-1604682145.511214-10554-195587695802279/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682145.511214-10554-195587695802279/ /root/.ansible/tmp/ansible-tmp-1604682145.511214-10554-195587695802279/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682145.511214-10554-195587695802279/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682145.511214-10554-195587695802279/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "helm",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.053988",
    "end": "2020-11-06 17:02:25.695650",
    "invocation": {
        "module_args": {
            "_raw_params": "helm version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:02:25.641662",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client: v2.16.12+g47f0b88",
    "stdout_lines": [
        "Client: v2.16.12+g47f0b88"
    ]
}

TASK [include_role : setup/vault] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:30

TASK [setup/vault : register temporary directory] ******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/vault/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682145.7995784-10587-88370663441079 `" && echo ansible-tmp-1604682145.7995784-10587-88370663441079="` echo /root/.ansible/tmp/ansible-tmp-1604682145.7995784-10587-88370663441079 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp94ibmli2 TO /root/.ansible/tmp/ansible-tmp-1604682145.7995784-10587-88370663441079/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682145.7995784-10587-88370663441079/ /root/.ansible/tmp/ansible-tmp-1604682145.7995784-10587-88370663441079/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682145.7995784-10587-88370663441079/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682145.7995784-10587-88370663441079/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.nc1ujs2f",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/vault : check vault] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/vault/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682145.9797292-10613-35617940103696 `" && echo ansible-tmp-1604682145.9797292-10613-35617940103696="` echo /root/.ansible/tmp/ansible-tmp-1604682145.9797292-10613-35617940103696 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp1jahio_9 TO /root/.ansible/tmp/ansible-tmp-1604682145.9797292-10613-35617940103696/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682145.9797292-10613-35617940103696/ /root/.ansible/tmp/ansible-tmp-1604682145.9797292-10613-35617940103696/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682145.9797292-10613-35617940103696/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682145.9797292-10613-35617940103696/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/vault"
        }
    },
    "stat": {
        "atime": 1603618466.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 270632,
        "charset": "binary",
        "checksum": "b1cacaa735c4406d1f47a6937e9329a38a842ede",
        "ctime": 1604239660.105088,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126520,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618466.0,
        "nlink": 1,
        "path": "/root/bin/vault",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 138561023,
        "uid": 0,
        "version": "2790310722",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/vault : Install vault client] **************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/vault/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/vault : create bin directory] **************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/vault/tasks/main.yaml:26
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/vault : Unzip vault archive] ***************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/vault/tasks/main.yaml:34
skipping: [localhost] => (item=vault)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "vault",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/vault : Test vault installation] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/vault/tasks/main.yaml:46
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682146.439884-10647-144659719654747 `" && echo ansible-tmp-1604682146.439884-10647-144659719654747="` echo /root/.ansible/tmp/ansible-tmp-1604682146.439884-10647-144659719654747 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpw6ure23w TO /root/.ansible/tmp/ansible-tmp-1604682146.439884-10647-144659719654747/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682146.439884-10647-144659719654747/ /root/.ansible/tmp/ansible-tmp-1604682146.439884-10647-144659719654747/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682146.439884-10647-144659719654747/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682146.439884-10647-144659719654747/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "vault",
        "version"
    ],
    "delta": "0:00:00.031159",
    "end": "2020-11-06 17:02:26.601885",
    "invocation": {
        "module_args": {
            "_raw_params": "vault version",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:02:26.570726",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Vault v1.5.5 (f5d1ddb3750e7c28e25036e1ef26a4c02379fc01)",
    "stdout_lines": [
        "Vault v1.5.5 (f5d1ddb3750e7c28e25036e1ef26a4c02379fc01)"
    ]
}

TASK [include_role : setup/aws-cli] ********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:40
skipping: [localhost] => (item={'organization': None, 'name': 'supplychain', 'country': 'UK', 'state': 'London', 'location': 'London', 'subject': 'O=Orderer,L=51.50/-0.13/London,C=GB', 'type': 'orderer', 'external_url_suffix': 'supplychain-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.supplychain-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'oreo', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'consensus': {'name': 'raft', 'type': 'broker', 'replicas': 4, 'grpc': {'port': 9092}}, 'orderers': [{'orderer': None, 'name': 'orderer3', 'type': 'orderer', 'consensus': 'raft', 'grpc': {'port': 7050}}]}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.supplychain-net:7054"
        },
        "cloud_provider": "azure",
        "country": "UK",
        "external_url_suffix": "supplychain-net.svc.cluster.local",
        "gitops": {
            "branch": "oreo",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "supplychain",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net",
                "type": "ca"
            },
            "consensus": {
                "grpc": {
                    "port": 9092
                },
                "name": "raft",
                "replicas": 4,
                "type": "broker"
            },
            "orderers": [
                {
                    "consensus": "raft",
                    "grpc": {
                        "port": 7050
                    },
                    "name": "orderer3",
                    "orderer": null,
                    "type": "orderer"
                }
            ]
        },
        "state": "London",
        "subject": "O=Orderer,L=51.50/-0.13/London,C=GB",
        "type": "orderer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'organization': None, 'name': 'carrier', 'country': 'GB', 'state': 'London', 'location': 'London', 'subject': 'O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB', 'type': 'peer', 'external_url_suffix': 'carrier-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.carrier-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'oreo', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'peers': [{'peer': None, 'name': 'peer0', 'type': 'anchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer0.carrier-net.svc.cluster.local:7051', 'cli': 'enabled', 'grpc': {'port': 7051}, 'events': {'port': 7053}, 'couchdb': {'port': 5984}, 'restserver': {'targetPort': 20001, 'port': 20001}, 'expressapi': {'targetPort': 3000, 'port': 3000}}, {'peer': None, 'name': 'peer1', 'type': 'nonanchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer1.carrier-net.svc.cluster.local:7061', 'cli': 'enabled', 'grpc': {'port': 7061}, 'events': {'port': 7063}, 'couchdb': {'port': 5994}, 'restserver': {'targetPort': 20011, 'port': 20011}, 'expressapi': {'targetPort': 3010, 'port': 3010}}]}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.carrier-net:7054"
        },
        "cloud_provider": "azure",
        "country": "GB",
        "external_url_suffix": "carrier-net.svc.cluster.local",
        "gitops": {
            "branch": "oreo",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "carrier",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net",
                "type": "ca"
            },
            "peers": [
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5984
                    },
                    "events": {
                        "port": 7053
                    },
                    "expressapi": {
                        "port": 3000,
                        "targetPort": 3000
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7051
                    },
                    "name": "peer0",
                    "peer": null,
                    "peerAddress": "peer0.carrier-net.svc.cluster.local:7051",
                    "restserver": {
                        "port": 20001,
                        "targetPort": 20001
                    },
                    "type": "anchor"
                },
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5994
                    },
                    "events": {
                        "port": 7063
                    },
                    "expressapi": {
                        "port": 3010,
                        "targetPort": 3010
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7061
                    },
                    "name": "peer1",
                    "peer": null,
                    "peerAddress": "peer1.carrier-net.svc.cluster.local:7061",
                    "restserver": {
                        "port": 20011,
                        "targetPort": 20011
                    },
                    "type": "nonanchor"
                }
            ]
        },
        "state": "London",
        "subject": "O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB",
        "type": "peer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [include_role : setup/aws-auth] *******************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:49
skipping: [localhost] => (item={'organization': None, 'name': 'supplychain', 'country': 'UK', 'state': 'London', 'location': 'London', 'subject': 'O=Orderer,L=51.50/-0.13/London,C=GB', 'type': 'orderer', 'external_url_suffix': 'supplychain-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.supplychain-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'oreo', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'consensus': {'name': 'raft', 'type': 'broker', 'replicas': 4, 'grpc': {'port': 9092}}, 'orderers': [{'orderer': None, 'name': 'orderer3', 'type': 'orderer', 'consensus': 'raft', 'grpc': {'port': 7050}}]}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.supplychain-net:7054"
        },
        "cloud_provider": "azure",
        "country": "UK",
        "external_url_suffix": "supplychain-net.svc.cluster.local",
        "gitops": {
            "branch": "oreo",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "supplychain",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net",
                "type": "ca"
            },
            "consensus": {
                "grpc": {
                    "port": 9092
                },
                "name": "raft",
                "replicas": 4,
                "type": "broker"
            },
            "orderers": [
                {
                    "consensus": "raft",
                    "grpc": {
                        "port": 7050
                    },
                    "name": "orderer3",
                    "orderer": null,
                    "type": "orderer"
                }
            ]
        },
        "state": "London",
        "subject": "O=Orderer,L=51.50/-0.13/London,C=GB",
        "type": "orderer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'organization': None, 'name': 'carrier', 'country': 'GB', 'state': 'London', 'location': 'London', 'subject': 'O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB', 'type': 'peer', 'external_url_suffix': 'carrier-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.carrier-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'oreo', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'peers': [{'peer': None, 'name': 'peer0', 'type': 'anchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer0.carrier-net.svc.cluster.local:7051', 'cli': 'enabled', 'grpc': {'port': 7051}, 'events': {'port': 7053}, 'couchdb': {'port': 5984}, 'restserver': {'targetPort': 20001, 'port': 20001}, 'expressapi': {'targetPort': 3000, 'port': 3000}}, {'peer': None, 'name': 'peer1', 'type': 'nonanchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer1.carrier-net.svc.cluster.local:7061', 'cli': 'enabled', 'grpc': {'port': 7061}, 'events': {'port': 7063}, 'couchdb': {'port': 5994}, 'restserver': {'targetPort': 20011, 'port': 20011}, 'expressapi': {'targetPort': 3010, 'port': 3010}}]}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.carrier-net:7054"
        },
        "cloud_provider": "azure",
        "country": "GB",
        "external_url_suffix": "carrier-net.svc.cluster.local",
        "gitops": {
            "branch": "oreo",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "carrier",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net",
                "type": "ca"
            },
            "peers": [
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5984
                    },
                    "events": {
                        "port": 7053
                    },
                    "expressapi": {
                        "port": 3000,
                        "targetPort": 3000
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7051
                    },
                    "name": "peer0",
                    "peer": null,
                    "peerAddress": "peer0.carrier-net.svc.cluster.local:7051",
                    "restserver": {
                        "port": 20001,
                        "targetPort": 20001
                    },
                    "type": "anchor"
                },
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5994
                    },
                    "events": {
                        "port": 7063
                    },
                    "expressapi": {
                        "port": 3010,
                        "targetPort": 3010
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7061
                    },
                    "name": "peer1",
                    "peer": null,
                    "peerAddress": "peer1.carrier-net.svc.cluster.local:7061",
                    "restserver": {
                        "port": 20011,
                        "targetPort": 20011
                    },
                    "type": "nonanchor"
                }
            ]
        },
        "state": "London",
        "subject": "O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB",
        "type": "peer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [include_role : setup/tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/environment-setup.yaml:63
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s to community.kubernetes.k8s
redirecting (type: modules) ansible.builtin.k8s to community.kubernetes.k8s
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s to community.kubernetes.k8s
redirecting (type: modules) ansible.builtin.k8s to community.kubernetes.k8s

TASK [setup/tiller : Check if Tiller is already installed in the Kubernetes clusters] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682146.8641853-10688-122263914154245 `" && echo ansible-tmp-1604682146.8641853-10688-122263914154245="` echo /root/.ansible/tmp/ansible-tmp-1604682146.8641853-10688-122263914154245 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpbv_5ytki TO /root/.ansible/tmp/ansible-tmp-1604682146.8641853-10688-122263914154245/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682146.8641853-10688-122263914154245/ /root/.ansible/tmp/ansible-tmp-1604682146.8641853-10688-122263914154245/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682146.8641853-10688-122263914154245/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682146.8641853-10688-122263914154245/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Create service account for Tiller] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:14
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Apply Tiller RBAC definintion] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Setup tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:47
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Wait for tiller to be ready] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:55
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682147.9214854-10728-20736865578319 `" && echo ansible-tmp-1604682147.9214854-10728-20736865578319="` echo /root/.ansible/tmp/ansible-tmp-1604682147.9214854-10728-20736865578319 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpco0lqfnv TO /root/.ansible/tmp/ansible-tmp-1604682147.9214854-10728-20736865578319/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682147.9214854-10728-20736865578319/ /root/.ansible/tmp/ansible-tmp-1604682147.9214854-10728-20736865578319/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682147.9214854-10728-20736865578319/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682147.9214854-10728-20736865578319/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Check if Tiller is already installed in the Kubernetes clusters] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682148.5770268-10756-247929334247285 `" && echo ansible-tmp-1604682148.5770268-10756-247929334247285="` echo /root/.ansible/tmp/ansible-tmp-1604682148.5770268-10756-247929334247285 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp3vpg57pd TO /root/.ansible/tmp/ansible-tmp-1604682148.5770268-10756-247929334247285/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682148.5770268-10756-247929334247285/ /root/.ansible/tmp/ansible-tmp-1604682148.5770268-10756-247929334247285/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682148.5770268-10756-247929334247285/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682148.5770268-10756-247929334247285/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Create service account for Tiller] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:14
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Apply Tiller RBAC definintion] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Setup tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:47
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Wait for tiller to be ready] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:55

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682149.3994863-10796-152851782146042 `" && echo ansible-tmp-1604682149.3994863-10796-152851782146042="` echo /root/.ansible/tmp/ansible-tmp-1604682149.3994863-10796-152851782146042 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpy6zj6y53 TO /root/.ansible/tmp/ansible-tmp-1604682149.3994863-10796-152851782146042/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682149.3994863-10796-152851782146042/ /root/.ansible/tmp/ansible-tmp-1604682149.3994863-10796-152851782146042/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682149.3994863-10796-152851782146042/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682149.3994863-10796-152851782146042/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}
META: ran handlers
META: ran handlers

PLAY [ansible_provisioners] ****************************************************
META: ran handlers

TASK [include_role : setup/flux] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/kubernetes-env-setup.yaml:11
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s to community.kubernetes.k8s
redirecting (type: modules) ansible.builtin.k8s to community.kubernetes.k8s
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [aws-cli : register temporary directory] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : check aws cli] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : download aws cli] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : extract aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:34
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : install aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:44
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : configuring aws] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:52
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-auth : register temporary directory] *********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check aws-authenticator] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-auth : create bin directory] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Install aws-authenticator] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:24
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-auth : Test Kubernetes connection] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:35
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [helm : register temporary directory] *************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682150.4839602-10851-126947730102980 `" && echo ansible-tmp-1604682150.4839602-10851-126947730102980="` echo /root/.ansible/tmp/ansible-tmp-1604682150.4839602-10851-126947730102980 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpkidjqzsh TO /root/.ansible/tmp/ansible-tmp-1604682150.4839602-10851-126947730102980/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682150.4839602-10851-126947730102980/ /root/.ansible/tmp/ansible-tmp-1604682150.4839602-10851-126947730102980/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682150.4839602-10851-126947730102980/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682150.4839602-10851-126947730102980/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.2n8z89zq",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [check helm] **************************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682150.66906-10877-4521371350818 `" && echo ansible-tmp-1604682150.66906-10877-4521371350818="` echo /root/.ansible/tmp/ansible-tmp-1604682150.66906-10877-4521371350818 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpxrh_3e3l TO /root/.ansible/tmp/ansible-tmp-1604682150.66906-10877-4521371350818/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682150.66906-10877-4521371350818/ /root/.ansible/tmp/ansible-tmp-1604682150.66906-10877-4521371350818/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682150.66906-10877-4521371350818/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682150.66906-10877-4521371350818/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/helm"
        }
    },
    "stat": {
        "atime": 1603618464.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 78000,
        "charset": "binary",
        "checksum": "5820860e398793a3b0b54449e9b6f9a4a0f35cb9",
        "ctime": 1604239659.0090716,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126511,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618464.0,
        "nlink": 1,
        "path": "/root/bin/helm",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 39936000,
        "uid": 0,
        "version": "2759632516",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [Install helm] ************************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Unzip helm archive] ******************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:37
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Move helm binaries] ******************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:47
skipping: [localhost] => (item=helm)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "helm",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Test helm installation] **************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:58
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682151.0304632-10913-268787875004478 `" && echo ansible-tmp-1604682151.0304632-10913-268787875004478="` echo /root/.ansible/tmp/ansible-tmp-1604682151.0304632-10913-268787875004478 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpdx1cbv85 TO /root/.ansible/tmp/ansible-tmp-1604682151.0304632-10913-268787875004478/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682151.0304632-10913-268787875004478/ /root/.ansible/tmp/ansible-tmp-1604682151.0304632-10913-268787875004478/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682151.0304632-10913-268787875004478/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682151.0304632-10913-268787875004478/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "helm",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.054656",
    "end": "2020-11-06 17:02:31.217456",
    "invocation": {
        "module_args": {
            "_raw_params": "helm version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:02:31.162800",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client: v2.16.12+g47f0b88",
    "stdout_lines": [
        "Client: v2.16.12+g47f0b88"
    ]
}

TASK [kubectl : register temporary directory] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682151.2756052-10944-97289780460346 `" && echo ansible-tmp-1604682151.2756052-10944-97289780460346="` echo /root/.ansible/tmp/ansible-tmp-1604682151.2756052-10944-97289780460346 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp3o6nc3wm TO /root/.ansible/tmp/ansible-tmp-1604682151.2756052-10944-97289780460346/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682151.2756052-10944-97289780460346/ /root/.ansible/tmp/ansible-tmp-1604682151.2756052-10944-97289780460346/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682151.2756052-10944-97289780460346/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682151.2756052-10944-97289780460346/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.u1zvn8fs",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [check kubectl] ***********************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682151.4597147-10970-214486810502423 `" && echo ansible-tmp-1604682151.4597147-10970-214486810502423="` echo /root/.ansible/tmp/ansible-tmp-1604682151.4597147-10970-214486810502423 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpb8gthzzt TO /root/.ansible/tmp/ansible-tmp-1604682151.4597147-10970-214486810502423/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682151.4597147-10970-214486810502423/ /root/.ansible/tmp/ansible-tmp-1604682151.4597147-10970-214486810502423/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682151.4597147-10970-214486810502423/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682151.4597147-10970-214486810502423/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/kubectl"
        }
    },
    "stat": {
        "atime": 1603618462.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 83992,
        "charset": "binary",
        "checksum": "fe0bcf142cabb39a09ab46440d797bd85d7fa838",
        "ctime": 1604239658.6170657,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126502,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618462.0,
        "nlink": 1,
        "path": "/root/bin/kubectl",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 43003904,
        "uid": 0,
        "version": "1156023499",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [Download kubectl binary] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [kubectl : Unarchive kubernetes-client] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [kubectl : create bin directory] ******************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:33
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Copy kubectl binary to destination directory] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:41
skipping: [localhost] => (item=kubectl)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "kubectl",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Test kubectl installation] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:55
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682151.8271956-11006-875867034068 `" && echo ansible-tmp-1604682151.8271956-11006-875867034068="` echo /root/.ansible/tmp/ansible-tmp-1604682151.8271956-11006-875867034068 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpd44n436b TO /root/.ansible/tmp/ansible-tmp-1604682151.8271956-11006-875867034068/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682151.8271956-11006-875867034068/ /root/.ansible/tmp/ansible-tmp-1604682151.8271956-11006-875867034068/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682151.8271956-11006-875867034068/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682151.8271956-11006-875867034068/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "kubectl",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.049289",
    "end": "2020-11-06 17:02:32.006726",
    "invocation": {
        "module_args": {
            "_raw_params": "kubectl version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:02:31.957437",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client Version: v1.19.0",
    "stdout_lines": [
        "Client Version: v1.19.0"
    ]
}

TASK [setup/tiller : Check if Tiller is already installed in the Kubernetes clusters] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682152.069632-11037-263107140992618 `" && echo ansible-tmp-1604682152.069632-11037-263107140992618="` echo /root/.ansible/tmp/ansible-tmp-1604682152.069632-11037-263107140992618 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpte9qrnq2 TO /root/.ansible/tmp/ansible-tmp-1604682152.069632-11037-263107140992618/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682152.069632-11037-263107140992618/ /root/.ansible/tmp/ansible-tmp-1604682152.069632-11037-263107140992618/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682152.069632-11037-263107140992618/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682152.069632-11037-263107140992618/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Create service account for Tiller] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:14
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Apply Tiller RBAC definintion] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Setup tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:47
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Wait for tiller to be ready] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:55
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682152.9314861-11077-47596887233278 `" && echo ansible-tmp-1604682152.9314861-11077-47596887233278="` echo /root/.ansible/tmp/ansible-tmp-1604682152.9314861-11077-47596887233278 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp6u0cte9x TO /root/.ansible/tmp/ansible-tmp-1604682152.9314861-11077-47596887233278/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682152.9314861-11077-47596887233278/ /root/.ansible/tmp/ansible-tmp-1604682152.9314861-11077-47596887233278/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682152.9314861-11077-47596887233278/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682152.9314861-11077-47596887233278/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/flux : Check if Flux is running] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682153.5724869-11105-188275255770232 `" && echo ansible-tmp-1604682153.5724869-11105-188275255770232="` echo /root/.ansible/tmp/ansible-tmp-1604682153.5724869-11105-188275255770232 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp11uhv670 TO /root/.ansible/tmp/ansible-tmp-1604682153.5724869-11105-188275255770232/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682153.5724869-11105-188275255770232/ /root/.ansible/tmp/ansible-tmp-1604682153.5724869-11105-188275255770232/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682153.5724869-11105-188275255770232/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682153.5724869-11105-188275255770232/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = flux",
                "release = flux-dev"
            ],
            "name": null,
            "namespace": "default",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": []
}

TASK [setup/flux : Get ssh known hosts] ****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:17
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682154.1802552-11133-113854551809231 `" && echo ansible-tmp-1604682154.1802552-11133-113854551809231="` echo /root/.ansible/tmp/ansible-tmp-1604682154.1802552-11133-113854551809231 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpq8at1kjj TO /root/.ansible/tmp/ansible-tmp-1604682154.1802552-11133-113854551809231/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682154.1802552-11133-113854551809231/ /root/.ansible/tmp/ansible-tmp-1604682154.1802552-11133-113854551809231/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682154.1802552-11133-113854551809231/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682154.1802552-11133-113854551809231/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "cmd": "ssh-keyscan github.com > flux_known_hosts\nchmod -R 777 flux_known_hosts\n",
    "delta": "0:00:00.378117",
    "end": "2020-11-06 17:02:34.688941",
    "invocation": {
        "module_args": {
            "_raw_params": "ssh-keyscan github.com > flux_known_hosts\nchmod -R 777 flux_known_hosts\n",
            "_uses_shell": true,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:02:34.310824",
    "stderr": "# github.com:22 SSH-2.0-babeld-17f526ba\n# github.com:22 SSH-2.0-babeld-17f526ba\n# github.com:22 SSH-2.0-babeld-17f526ba",
    "stderr_lines": [
        "# github.com:22 SSH-2.0-babeld-17f526ba",
        "# github.com:22 SSH-2.0-babeld-17f526ba",
        "# github.com:22 SSH-2.0-babeld-17f526ba"
    ],
    "stdout": "",
    "stdout_lines": []
}

TASK [setup/flux : Helm repo add] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:23
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682154.7449522-11162-98566558208585 `" && echo ansible-tmp-1604682154.7449522-11162-98566558208585="` echo /root/.ansible/tmp/ansible-tmp-1604682154.7449522-11162-98566558208585 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpnoypg6zy TO /root/.ansible/tmp/ansible-tmp-1604682154.7449522-11162-98566558208585/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682154.7449522-11162-98566558208585/ /root/.ansible/tmp/ansible-tmp-1604682154.7449522-11162-98566558208585/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682154.7449522-11162-98566558208585/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682154.7449522-11162-98566558208585/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "cmd": "helm init --client-only && helm repo add fluxcd https://fluxcd.github.io/flux\n",
    "delta": "0:00:00.284168",
    "end": "2020-11-06 17:02:35.170114",
    "invocation": {
        "module_args": {
            "_raw_params": "helm init --client-only && helm repo add fluxcd https://fluxcd.github.io/flux\n",
            "_uses_shell": true,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:02:34.885946",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "$HELM_HOME has been configured at /root/.helm.\nNot installing Tiller due to 'client-only' flag having been set\n\"fluxcd\" has been added to your repositories",
    "stdout_lines": [
        "$HELM_HOME has been configured at /root/.helm.",
        "Not installing Tiller due to 'client-only' flag having been set",
        "\"fluxcd\" has been added to your repositories"
    ]
}

TASK [setup/flux : Install flux] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:30
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682155.238535-11199-156467110964969 `" && echo ansible-tmp-1604682155.238535-11199-156467110964969="` echo /root/.ansible/tmp/ansible-tmp-1604682155.238535-11199-156467110964969 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpaj61d7dx TO /root/.ansible/tmp/ansible-tmp-1604682155.238535-11199-156467110964969/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682155.238535-11199-156467110964969/ /root/.ansible/tmp/ansible-tmp-1604682155.238535-11199-156467110964969/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682155.238535-11199-156467110964969/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682155.238535-11199-156467110964969/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "cmd": "KUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl create secret generic git-auth-dev --from-file=identity=/Users/s0s0dit/project/blockchain-automation-framework/build/gitops --namespace default\nKUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl apply -f /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/../../../platforms/shared/charts/flux-helm-release-crd.yaml --context=\"fabric-aks-dev1\"\nKUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml helm upgrade --install --set rbac.create=true --set helmOperator.create=true --set git.timeout=200s --set git.pollInterval=2m --set git.url='ssh://git@github.com/bafsunsu/blockchain-automation-framework.git' --set git.secretName=git-auth-dev --set git.branch=oreo --set git.label='sync-dev' --set git.path=\"platforms/hyperledger-fabric/releases/dev\" --set-file ssh.known_hosts=flux_known_hosts --set registry.insecureHosts=\"index.docker.io/hyperledgerlabs\" --namespace default flux-dev --version \"0.15.0\" fluxcd/flux --kube-context=\"fabric-aks-dev1\"\n",
    "delta": "0:00:01.685009",
    "end": "2020-11-06 17:02:37.056001",
    "invocation": {
        "module_args": {
            "_raw_params": "KUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl create secret generic git-auth-dev --from-file=identity=/Users/s0s0dit/project/blockchain-automation-framework/build/gitops --namespace default\nKUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl apply -f /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/../../../platforms/shared/charts/flux-helm-release-crd.yaml --context=\"fabric-aks-dev1\"\nKUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml helm upgrade --install --set rbac.create=true --set helmOperator.create=true --set git.timeout=200s --set git.pollInterval=2m --set git.url='ssh://git@github.com/bafsunsu/blockchain-automation-framework.git' --set git.secretName=git-auth-dev --set git.branch=oreo --set git.label='sync-dev' --set git.path=\"platforms/hyperledger-fabric/releases/dev\" --set-file ssh.known_hosts=flux_known_hosts --set registry.insecureHosts=\"index.docker.io/hyperledgerlabs\" --namespace default flux-dev --version \"0.15.0\" fluxcd/flux --kube-context=\"fabric-aks-dev1\"\n",
            "_uses_shell": true,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:02:35.370992",
    "stderr": "Error from server (AlreadyExists): secrets \"git-auth-dev\" already exists",
    "stderr_lines": [
        "Error from server (AlreadyExists): secrets \"git-auth-dev\" already exists"
    ],
    "stdout": "customresourcedefinition.apiextensions.k8s.io/helmreleases.flux.weave.works unchanged\nRelease \"flux-dev\" does not exist. Installing it now.\nNAME:   flux-dev\nLAST DEPLOYED: Fri Nov  6 17:02:36 2020\nNAMESPACE: default\nSTATUS: DEPLOYED\n\nRESOURCES:\n==> v1/ConfigMap\nNAME                  DATA  AGE\nflux-dev-kube-config  1     0s\nflux-dev-ssh-config   1     0s\n\n==> v1/Deployment\nNAME                    READY  UP-TO-DATE  AVAILABLE  AGE\nflux-dev                0/1    1           0          0s\nflux-dev-helm-operator  0/1    1           0          0s\nflux-dev-memcached      0/1    1           0          0s\n\n==> v1/Pod(related)\nNAME                                     READY  STATUS             RESTARTS  AGE\nflux-dev-77c5476976-p7hwf                0/1    ContainerCreating  0         1s\nflux-dev-helm-operator-745dc7fb99-czh6f  0/1    ContainerCreating  0         1s\nflux-dev-memcached-5f689bfdb9-sd9sr      0/1    ContainerCreating  0         1s\n\n==> v1/Service\nNAME                TYPE       CLUSTER-IP   EXTERNAL-IP  PORT(S)    AGE\nflux-dev            ClusterIP  10.0.52.167  <none>       3030/TCP   0s\nflux-dev-memcached  ClusterIP  10.0.139.74  <none>       11211/TCP  0s\n\n==> v1/ServiceAccount\nNAME      SECRETS  AGE\nflux-dev  1        0s\n\n==> v1beta1/ClusterRole\nNAME      AGE\nflux-dev  1s\n\n==> v1beta1/ClusterRoleBinding\nNAME      AGE\nflux-dev  1s\n\n\nNOTES:\nGet the Git deploy key by either (a) running\n\n  kubectl -n default logs deployment/flux-dev | grep identity.pub | cut -d '\"' -f2\n\nor by (b) installing fluxctl through\nhttps://docs.fluxcd.io/en/latest/references/fluxctl.html#installing-fluxctl\nand running:\n\n  fluxctl identity --k8s-fwd-ns default",
    "stdout_lines": [
        "customresourcedefinition.apiextensions.k8s.io/helmreleases.flux.weave.works unchanged",
        "Release \"flux-dev\" does not exist. Installing it now.",
        "NAME:   flux-dev",
        "LAST DEPLOYED: Fri Nov  6 17:02:36 2020",
        "NAMESPACE: default",
        "STATUS: DEPLOYED",
        "",
        "RESOURCES:",
        "==> v1/ConfigMap",
        "NAME                  DATA  AGE",
        "flux-dev-kube-config  1     0s",
        "flux-dev-ssh-config   1     0s",
        "",
        "==> v1/Deployment",
        "NAME                    READY  UP-TO-DATE  AVAILABLE  AGE",
        "flux-dev                0/1    1           0          0s",
        "flux-dev-helm-operator  0/1    1           0          0s",
        "flux-dev-memcached      0/1    1           0          0s",
        "",
        "==> v1/Pod(related)",
        "NAME                                     READY  STATUS             RESTARTS  AGE",
        "flux-dev-77c5476976-p7hwf                0/1    ContainerCreating  0         1s",
        "flux-dev-helm-operator-745dc7fb99-czh6f  0/1    ContainerCreating  0         1s",
        "flux-dev-memcached-5f689bfdb9-sd9sr      0/1    ContainerCreating  0         1s",
        "",
        "==> v1/Service",
        "NAME                TYPE       CLUSTER-IP   EXTERNAL-IP  PORT(S)    AGE",
        "flux-dev            ClusterIP  10.0.52.167  <none>       3030/TCP   0s",
        "flux-dev-memcached  ClusterIP  10.0.139.74  <none>       11211/TCP  0s",
        "",
        "==> v1/ServiceAccount",
        "NAME      SECRETS  AGE",
        "flux-dev  1        0s",
        "",
        "==> v1beta1/ClusterRole",
        "NAME      AGE",
        "flux-dev  1s",
        "",
        "==> v1beta1/ClusterRoleBinding",
        "NAME      AGE",
        "flux-dev  1s",
        "",
        "",
        "NOTES:",
        "Get the Git deploy key by either (a) running",
        "",
        "  kubectl -n default logs deployment/flux-dev | grep identity.pub | cut -d '\"' -f2",
        "",
        "or by (b) installing fluxctl through",
        "https://docs.fluxcd.io/en/latest/references/fluxctl.html#installing-fluxctl",
        "and running:",
        "",
        "  fluxctl identity --k8s-fwd-ns default"
    ]
}

TASK [wait for pods to come up] ************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:40
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [check/helm_component : Wait for Pod flux in default] *********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod flux in default] *********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682157.243959-11248-253099380495603 `" && echo ansible-tmp-1604682157.243959-11248-253099380495603="` echo /root/.ansible/tmp/ansible-tmp-1604682157.243959-11248-253099380495603 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp9ghdhz4y TO /root/.ansible/tmp/ansible-tmp-1604682157.243959-11248-253099380495603/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682157.243959-11248-253099380495603/ /root/.ansible/tmp/ansible-tmp-1604682157.243959-11248-253099380495603/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682157.243959-11248-253099380495603/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682157.243959-11248-253099380495603/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for Pod flux in default (20 retries left).Result was: {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = flux",
                "release = flux-dev"
            ],
            "name": null,
            "namespace": "default",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682187.889201-11248-126491226246688 `" && echo ansible-tmp-1604682187.889201-11248-126491226246688="` echo /root/.ansible/tmp/ansible-tmp-1604682187.889201-11248-126491226246688 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpa6t3w05o TO /root/.ansible/tmp/ansible-tmp-1604682187.889201-11248-126491226246688/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682187.889201-11248-126491226246688/ /root/.ansible/tmp/ansible-tmp-1604682187.889201-11248-126491226246688/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682187.889201-11248-126491226246688/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682187.889201-11248-126491226246688/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 2,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = flux",
                "release = flux-dev"
            ],
            "name": null,
            "namespace": "default",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-11-06T17:02:36Z",
                "generateName": "flux-dev-77c5476976-",
                "labels": {
                    "app": "flux",
                    "pod-template-hash": "77c5476976",
                    "release": "flux-dev"
                },
                "name": "flux-dev-77c5476976-p7hwf",
                "namespace": "default",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "flux-dev-77c5476976",
                        "uid": "d82a46be-3da8-4163-b4cb-0be67d41cdaf"
                    }
                ],
                "resourceVersion": "2490113",
                "selfLink": "/api/v1/namespaces/default/pods/flux-dev-77c5476976-p7hwf",
                "uid": "dee290ed-ceaa-450d-af37-b7a2772cf7ea"
            },
            "spec": {
                "containers": [
                    {
                        "args": [
                            "--log-format=fmt",
                            "--ssh-keygen-dir=/var/fluxd/keygen",
                            "--k8s-secret-name=git-auth-dev",
                            "--memcached-hostname=flux-dev-memcached",
                            "--sync-state=git",
                            "--memcached-service=",
                            "--git-url=ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
                            "--git-branch=oreo",
                            "--git-path=platforms/hyperledger-fabric/releases/dev",
                            "--git-readonly=false",
                            "--git-user=Weave Flux",
                            "--git-email=support@weave.works",
                            "--git-set-author=false",
                            "--git-poll-interval=2m",
                            "--git-timeout=200s",
                            "--sync-interval=2m",
                            "--git-ci-skip=false",
                            "--git-label=sync-dev",
                            "--registry-poll-interval=5m",
                            "--registry-rps=200",
                            "--registry-burst=125",
                            "--registry-trace=false",
                            "--registry-insecure-host=index.docker.io/hyperledgerlabs"
                        ],
                        "env": [
                            {
                                "name": "KUBECONFIG",
                                "value": "/root/.kubectl/config"
                            }
                        ],
                        "image": "docker.io/fluxcd/flux:1.15.0",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/api/flux/v6/identity.pub",
                                "port": 3030,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 5,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 5
                        },
                        "name": "flux",
                        "ports": [
                            {
                                "containerPort": 3030,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/api/flux/v6/identity.pub",
                                "port": 3030,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 5,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 5
                        },
                        "resources": {
                            "requests": {
                                "cpu": "50m",
                                "memory": "64Mi"
                            }
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/root/.kubectl",
                                "name": "kubedir"
                            },
                            {
                                "mountPath": "/root/.ssh",
                                "name": "sshdir",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/etc/fluxd/ssh",
                                "name": "git-key",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/var/fluxd/keygen",
                                "name": "git-keygen"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "flux-dev-token-cc68d",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "flux-dev",
                "serviceAccountName": "flux-dev",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "configMap": {
                            "defaultMode": 420,
                            "name": "flux-dev-kube-config"
                        },
                        "name": "kubedir"
                    },
                    {
                        "configMap": {
                            "defaultMode": 384,
                            "name": "flux-dev-ssh-config"
                        },
                        "name": "sshdir"
                    },
                    {
                        "name": "git-key",
                        "secret": {
                            "defaultMode": 256,
                            "secretName": "git-auth-dev"
                        }
                    },
                    {
                        "emptyDir": {
                            "medium": "Memory"
                        },
                        "name": "git-keygen"
                    },
                    {
                        "name": "flux-dev-token-cc68d",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "flux-dev-token-cc68d"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:02:36Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:02:44Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:02:44Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:02:36Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://137768a5233446262cdf76f7993eed8ba2cd9fa8f66282ea520f2d13ee1c0fa5",
                        "image": "fluxcd/flux:1.15.0",
                        "imageID": "docker-pullable://fluxcd/flux@sha256:ba4bd9ed8ea13ba4aa94d97b6ca285b6f3831fc5861369110dc19f238ac13201",
                        "lastState": {},
                        "name": "flux",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-11-06T17:02:38Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.80",
                "podIPs": [
                    {
                        "ip": "10.1.0.80"
                    }
                ],
                "qosClass": "Burstable",
                "startTime": "2020-11-06T17:02:36Z"
            }
        }
    ]
}

TASK [setup/flux : Get ssh key] ************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:54
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682188.5572524-11302-57739037501420 `" && echo ansible-tmp-1604682188.5572524-11302-57739037501420="` echo /root/.ansible/tmp/ansible-tmp-1604682188.5572524-11302-57739037501420 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmprj3ejp5h TO /root/.ansible/tmp/ansible-tmp-1604682188.5572524-11302-57739037501420/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682188.5572524-11302-57739037501420/ /root/.ansible/tmp/ansible-tmp-1604682188.5572524-11302-57739037501420/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682188.5572524-11302-57739037501420/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682188.5572524-11302-57739037501420/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": "KUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl -n default logs deployment/flux-dev | grep identity.pub | cut -d '\"' -f2\n",
    "delta": "0:00:00.156342",
    "end": "2020-11-06 17:03:08.843494",
    "invocation": {
        "module_args": {
            "_raw_params": "KUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl -n default logs deployment/flux-dev | grep identity.pub | cut -d '\"' -f2\n",
            "_uses_shell": true,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:03:08.687152",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC8ImoOJkm9nhYVB2d6wbBVNW526Q3nEQoeBG0tQTTbQ5F6bFIkfraDGKKxqpRZRPwiSTkcxUbGeWV1xpbX4kuG3NKn8MwFm1LBilEnp8m9t48ID9cIfLe4WESE4KCqmXPXjMK/OFa1Yo1JRd9P/PHVK4mJK1syXAZl0XKhK9gujrStC/EOsRaB/6ToyQeOPPfeWqL/EO8P6a5T1CFerUBc+Mw4lnFa8XEP7ab4q3xZbmuZ+oGt6sFR+/Jzu8kYJAY1j0ASqBU0DbJbUvvDnpEr7sM3DHTLHj3Mu0K3d4qyc+eaSMono+6BJZIi5JfT3ymgJ5Xwa3W87w5zPgYd+/LVF/wnChgeYYAzCfHZagFQTzxS/wEuWjvNouTf2TbVbgdFRCKPQ9BTTQB+Hrlm8kzqhduNsWlQO9puWd6Zn/A8B+rcae0hrJdKrF7A8NA5N5N/cR9kiri6rJ4m8kJWvrG+zTEBHWcqtDvRj0Yqf29m0XP2IjERFfCwe5W5efIkEk0=",
    "stdout_lines": [
        "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC8ImoOJkm9nhYVB2d6wbBVNW526Q3nEQoeBG0tQTTbQ5F6bFIkfraDGKKxqpRZRPwiSTkcxUbGeWV1xpbX4kuG3NKn8MwFm1LBilEnp8m9t48ID9cIfLe4WESE4KCqmXPXjMK/OFa1Yo1JRd9P/PHVK4mJK1syXAZl0XKhK9gujrStC/EOsRaB/6ToyQeOPPfeWqL/EO8P6a5T1CFerUBc+Mw4lnFa8XEP7ab4q3xZbmuZ+oGt6sFR+/Jzu8kYJAY1j0ASqBU0DbJbUvvDnpEr7sM3DHTLHj3Mu0K3d4qyc+eaSMono+6BJZIi5JfT3ymgJ5Xwa3W87w5zPgYd+/LVF/wnChgeYYAzCfHZagFQTzxS/wEuWjvNouTf2TbVbgdFRCKPQ9BTTQB+Hrlm8kzqhduNsWlQO9puWd6Zn/A8B+rcae0hrJdKrF7A8NA5N5N/cR9kiri6rJ4m8kJWvrG+zTEBHWcqtDvRj0Yqf29m0XP2IjERFfCwe5W5efIkEk0="
    ]
}

TASK [setup/flux : Output ssh key] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:60
ok: [localhost] => {
    "ssh_key.stdout": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC8ImoOJkm9nhYVB2d6wbBVNW526Q3nEQoeBG0tQTTbQ5F6bFIkfraDGKKxqpRZRPwiSTkcxUbGeWV1xpbX4kuG3NKn8MwFm1LBilEnp8m9t48ID9cIfLe4WESE4KCqmXPXjMK/OFa1Yo1JRd9P/PHVK4mJK1syXAZl0XKhK9gujrStC/EOsRaB/6ToyQeOPPfeWqL/EO8P6a5T1CFerUBc+Mw4lnFa8XEP7ab4q3xZbmuZ+oGt6sFR+/Jzu8kYJAY1j0ASqBU0DbJbUvvDnpEr7sM3DHTLHj3Mu0K3d4qyc+eaSMono+6BJZIi5JfT3ymgJ5Xwa3W87w5zPgYd+/LVF/wnChgeYYAzCfHZagFQTzxS/wEuWjvNouTf2TbVbgdFRCKPQ9BTTQB+Hrlm8kzqhduNsWlQO9puWd6Zn/A8B+rcae0hrJdKrF7A8NA5N5N/cR9kiri6rJ4m8kJWvrG+zTEBHWcqtDvRj0Yqf29m0XP2IjERFfCwe5W5efIkEk0="
}

TASK [aws-cli : register temporary directory] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : check aws cli] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : download aws cli] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : extract aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:34
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : install aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:44
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : configuring aws] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:52
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-auth : register temporary directory] *********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check aws-authenticator] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-auth : create bin directory] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Install aws-authenticator] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:24
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-auth : Test Kubernetes connection] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:35
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [helm : register temporary directory] *************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682189.2356322-11362-209767476301946 `" && echo ansible-tmp-1604682189.2356322-11362-209767476301946="` echo /root/.ansible/tmp/ansible-tmp-1604682189.2356322-11362-209767476301946 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp85uok7m2 TO /root/.ansible/tmp/ansible-tmp-1604682189.2356322-11362-209767476301946/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682189.2356322-11362-209767476301946/ /root/.ansible/tmp/ansible-tmp-1604682189.2356322-11362-209767476301946/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682189.2356322-11362-209767476301946/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682189.2356322-11362-209767476301946/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.3k0x4763",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [check helm] **************************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682189.415161-11388-172914876694353 `" && echo ansible-tmp-1604682189.415161-11388-172914876694353="` echo /root/.ansible/tmp/ansible-tmp-1604682189.415161-11388-172914876694353 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpvqj3kie8 TO /root/.ansible/tmp/ansible-tmp-1604682189.415161-11388-172914876694353/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682189.415161-11388-172914876694353/ /root/.ansible/tmp/ansible-tmp-1604682189.415161-11388-172914876694353/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682189.415161-11388-172914876694353/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682189.415161-11388-172914876694353/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/helm"
        }
    },
    "stat": {
        "atime": 1603618464.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 78000,
        "charset": "binary",
        "checksum": "5820860e398793a3b0b54449e9b6f9a4a0f35cb9",
        "ctime": 1604239659.0090716,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126511,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618464.0,
        "nlink": 1,
        "path": "/root/bin/helm",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 39936000,
        "uid": 0,
        "version": "2759632516",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [Install helm] ************************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Unzip helm archive] ******************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:37
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Move helm binaries] ******************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:47
skipping: [localhost] => (item=helm)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "helm",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Test helm installation] **************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:58
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682189.7743342-11424-198381270619768 `" && echo ansible-tmp-1604682189.7743342-11424-198381270619768="` echo /root/.ansible/tmp/ansible-tmp-1604682189.7743342-11424-198381270619768 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpkal60e34 TO /root/.ansible/tmp/ansible-tmp-1604682189.7743342-11424-198381270619768/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682189.7743342-11424-198381270619768/ /root/.ansible/tmp/ansible-tmp-1604682189.7743342-11424-198381270619768/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682189.7743342-11424-198381270619768/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682189.7743342-11424-198381270619768/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "helm",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.059688",
    "end": "2020-11-06 17:03:09.964139",
    "invocation": {
        "module_args": {
            "_raw_params": "helm version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:03:09.904451",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client: v2.16.12+g47f0b88",
    "stdout_lines": [
        "Client: v2.16.12+g47f0b88"
    ]
}

TASK [kubectl : register temporary directory] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682190.0198224-11455-261512199816466 `" && echo ansible-tmp-1604682190.0198224-11455-261512199816466="` echo /root/.ansible/tmp/ansible-tmp-1604682190.0198224-11455-261512199816466 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpzlbzgt8w TO /root/.ansible/tmp/ansible-tmp-1604682190.0198224-11455-261512199816466/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682190.0198224-11455-261512199816466/ /root/.ansible/tmp/ansible-tmp-1604682190.0198224-11455-261512199816466/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682190.0198224-11455-261512199816466/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682190.0198224-11455-261512199816466/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.aei7404g",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [check kubectl] ***********************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682190.1999211-11481-10695424369882 `" && echo ansible-tmp-1604682190.1999211-11481-10695424369882="` echo /root/.ansible/tmp/ansible-tmp-1604682190.1999211-11481-10695424369882 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp3cma3mqr TO /root/.ansible/tmp/ansible-tmp-1604682190.1999211-11481-10695424369882/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682190.1999211-11481-10695424369882/ /root/.ansible/tmp/ansible-tmp-1604682190.1999211-11481-10695424369882/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682190.1999211-11481-10695424369882/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682190.1999211-11481-10695424369882/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/kubectl"
        }
    },
    "stat": {
        "atime": 1603618462.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 83992,
        "charset": "binary",
        "checksum": "fe0bcf142cabb39a09ab46440d797bd85d7fa838",
        "ctime": 1604239658.6170657,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126502,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618462.0,
        "nlink": 1,
        "path": "/root/bin/kubectl",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 43003904,
        "uid": 0,
        "version": "1156023499",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [Download kubectl binary] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [kubectl : Unarchive kubernetes-client] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [kubectl : create bin directory] ******************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:33
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Copy kubectl binary to destination directory] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:41
skipping: [localhost] => (item=kubectl)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "kubectl",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Test kubectl installation] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/kubectl/tasks/main.yaml:55
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682190.5692549-11517-106988051102825 `" && echo ansible-tmp-1604682190.5692549-11517-106988051102825="` echo /root/.ansible/tmp/ansible-tmp-1604682190.5692549-11517-106988051102825 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpw9zvfrqi TO /root/.ansible/tmp/ansible-tmp-1604682190.5692549-11517-106988051102825/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682190.5692549-11517-106988051102825/ /root/.ansible/tmp/ansible-tmp-1604682190.5692549-11517-106988051102825/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682190.5692549-11517-106988051102825/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682190.5692549-11517-106988051102825/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "kubectl",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.050653",
    "end": "2020-11-06 17:03:10.753275",
    "invocation": {
        "module_args": {
            "_raw_params": "kubectl version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:03:10.702622",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client Version: v1.19.0",
    "stdout_lines": [
        "Client Version: v1.19.0"
    ]
}

TASK [setup/tiller : Check if Tiller is already installed in the Kubernetes clusters] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682190.815139-11548-119325169502644 `" && echo ansible-tmp-1604682190.815139-11548-119325169502644="` echo /root/.ansible/tmp/ansible-tmp-1604682190.815139-11548-119325169502644 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpoozycn8_ TO /root/.ansible/tmp/ansible-tmp-1604682190.815139-11548-119325169502644/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682190.815139-11548-119325169502644/ /root/.ansible/tmp/ansible-tmp-1604682190.815139-11548-119325169502644/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682190.815139-11548-119325169502644/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682190.815139-11548-119325169502644/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Create service account for Tiller] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:14
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Apply Tiller RBAC definintion] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Setup tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:47
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Wait for tiller to be ready] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:55

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682191.678317-11588-78649206530781 `" && echo ansible-tmp-1604682191.678317-11588-78649206530781="` echo /root/.ansible/tmp/ansible-tmp-1604682191.678317-11588-78649206530781 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpt70mkhcg TO /root/.ansible/tmp/ansible-tmp-1604682191.678317-11588-78649206530781/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682191.678317-11588-78649206530781/ /root/.ansible/tmp/ansible-tmp-1604682191.678317-11588-78649206530781/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682191.678317-11588-78649206530781/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682191.678317-11588-78649206530781/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/flux : Check if Flux is running] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682192.316353-11616-215692685369217 `" && echo ansible-tmp-1604682192.316353-11616-215692685369217="` echo /root/.ansible/tmp/ansible-tmp-1604682192.316353-11616-215692685369217 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpmfd7q3ng TO /root/.ansible/tmp/ansible-tmp-1604682192.316353-11616-215692685369217/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682192.316353-11616-215692685369217/ /root/.ansible/tmp/ansible-tmp-1604682192.316353-11616-215692685369217/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682192.316353-11616-215692685369217/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682192.316353-11616-215692685369217/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = flux",
                "release = flux-dev"
            ],
            "name": null,
            "namespace": "default",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-11-06T17:02:36Z",
                "generateName": "flux-dev-77c5476976-",
                "labels": {
                    "app": "flux",
                    "pod-template-hash": "77c5476976",
                    "release": "flux-dev"
                },
                "name": "flux-dev-77c5476976-p7hwf",
                "namespace": "default",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "flux-dev-77c5476976",
                        "uid": "d82a46be-3da8-4163-b4cb-0be67d41cdaf"
                    }
                ],
                "resourceVersion": "2490113",
                "selfLink": "/api/v1/namespaces/default/pods/flux-dev-77c5476976-p7hwf",
                "uid": "dee290ed-ceaa-450d-af37-b7a2772cf7ea"
            },
            "spec": {
                "containers": [
                    {
                        "args": [
                            "--log-format=fmt",
                            "--ssh-keygen-dir=/var/fluxd/keygen",
                            "--k8s-secret-name=git-auth-dev",
                            "--memcached-hostname=flux-dev-memcached",
                            "--sync-state=git",
                            "--memcached-service=",
                            "--git-url=ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
                            "--git-branch=oreo",
                            "--git-path=platforms/hyperledger-fabric/releases/dev",
                            "--git-readonly=false",
                            "--git-user=Weave Flux",
                            "--git-email=support@weave.works",
                            "--git-set-author=false",
                            "--git-poll-interval=2m",
                            "--git-timeout=200s",
                            "--sync-interval=2m",
                            "--git-ci-skip=false",
                            "--git-label=sync-dev",
                            "--registry-poll-interval=5m",
                            "--registry-rps=200",
                            "--registry-burst=125",
                            "--registry-trace=false",
                            "--registry-insecure-host=index.docker.io/hyperledgerlabs"
                        ],
                        "env": [
                            {
                                "name": "KUBECONFIG",
                                "value": "/root/.kubectl/config"
                            }
                        ],
                        "image": "docker.io/fluxcd/flux:1.15.0",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/api/flux/v6/identity.pub",
                                "port": 3030,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 5,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 5
                        },
                        "name": "flux",
                        "ports": [
                            {
                                "containerPort": 3030,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/api/flux/v6/identity.pub",
                                "port": 3030,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 5,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 5
                        },
                        "resources": {
                            "requests": {
                                "cpu": "50m",
                                "memory": "64Mi"
                            }
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/root/.kubectl",
                                "name": "kubedir"
                            },
                            {
                                "mountPath": "/root/.ssh",
                                "name": "sshdir",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/etc/fluxd/ssh",
                                "name": "git-key",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/var/fluxd/keygen",
                                "name": "git-keygen"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "flux-dev-token-cc68d",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "flux-dev",
                "serviceAccountName": "flux-dev",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "configMap": {
                            "defaultMode": 420,
                            "name": "flux-dev-kube-config"
                        },
                        "name": "kubedir"
                    },
                    {
                        "configMap": {
                            "defaultMode": 384,
                            "name": "flux-dev-ssh-config"
                        },
                        "name": "sshdir"
                    },
                    {
                        "name": "git-key",
                        "secret": {
                            "defaultMode": 256,
                            "secretName": "git-auth-dev"
                        }
                    },
                    {
                        "emptyDir": {
                            "medium": "Memory"
                        },
                        "name": "git-keygen"
                    },
                    {
                        "name": "flux-dev-token-cc68d",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "flux-dev-token-cc68d"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:02:36Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:02:44Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:02:44Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-11-06T17:02:36Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://137768a5233446262cdf76f7993eed8ba2cd9fa8f66282ea520f2d13ee1c0fa5",
                        "image": "fluxcd/flux:1.15.0",
                        "imageID": "docker-pullable://fluxcd/flux@sha256:ba4bd9ed8ea13ba4aa94d97b6ca285b6f3831fc5861369110dc19f238ac13201",
                        "lastState": {},
                        "name": "flux",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-11-06T17:02:38Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.80",
                "podIPs": [
                    {
                        "ip": "10.1.0.80"
                    }
                ],
                "qosClass": "Burstable",
                "startTime": "2020-11-06T17:02:36Z"
            }
        }
    ]
}

TASK [setup/flux : Get ssh known hosts] ****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:17
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/flux : Helm repo add] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:23
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/flux : Install flux] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:30
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [wait for pods to come up] ************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:40
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/flux : Get ssh key] ************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:54
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682193.0494976-11652-52654194595944 `" && echo ansible-tmp-1604682193.0494976-11652-52654194595944="` echo /root/.ansible/tmp/ansible-tmp-1604682193.0494976-11652-52654194595944 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp5ow5b32e TO /root/.ansible/tmp/ansible-tmp-1604682193.0494976-11652-52654194595944/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682193.0494976-11652-52654194595944/ /root/.ansible/tmp/ansible-tmp-1604682193.0494976-11652-52654194595944/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682193.0494976-11652-52654194595944/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682193.0494976-11652-52654194595944/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": "KUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl -n default logs deployment/flux-dev | grep identity.pub | cut -d '\"' -f2\n",
    "delta": "0:00:00.132114",
    "end": "2020-11-06 17:03:13.313977",
    "invocation": {
        "module_args": {
            "_raw_params": "KUBECONFIG=/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml kubectl -n default logs deployment/flux-dev | grep identity.pub | cut -d '\"' -f2\n",
            "_uses_shell": true,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:03:13.181863",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC8ImoOJkm9nhYVB2d6wbBVNW526Q3nEQoeBG0tQTTbQ5F6bFIkfraDGKKxqpRZRPwiSTkcxUbGeWV1xpbX4kuG3NKn8MwFm1LBilEnp8m9t48ID9cIfLe4WESE4KCqmXPXjMK/OFa1Yo1JRd9P/PHVK4mJK1syXAZl0XKhK9gujrStC/EOsRaB/6ToyQeOPPfeWqL/EO8P6a5T1CFerUBc+Mw4lnFa8XEP7ab4q3xZbmuZ+oGt6sFR+/Jzu8kYJAY1j0ASqBU0DbJbUvvDnpEr7sM3DHTLHj3Mu0K3d4qyc+eaSMono+6BJZIi5JfT3ymgJ5Xwa3W87w5zPgYd+/LVF/wnChgeYYAzCfHZagFQTzxS/wEuWjvNouTf2TbVbgdFRCKPQ9BTTQB+Hrlm8kzqhduNsWlQO9puWd6Zn/A8B+rcae0hrJdKrF7A8NA5N5N/cR9kiri6rJ4m8kJWvrG+zTEBHWcqtDvRj0Yqf29m0XP2IjERFfCwe5W5efIkEk0=",
    "stdout_lines": [
        "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC8ImoOJkm9nhYVB2d6wbBVNW526Q3nEQoeBG0tQTTbQ5F6bFIkfraDGKKxqpRZRPwiSTkcxUbGeWV1xpbX4kuG3NKn8MwFm1LBilEnp8m9t48ID9cIfLe4WESE4KCqmXPXjMK/OFa1Yo1JRd9P/PHVK4mJK1syXAZl0XKhK9gujrStC/EOsRaB/6ToyQeOPPfeWqL/EO8P6a5T1CFerUBc+Mw4lnFa8XEP7ab4q3xZbmuZ+oGt6sFR+/Jzu8kYJAY1j0ASqBU0DbJbUvvDnpEr7sM3DHTLHj3Mu0K3d4qyc+eaSMono+6BJZIi5JfT3ymgJ5Xwa3W87w5zPgYd+/LVF/wnChgeYYAzCfHZagFQTzxS/wEuWjvNouTf2TbVbgdFRCKPQ9BTTQB+Hrlm8kzqhduNsWlQO9puWd6Zn/A8B+rcae0hrJdKrF7A8NA5N5N/cR9kiri6rJ4m8kJWvrG+zTEBHWcqtDvRj0Yqf29m0XP2IjERFfCwe5W5efIkEk0="
    ]
}

TASK [setup/flux : Output ssh key] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/flux/tasks/main.yaml:60
ok: [localhost] => {
    "ssh_key.stdout": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC8ImoOJkm9nhYVB2d6wbBVNW526Q3nEQoeBG0tQTTbQ5F6bFIkfraDGKKxqpRZRPwiSTkcxUbGeWV1xpbX4kuG3NKn8MwFm1LBilEnp8m9t48ID9cIfLe4WESE4KCqmXPXjMK/OFa1Yo1JRd9P/PHVK4mJK1syXAZl0XKhK9gujrStC/EOsRaB/6ToyQeOPPfeWqL/EO8P6a5T1CFerUBc+Mw4lnFa8XEP7ab4q3xZbmuZ+oGt6sFR+/Jzu8kYJAY1j0ASqBU0DbJbUvvDnpEr7sM3DHTLHj3Mu0K3d4qyc+eaSMono+6BJZIi5JfT3ymgJ5Xwa3W87w5zPgYd+/LVF/wnChgeYYAzCfHZagFQTzxS/wEuWjvNouTf2TbVbgdFRCKPQ9BTTQB+Hrlm8kzqhduNsWlQO9puWd6Zn/A8B+rcae0hrJdKrF7A8NA5N5N/cR9kiri6rJ4m8kJWvrG+zTEBHWcqtDvRj0Yqf29m0XP2IjERFfCwe5W5efIkEk0="
}

TASK [Prepare nodes and clients ports for ambassador] **************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/kubernetes-env-setup.yaml:22
skipping: [localhost] => (item={'organization': None, 'name': 'supplychain', 'country': 'UK', 'state': 'London', 'location': 'London', 'subject': 'O=Orderer,L=51.50/-0.13/London,C=GB', 'type': 'orderer', 'external_url_suffix': 'supplychain-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.supplychain-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'oreo', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'consensus': {'name': 'raft', 'type': 'broker', 'replicas': 4, 'grpc': {'port': 9092}}, 'orderers': [{'orderer': None, 'name': 'orderer3', 'type': 'orderer', 'consensus': 'raft', 'grpc': {'port': 7050}}]}})  => {
    "ansible_loop_var": "organizationItem",
    "changed": false,
    "organizationItem": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.supplychain-net:7054"
        },
        "cloud_provider": "azure",
        "country": "UK",
        "external_url_suffix": "supplychain-net.svc.cluster.local",
        "gitops": {
            "branch": "oreo",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "supplychain",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net",
                "type": "ca"
            },
            "consensus": {
                "grpc": {
                    "port": 9092
                },
                "name": "raft",
                "replicas": 4,
                "type": "broker"
            },
            "orderers": [
                {
                    "consensus": "raft",
                    "grpc": {
                        "port": 7050
                    },
                    "name": "orderer3",
                    "orderer": null,
                    "type": "orderer"
                }
            ]
        },
        "state": "London",
        "subject": "O=Orderer,L=51.50/-0.13/London,C=GB",
        "type": "orderer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'organization': None, 'name': 'carrier', 'country': 'GB', 'state': 'London', 'location': 'London', 'subject': 'O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB', 'type': 'peer', 'external_url_suffix': 'carrier-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.carrier-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'oreo', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'peers': [{'peer': None, 'name': 'peer0', 'type': 'anchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer0.carrier-net.svc.cluster.local:7051', 'cli': 'enabled', 'grpc': {'port': 7051}, 'events': {'port': 7053}, 'couchdb': {'port': 5984}, 'restserver': {'targetPort': 20001, 'port': 20001}, 'expressapi': {'targetPort': 3000, 'port': 3000}}, {'peer': None, 'name': 'peer1', 'type': 'nonanchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer1.carrier-net.svc.cluster.local:7061', 'cli': 'enabled', 'grpc': {'port': 7061}, 'events': {'port': 7063}, 'couchdb': {'port': 5994}, 'restserver': {'targetPort': 20011, 'port': 20011}, 'expressapi': {'targetPort': 3010, 'port': 3010}}]}})  => {
    "ansible_loop_var": "organizationItem",
    "changed": false,
    "organizationItem": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.carrier-net:7054"
        },
        "cloud_provider": "azure",
        "country": "GB",
        "external_url_suffix": "carrier-net.svc.cluster.local",
        "gitops": {
            "branch": "oreo",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "carrier",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net",
                "type": "ca"
            },
            "peers": [
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5984
                    },
                    "events": {
                        "port": 7053
                    },
                    "expressapi": {
                        "port": 3000,
                        "targetPort": 3000
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7051
                    },
                    "name": "peer0",
                    "peer": null,
                    "peerAddress": "peer0.carrier-net.svc.cluster.local:7051",
                    "restserver": {
                        "port": 20001,
                        "targetPort": 20001
                    },
                    "type": "anchor"
                },
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5994
                    },
                    "events": {
                        "port": 7063
                    },
                    "expressapi": {
                        "port": 3010,
                        "targetPort": 3010
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7061
                    },
                    "name": "peer1",
                    "peer": null,
                    "peerAddress": "peer1.carrier-net.svc.cluster.local:7061",
                    "restserver": {
                        "port": 20011,
                        "targetPort": 20011
                    },
                    "type": "nonanchor"
                }
            ]
        },
        "state": "London",
        "subject": "O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB",
        "type": "peer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [include_role : setup/ambassador] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/kubernetes-env-setup.yaml:31
skipping: [localhost] => (item={'organization': None, 'name': 'supplychain', 'country': 'UK', 'state': 'London', 'location': 'London', 'subject': 'O=Orderer,L=51.50/-0.13/London,C=GB', 'type': 'orderer', 'external_url_suffix': 'supplychain-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.supplychain-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'oreo', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'consensus': {'name': 'raft', 'type': 'broker', 'replicas': 4, 'grpc': {'port': 9092}}, 'orderers': [{'orderer': None, 'name': 'orderer3', 'type': 'orderer', 'consensus': 'raft', 'grpc': {'port': 7050}}]}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.supplychain-net:7054"
        },
        "cloud_provider": "azure",
        "country": "UK",
        "external_url_suffix": "supplychain-net.svc.cluster.local",
        "gitops": {
            "branch": "oreo",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "supplychain",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Orderer/CN=ca.supplychain-net",
                "type": "ca"
            },
            "consensus": {
                "grpc": {
                    "port": 9092
                },
                "name": "raft",
                "replicas": 4,
                "type": "broker"
            },
            "orderers": [
                {
                    "consensus": "raft",
                    "grpc": {
                        "port": 7050
                    },
                    "name": "orderer3",
                    "orderer": null,
                    "type": "orderer"
                }
            ]
        },
        "state": "London",
        "subject": "O=Orderer,L=51.50/-0.13/London,C=GB",
        "type": "orderer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}
skipping: [localhost] => (item={'organization': None, 'name': 'carrier', 'country': 'GB', 'state': 'London', 'location': 'London', 'subject': 'O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB', 'type': 'peer', 'external_url_suffix': 'carrier-net.svc.cluster.local', 'org_status': 'new', 'ca_data': {'url': 'ca.carrier-net:7054', 'certificate': 'file/server.crt'}, 'cloud_provider': 'azure', 'k8s': {'region': 'cluster_region', 'context': 'fabric-aks-dev1', 'config_file': '/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml'}, 'vault': {'url': 'http://vault.suneelbaf.svc.cluster.local:8200', 'root_token': 's.V28i17sRnBQyQV55J3jHp0hu'}, 'gitops': {'git_ssh': 'ssh://git@github.com/bafsunsu/blockchain-automation-framework.git', 'branch': 'oreo', 'release_dir': 'platforms/hyperledger-fabric/releases/dev', 'chart_source': 'platforms/hyperledger-fabric/charts', 'git_push_url': 'github.com/bafsunsu/blockchain-automation-framework.git', 'username': 'bafsunsu', 'password': 'bafsunsu2020', 'email': 's.unil18031992@gmail.com', 'private_key': '/Users/s0s0dit/project/blockchain-automation-framework/build/gitops'}, 'services': {'ca': {'name': 'ca', 'subject': '/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net', 'type': 'ca', 'grpc': {'port': 7054}}, 'peers': [{'peer': None, 'name': 'peer0', 'type': 'anchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer0.carrier-net.svc.cluster.local:7051', 'cli': 'enabled', 'grpc': {'port': 7051}, 'events': {'port': 7053}, 'couchdb': {'port': 5984}, 'restserver': {'targetPort': 20001, 'port': 20001}, 'expressapi': {'targetPort': 3000, 'port': 3000}}, {'peer': None, 'name': 'peer1', 'type': 'nonanchor', 'gossippeeraddress': 'peer0.carrier-net:7051', 'peerAddress': 'peer1.carrier-net.svc.cluster.local:7061', 'cli': 'enabled', 'grpc': {'port': 7061}, 'events': {'port': 7063}, 'couchdb': {'port': 5994}, 'restserver': {'targetPort': 20011, 'port': 20011}, 'expressapi': {'targetPort': 3010, 'port': 3010}}]}})  => {
    "ansible_loop_var": "item",
    "changed": false,
    "item": {
        "ca_data": {
            "certificate": "file/server.crt",
            "url": "ca.carrier-net:7054"
        },
        "cloud_provider": "azure",
        "country": "GB",
        "external_url_suffix": "carrier-net.svc.cluster.local",
        "gitops": {
            "branch": "oreo",
            "chart_source": "platforms/hyperledger-fabric/charts",
            "email": "s.unil18031992@gmail.com",
            "git_push_url": "github.com/bafsunsu/blockchain-automation-framework.git",
            "git_ssh": "ssh://git@github.com/bafsunsu/blockchain-automation-framework.git",
            "password": "bafsunsu2020",
            "private_key": "/Users/s0s0dit/project/blockchain-automation-framework/build/gitops",
            "release_dir": "platforms/hyperledger-fabric/releases/dev",
            "username": "bafsunsu"
        },
        "k8s": {
            "config_file": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "context": "fabric-aks-dev1",
            "region": "cluster_region"
        },
        "location": "London",
        "name": "carrier",
        "org_status": "new",
        "organization": null,
        "services": {
            "ca": {
                "grpc": {
                    "port": 7054
                },
                "name": "ca",
                "subject": "/C=GB/ST=London/L=London/O=Carrier/CN=ca.carrier-net",
                "type": "ca"
            },
            "peers": [
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5984
                    },
                    "events": {
                        "port": 7053
                    },
                    "expressapi": {
                        "port": 3000,
                        "targetPort": 3000
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7051
                    },
                    "name": "peer0",
                    "peer": null,
                    "peerAddress": "peer0.carrier-net.svc.cluster.local:7051",
                    "restserver": {
                        "port": 20001,
                        "targetPort": 20001
                    },
                    "type": "anchor"
                },
                {
                    "cli": "enabled",
                    "couchdb": {
                        "port": 5994
                    },
                    "events": {
                        "port": 7063
                    },
                    "expressapi": {
                        "port": 3010,
                        "targetPort": 3010
                    },
                    "gossippeeraddress": "peer0.carrier-net:7051",
                    "grpc": {
                        "port": 7061
                    },
                    "name": "peer1",
                    "peer": null,
                    "peerAddress": "peer1.carrier-net.svc.cluster.local:7061",
                    "restserver": {
                        "port": 20011,
                        "targetPort": 20011
                    },
                    "type": "nonanchor"
                }
            ]
        },
        "state": "London",
        "subject": "O=Carrier,OU=Carrier,L=51.50/-0.13/London,C=GB",
        "type": "peer",
        "vault": {
            "root_token": "s.V28i17sRnBQyQV55J3jHp0hu",
            "url": "http://vault.suneelbaf.svc.cluster.local:8200"
        }
    },
    "skip_reason": "Conditional result was False"
}

TASK [include_role : setup/haproxy-ingress] ************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/kubernetes-env-setup.yaml:45
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [aws-cli : register temporary directory] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : check aws cli] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : download aws cli] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : extract aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:34
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : install aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:44
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : configuring aws] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:52
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : register temporary directory] ***************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : check aws-authenticator] ********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : create bin directory] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : Install aws-authenticator] ******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:24
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : Test Kubernetes connection] *****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:35
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : register temporary directory] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682193.979157-11718-183287652674155 `" && echo ansible-tmp-1604682193.979157-11718-183287652674155="` echo /root/.ansible/tmp/ansible-tmp-1604682193.979157-11718-183287652674155 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp4fmug68j TO /root/.ansible/tmp/ansible-tmp-1604682193.979157-11718-183287652674155/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682193.979157-11718-183287652674155/ /root/.ansible/tmp/ansible-tmp-1604682193.979157-11718-183287652674155/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682193.979157-11718-183287652674155/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682193.979157-11718-183287652674155/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.10fuqd8s",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/helm : check helm] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682194.1594834-11744-90636574505503 `" && echo ansible-tmp-1604682194.1594834-11744-90636574505503="` echo /root/.ansible/tmp/ansible-tmp-1604682194.1594834-11744-90636574505503 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmphkgnpodg TO /root/.ansible/tmp/ansible-tmp-1604682194.1594834-11744-90636574505503/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682194.1594834-11744-90636574505503/ /root/.ansible/tmp/ansible-tmp-1604682194.1594834-11744-90636574505503/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682194.1594834-11744-90636574505503/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682194.1594834-11744-90636574505503/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/helm"
        }
    },
    "stat": {
        "atime": 1603618464.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 78000,
        "charset": "binary",
        "checksum": "5820860e398793a3b0b54449e9b6f9a4a0f35cb9",
        "ctime": 1604239659.0090716,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126511,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618464.0,
        "nlink": 1,
        "path": "/root/bin/helm",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 39936000,
        "uid": 0,
        "version": "2759632516",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/helm : Install helm] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Unzip helm archive] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:37
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Move helm binaries] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:47
skipping: [localhost] => (item=helm)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "helm",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Test helm installation] *************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:58
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682194.5215044-11780-186728991498925 `" && echo ansible-tmp-1604682194.5215044-11780-186728991498925="` echo /root/.ansible/tmp/ansible-tmp-1604682194.5215044-11780-186728991498925 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp_gi0_5ac TO /root/.ansible/tmp/ansible-tmp-1604682194.5215044-11780-186728991498925/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682194.5215044-11780-186728991498925/ /root/.ansible/tmp/ansible-tmp-1604682194.5215044-11780-186728991498925/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682194.5215044-11780-186728991498925/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682194.5215044-11780-186728991498925/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "helm",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.056545",
    "end": "2020-11-06 17:03:14.709507",
    "invocation": {
        "module_args": {
            "_raw_params": "helm version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:03:14.652962",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client: v2.16.12+g47f0b88",
    "stdout_lines": [
        "Client: v2.16.12+g47f0b88"
    ]
}

TASK [setup/tiller : Check if Tiller is already installed in the Kubernetes clusters] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682194.7673943-11811-173095239747160 `" && echo ansible-tmp-1604682194.7673943-11811-173095239747160="` echo /root/.ansible/tmp/ansible-tmp-1604682194.7673943-11811-173095239747160 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmplfo3t94x TO /root/.ansible/tmp/ansible-tmp-1604682194.7673943-11811-173095239747160/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682194.7673943-11811-173095239747160/ /root/.ansible/tmp/ansible-tmp-1604682194.7673943-11811-173095239747160/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682194.7673943-11811-173095239747160/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682194.7673943-11811-173095239747160/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Create service account for Tiller] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:14
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Apply Tiller RBAC definintion] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Setup tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:47
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Wait for tiller to be ready] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:55

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682195.585037-11851-262909646744639 `" && echo ansible-tmp-1604682195.585037-11851-262909646744639="` echo /root/.ansible/tmp/ansible-tmp-1604682195.585037-11851-262909646744639 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpf4x2tbgh TO /root/.ansible/tmp/ansible-tmp-1604682195.585037-11851-262909646744639/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682195.585037-11851-262909646744639/ /root/.ansible/tmp/ansible-tmp-1604682195.585037-11851-262909646744639/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682195.585037-11851-262909646744639/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682195.585037-11851-262909646744639/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/haproxy-ingress : Check if haproxy is already installed] ***********
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682196.2083607-11879-27782744698863 `" && echo ansible-tmp-1604682196.2083607-11879-27782744698863="` echo /root/.ansible/tmp/ansible-tmp-1604682196.2083607-11879-27782744698863 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmptuyamsl7 TO /root/.ansible/tmp/ansible-tmp-1604682196.2083607-11879-27782744698863/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682196.2083607-11879-27782744698863/ /root/.ansible/tmp/ansible-tmp-1604682196.2083607-11879-27782744698863/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682196.2083607-11879-27782744698863/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682196.2083607-11879-27782744698863/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "run = haproxy-ingress"
            ],
            "name": null,
            "namespace": "ingress-controller",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-6ksdw",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106895",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-6ksdw",
                "uid": "8563bc8d-1403-4bd4-aee2-7951da46957d"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000002"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4176a8d9672284d4518d9c6472735301169dbef1f5f96e8543488e1d8cc80b9e",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.66",
                "podIPs": [
                    {
                        "ip": "10.1.0.66"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-cp4vl",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106892",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-cp4vl",
                "uid": "a4be4342-5781-4905-83af-ff731371aca9"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000000"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000000",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4d1866dac0c6f40ce0ecaa88085357e276165bd48a61d29224c7e7e34dee4054",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.4",
                "phase": "Running",
                "podIP": "10.1.0.4",
                "podIPs": [
                    {
                        "ip": "10.1.0.4"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-rwks2",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106888",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-rwks2",
                "uid": "d50d75fe-0b73-48e7-9523-365002cc2784"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000001"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000001",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4ea1edbd8c67e0e8a562d94639105dd6b0066370c17eb29f212680cbd72e578d",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.35",
                "phase": "Running",
                "podIP": "10.1.0.35",
                "podIPs": [
                    {
                        "ip": "10.1.0.35"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        }
    ]
}

TASK [setup/haproxy-ingress : Install HAProxy Ingress controller] **************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/haproxy-ingress : Enable external DNS] *****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:24
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/haproxy-ingress : Disable TLS1.0 for the AWS] **********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:33
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [wait for pods to come up] ************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:42
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [check/helm_component : Wait for Pod flux in ingress-controller] **********
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod flux in ingress-controller] **********
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682197.0887096-11919-155829364303198 `" && echo ansible-tmp-1604682197.0887096-11919-155829364303198="` echo /root/.ansible/tmp/ansible-tmp-1604682197.0887096-11919-155829364303198 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpxsfmfth7 TO /root/.ansible/tmp/ansible-tmp-1604682197.0887096-11919-155829364303198/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682197.0887096-11919-155829364303198/ /root/.ansible/tmp/ansible-tmp-1604682197.0887096-11919-155829364303198/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682197.0887096-11919-155829364303198/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682197.0887096-11919-155829364303198/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "run = haproxy-ingress"
            ],
            "name": null,
            "namespace": "ingress-controller",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-6ksdw",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106895",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-6ksdw",
                "uid": "8563bc8d-1403-4bd4-aee2-7951da46957d"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000002"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4176a8d9672284d4518d9c6472735301169dbef1f5f96e8543488e1d8cc80b9e",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.66",
                "podIPs": [
                    {
                        "ip": "10.1.0.66"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-cp4vl",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106892",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-cp4vl",
                "uid": "a4be4342-5781-4905-83af-ff731371aca9"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000000"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000000",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4d1866dac0c6f40ce0ecaa88085357e276165bd48a61d29224c7e7e34dee4054",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.4",
                "phase": "Running",
                "podIP": "10.1.0.4",
                "podIPs": [
                    {
                        "ip": "10.1.0.4"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-rwks2",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106888",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-rwks2",
                "uid": "d50d75fe-0b73-48e7-9523-365002cc2784"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000001"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000001",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4ea1edbd8c67e0e8a562d94639105dd6b0066370c17eb29f212680cbd72e578d",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.35",
                "phase": "Running",
                "podIP": "10.1.0.35",
                "podIPs": [
                    {
                        "ip": "10.1.0.35"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        }
    ]
}

TASK [aws-cli : register temporary directory] **********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : check aws cli] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : download aws cli] **********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : extract aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:25
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:34
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : install aws cli] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:44
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [aws-cli : configuring aws] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-cli/tasks/main.yaml:52
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : register temporary directory] ***************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:2
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : check aws-authenticator] ********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:9
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : create bin directory] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : Install aws-authenticator] ******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:24
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/aws-auth : Test Kubernetes connection] *****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/aws-auth/tasks/main.yaml:35
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : register temporary directory] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682198.0408866-11971-65192575547246 `" && echo ansible-tmp-1604682198.0408866-11971-65192575547246="` echo /root/.ansible/tmp/ansible-tmp-1604682198.0408866-11971-65192575547246 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/tempfile.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpvouebcuy TO /root/.ansible/tmp/ansible-tmp-1604682198.0408866-11971-65192575547246/AnsiballZ_tempfile.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682198.0408866-11971-65192575547246/ /root/.ansible/tmp/ansible-tmp-1604682198.0408866-11971-65192575547246/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682198.0408866-11971-65192575547246/AnsiballZ_tempfile.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682198.0408866-11971-65192575547246/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "path": null,
            "prefix": "ansible.",
            "state": "directory",
            "suffix": ""
        }
    },
    "mode": "0700",
    "owner": "root",
    "path": "/tmp/ansible.27swg0wc",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [setup/helm : check helm] *************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682198.2235074-11997-120756981290490 `" && echo ansible-tmp-1604682198.2235074-11997-120756981290490="` echo /root/.ansible/tmp/ansible-tmp-1604682198.2235074-11997-120756981290490 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp2pj8qtn5 TO /root/.ansible/tmp/ansible-tmp-1604682198.2235074-11997-120756981290490/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682198.2235074-11997-120756981290490/ /root/.ansible/tmp/ansible-tmp-1604682198.2235074-11997-120756981290490/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682198.2235074-11997-120756981290490/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682198.2235074-11997-120756981290490/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "checksum_algorithm": "sha1",
            "follow": false,
            "get_attributes": true,
            "get_checksum": true,
            "get_md5": false,
            "get_mime": true,
            "path": "/root/bin/helm"
        }
    },
    "stat": {
        "atime": 1603618464.0,
        "attr_flags": "e",
        "attributes": [
            "extents"
        ],
        "block_size": 4096,
        "blocks": 78000,
        "charset": "binary",
        "checksum": "5820860e398793a3b0b54449e9b6f9a4a0f35cb9",
        "ctime": 1604239659.0090716,
        "dev": 255,
        "device_type": 0,
        "executable": true,
        "exists": true,
        "gid": 0,
        "gr_name": "root",
        "inode": 3126511,
        "isblk": false,
        "ischr": false,
        "isdir": false,
        "isfifo": false,
        "isgid": false,
        "islnk": false,
        "isreg": true,
        "issock": false,
        "isuid": false,
        "mimetype": "application/x-executable",
        "mode": "0755",
        "mtime": 1603618464.0,
        "nlink": 1,
        "path": "/root/bin/helm",
        "pw_name": "root",
        "readable": true,
        "rgrp": true,
        "roth": true,
        "rusr": true,
        "size": 39936000,
        "uid": 0,
        "version": "2759632516",
        "wgrp": false,
        "woth": false,
        "writeable": true,
        "wusr": true,
        "xgrp": true,
        "xoth": true,
        "xusr": true
    }
}

TASK [setup/helm : Install helm] ***********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Unzip helm archive] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create bin directory] ****************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:37
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Move helm binaries] *****************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:47
skipping: [localhost] => (item=helm)  => {
    "ansible_loop_var": "bin_item",
    "bin_item": "helm",
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/helm : Test helm installation] *************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/helm/tasks/main.yaml:58
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682198.5850425-12033-247814610725657 `" && echo ansible-tmp-1604682198.5850425-12033-247814610725657="` echo /root/.ansible/tmp/ansible-tmp-1604682198.5850425-12033-247814610725657 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp81gzlwl8 TO /root/.ansible/tmp/ansible-tmp-1604682198.5850425-12033-247814610725657/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682198.5850425-12033-247814610725657/ /root/.ansible/tmp/ansible-tmp-1604682198.5850425-12033-247814610725657/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682198.5850425-12033-247814610725657/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682198.5850425-12033-247814610725657/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "cmd": [
        "helm",
        "version",
        "--client",
        "--short"
    ],
    "delta": "0:00:00.050236",
    "end": "2020-11-06 17:03:18.765623",
    "invocation": {
        "module_args": {
            "_raw_params": "helm version --client --short",
            "_uses_shell": false,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "rc": 0,
    "start": "2020-11-06 17:03:18.715387",
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Client: v2.16.12+g47f0b88",
    "stdout_lines": [
        "Client: v2.16.12+g47f0b88"
    ]
}

TASK [setup/tiller : Check if Tiller is already installed in the Kubernetes clusters] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:2
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682198.8262606-12064-69716994871529 `" && echo ansible-tmp-1604682198.8262606-12064-69716994871529="` echo /root/.ansible/tmp/ansible-tmp-1604682198.8262606-12064-69716994871529 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpu25x7n37 TO /root/.ansible/tmp/ansible-tmp-1604682198.8262606-12064-69716994871529/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682198.8262606-12064-69716994871529/ /root/.ansible/tmp/ansible-tmp-1604682198.8262606-12064-69716994871529/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682198.8262606-12064-69716994871529/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682198.8262606-12064-69716994871529/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/tiller : Create service account for Tiller] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:14
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Apply Tiller RBAC definintion] ****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:27
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/tiller : Setup tiller] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:47
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Wait for tiller to be ready] *********************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/tiller/tasks/main.yaml:55

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod helm in kube-system] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682199.689782-12104-260168936599441 `" && echo ansible-tmp-1604682199.689782-12104-260168936599441="` echo /root/.ansible/tmp/ansible-tmp-1604682199.689782-12104-260168936599441 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp9gwozjlx TO /root/.ansible/tmp/ansible-tmp-1604682199.689782-12104-260168936599441/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682199.689782-12104-260168936599441/ /root/.ansible/tmp/ansible-tmp-1604682199.689782-12104-260168936599441/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682199.689782-12104-260168936599441/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682199.689782-12104-260168936599441/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "app = helm"
            ],
            "name": null,
            "namespace": "kube-system",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T18:12:54Z",
                "generateName": "tiller-deploy-59fbf5447c-",
                "labels": {
                    "app": "helm",
                    "name": "tiller",
                    "pod-template-hash": "59fbf5447c"
                },
                "name": "tiller-deploy-59fbf5447c-cpkbh",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "tiller-deploy-59fbf5447c",
                        "uid": "c3d6ed6b-8817-4666-9014-a9e57ba14a2d"
                    }
                ],
                "resourceVersion": "236917",
                "selfLink": "/api/v1/namespaces/kube-system/pods/tiller-deploy-59fbf5447c-cpkbh",
                "uid": "536ed4d6-9da8-4cf5-b6d4-7cf61a081618"
            },
            "spec": {
                "automountServiceAccountToken": true,
                "containers": [
                    {
                        "env": [
                            {
                                "name": "TILLER_NAMESPACE",
                                "value": "kube-system"
                            },
                            {
                                "name": "TILLER_HISTORY_MAX",
                                "value": "200"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP_ADDR",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            },
                            {
                                "name": "KUBERNETES_PORT",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_PORT_443_TCP",
                                "value": "tcp://fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io:443"
                            },
                            {
                                "name": "KUBERNETES_SERVICE_HOST",
                                "value": "fabric-dns-1-d0b060a1.hcp.southcentralus.azmk8s.io"
                            }
                        ],
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/liveness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "tiller",
                        "ports": [
                            {
                                "containerPort": 44134,
                                "name": "tiller",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 44135,
                                "name": "http",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/readiness",
                                "port": 44135,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 1,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "tiller-token-r24lq",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "tiller",
                "serviceAccountName": "tiller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "name": "tiller-token-r24lq",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "tiller-token-r24lq"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:13:07Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T18:12:54Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://5d833a631b5d8b2e0bc8397d5e1f473b3bd9d918eaebac7c0d466ab91f292a28",
                        "image": "gcr.io/kubernetes-helm/tiller:v2.16.12",
                        "imageID": "docker-pullable://gcr.io/kubernetes-helm/tiller@sha256:6003775d503546087266eda39418d221f9afb5ccfe35f637c32a1161619a3f9c",
                        "lastState": {},
                        "name": "tiller",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T18:13:00Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.75",
                "podIPs": [
                    {
                        "ip": "10.1.0.75"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T18:12:54Z"
            }
        }
    ]
}

TASK [setup/haproxy-ingress : Check if haproxy is already installed] ***********
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682200.3206594-12132-214161557058756 `" && echo ansible-tmp-1604682200.3206594-12132-214161557058756="` echo /root/.ansible/tmp/ansible-tmp-1604682200.3206594-12132-214161557058756 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpwo2sdwef TO /root/.ansible/tmp/ansible-tmp-1604682200.3206594-12132-214161557058756/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682200.3206594-12132-214161557058756/ /root/.ansible/tmp/ansible-tmp-1604682200.3206594-12132-214161557058756/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682200.3206594-12132-214161557058756/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682200.3206594-12132-214161557058756/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "run = haproxy-ingress"
            ],
            "name": null,
            "namespace": "ingress-controller",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-6ksdw",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106895",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-6ksdw",
                "uid": "8563bc8d-1403-4bd4-aee2-7951da46957d"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000002"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4176a8d9672284d4518d9c6472735301169dbef1f5f96e8543488e1d8cc80b9e",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.66",
                "podIPs": [
                    {
                        "ip": "10.1.0.66"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-cp4vl",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106892",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-cp4vl",
                "uid": "a4be4342-5781-4905-83af-ff731371aca9"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000000"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000000",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4d1866dac0c6f40ce0ecaa88085357e276165bd48a61d29224c7e7e34dee4054",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.4",
                "phase": "Running",
                "podIP": "10.1.0.4",
                "podIPs": [
                    {
                        "ip": "10.1.0.4"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-rwks2",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106888",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-rwks2",
                "uid": "d50d75fe-0b73-48e7-9523-365002cc2784"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000001"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000001",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4ea1edbd8c67e0e8a562d94639105dd6b0066370c17eb29f212680cbd72e578d",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.35",
                "phase": "Running",
                "podIP": "10.1.0.35",
                "podIPs": [
                    {
                        "ip": "10.1.0.35"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        }
    ]
}

TASK [setup/haproxy-ingress : Install HAProxy Ingress controller] **************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:16
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/haproxy-ingress : Enable external DNS] *****************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:24
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [setup/haproxy-ingress : Disable TLS1.0 for the AWS] **********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:33
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [wait for pods to come up] ************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/setup/haproxy-ingress/tasks/main.yaml:42

TASK [check/helm_component : Wait for Pod flux in ingress-controller] **********
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:5
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Check for {{ job_title }} job on {{ component_name }}] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:22
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [check/helm_component : Wait for Pod flux in ingress-controller] **********
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/helm_component/tasks/main.yaml:36
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682201.1472423-12172-7252368162469 `" && echo ansible-tmp-1604682201.1472423-12172-7252368162469="` echo /root/.ansible/tmp/ansible-tmp-1604682201.1472423-12172-7252368162469 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpg3la8izy TO /root/.ansible/tmp/ansible-tmp-1604682201.1472423-12172-7252368162469/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682201.1472423-12172-7252368162469/ /root/.ansible/tmp/ansible-tmp-1604682201.1472423-12172-7252368162469/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682201.1472423-12172-7252368162469/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682201.1472423-12172-7252368162469/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [
                "status.phase=Running"
            ],
            "host": null,
            "kind": "Pod",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [
                "run = haproxy-ingress"
            ],
            "name": null,
            "namespace": "ingress-controller",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-6ksdw",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106895",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-6ksdw",
                "uid": "8563bc8d-1403-4bd4-aee2-7951da46957d"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000002"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000002",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4176a8d9672284d4518d9c6472735301169dbef1f5f96e8543488e1d8cc80b9e",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.66",
                "phase": "Running",
                "podIP": "10.1.0.66",
                "podIPs": [
                    {
                        "ip": "10.1.0.66"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-cp4vl",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106892",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-cp4vl",
                "uid": "a4be4342-5781-4905-83af-ff731371aca9"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000000"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000000",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4d1866dac0c6f40ce0ecaa88085357e276165bd48a61d29224c7e7e34dee4054",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.4",
                "phase": "Running",
                "podIP": "10.1.0.4",
                "podIPs": [
                    {
                        "ip": "10.1.0.4"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2020-10-27T04:00:06Z",
                "generateName": "haproxy-ingress-",
                "labels": {
                    "controller-revision-hash": "6fdf94c59f",
                    "pod-template-generation": "1",
                    "run": "haproxy-ingress"
                },
                "name": "haproxy-ingress-rwks2",
                "namespace": "ingress-controller",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "haproxy-ingress",
                        "uid": "4c1ad8e7-b166-464b-b1b3-0ebfec677b09"
                    }
                ],
                "resourceVersion": "106888",
                "selfLink": "/api/v1/namespaces/ingress-controller/pods/haproxy-ingress-rwks2",
                "uid": "d50d75fe-0b73-48e7-9523-365002cc2784"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "aks-fabricpool-41135923-vmss000001"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "args": [
                            "--default-backend-service=$(POD_NAMESPACE)/ingress-default-backend",
                            "--configmap=$(POD_NAMESPACE)/haproxy-ingress",
                            "--sort-backends"
                        ],
                        "env": [
                            {
                                "name": "POD_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.name"
                                    }
                                }
                            },
                            {
                                "name": "POD_NAMESPACE",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "metadata.namespace"
                                    }
                                }
                            }
                        ],
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/healthz",
                                "port": 10253,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "name": "haproxy-ingress",
                        "ports": [
                            {
                                "containerPort": 80,
                                "hostPort": 80,
                                "name": "http",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 443,
                                "hostPort": 443,
                                "name": "https",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 1936,
                                "hostPort": 1936,
                                "name": "stat",
                                "protocol": "TCP"
                            }
                        ],
                        "resources": {},
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "ingress-controller-token-qdm2n",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "aks-fabricpool-41135923-vmss000001",
                "priority": 0,
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "ingress-controller",
                "serviceAccountName": "ingress-controller",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "name": "ingress-controller-token-qdm2n",
                        "secret": {
                            "defaultMode": 420,
                            "secretName": "ingress-controller-token-qdm2n"
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2020-10-27T04:00:06Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "docker://4ea1edbd8c67e0e8a562d94639105dd6b0066370c17eb29f212680cbd72e578d",
                        "image": "quay.io/jcmoraisjr/haproxy-ingress:v0.9.1",
                        "imageID": "docker-pullable://quay.io/jcmoraisjr/haproxy-ingress@sha256:406705945c949a3efa9ad33cc21b3f643f45debeb0a54c61066a6c104e404d91",
                        "lastState": {},
                        "name": "haproxy-ingress",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2020-10-27T04:00:11Z"
                            }
                        }
                    }
                ],
                "hostIP": "10.1.0.35",
                "phase": "Running",
                "podIP": "10.1.0.35",
                "podIPs": [
                    {
                        "ip": "10.1.0.35"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2020-10-27T04:00:06Z"
            }
        }
    ]
}
META: ran handlers
META: ran handlers

PLAY [ansible_provisioners] ****************************************************
META: ran handlers

TASK [Remove build directory] **************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/deploy-network.yaml:16
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682201.7959883-12201-243031083092505 `" && echo ansible-tmp-1604682201.7959883-12201-243031083092505="` echo /root/.ansible/tmp/ansible-tmp-1604682201.7959883-12201-243031083092505 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp2bi31sda TO /root/.ansible/tmp/ansible-tmp-1604682201.7959883-12201-243031083092505/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682201.7959883-12201-243031083092505/ /root/.ansible/tmp/ansible-tmp-1604682201.7959883-12201-243031083092505/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682201.7959883-12201-243031083092505/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682201.7959883-12201-243031083092505/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "./build",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "absent",
            "unsafe_writes": false
        }
    },
    "path": "./build",
    "state": "absent"
}

TASK [include_role : create/namespace_vaultauth] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/deploy-network.yaml:22

TASK [Checking if the namespace supplychain-net already exists] ****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:6
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Check Namespace supplychain-net is created] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:7
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682202.3060453-12231-11339920521677 `" && echo ansible-tmp-1604682202.3060453-12231-11339920521677="` echo /root/.ansible/tmp/ansible-tmp-1604682202.3060453-12231-11339920521677 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpl3se45dh TO /root/.ansible/tmp/ansible-tmp-1604682202.3060453-12231-11339920521677/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682202.3060453-12231-11339920521677/ /root/.ansible/tmp/ansible-tmp-1604682202.3060453-12231-11339920521677/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682202.3060453-12231-11339920521677/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682202.3060453-12231-11339920521677/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "Namespace",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "supplychain-net",
            "namespace": null,
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": []
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for Namespace supplychain-net] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:17
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for Namespace supplychain-net] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:32
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for Namespace supplychain-net] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:45
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [create/namespace_vaultauth : Set Variable] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:17
ok: [localhost] => {
    "ansible_facts": {
        "get_namespace": {
            "changed": false,
            "failed": false,
            "resources": []
        }
    },
    "changed": false
}

TASK [Create namespaces] *******************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:24

TASK [k8_component : Ensures orderer dir exists] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682203.1099606-12269-183462106331201 `" && echo ansible-tmp-1604682203.1099606-12269-183462106331201="` echo /root/.ansible/tmp/ansible-tmp-1604682203.1099606-12269-183462106331201 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp8ohq6_84 TO /root/.ansible/tmp/ansible-tmp-1604682203.1099606-12269-183462106331201/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682203.1099606-12269-183462106331201/ /root/.ansible/tmp/ansible-tmp-1604682203.1099606-12269-183462106331201/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682203.1099606-12269-183462106331201/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682203.1099606-12269-183462106331201/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
            "state": "directory"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
            "state": "absent"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [k8_component : create namespace file for orderer] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:15
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346 `" && echo ansible-tmp-1604682203.322646-12295-76560277698346="` echo /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpf0siorot TO /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/ /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpnewpeh50/namespace_component.tpl TO /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/ /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/source && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/copy.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp68u170tg TO /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/AnsiballZ_copy.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/ /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "checksum": "764a9d412ee8c0bb2dcd3c55cdb72e2d1ff9d691",
    "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/namespace.yaml",
    "diff": [],
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_original_basename": "namespace_component.tpl",
            "attributes": null,
            "backup": false,
            "checksum": "764a9d412ee8c0bb2dcd3c55cdb72e2d1ff9d691",
            "content": null,
            "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/namespace.yaml",
            "directory_mode": null,
            "follow": false,
            "force": true,
            "group": null,
            "local_follow": null,
            "mode": null,
            "owner": null,
            "remote_src": null,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/source",
            "unsafe_writes": false,
            "validate": null
        }
    },
    "md5sum": "cf1425b79e968b40d5e1e2117e221f20",
    "mode": "0644",
    "owner": "root",
    "size": 64,
    "src": "/root/.ansible/tmp/ansible-tmp-1604682203.322646-12295-76560277698346/source",
    "state": "file",
    "uid": 0
}

TASK [Create vault reviewer service account for Organizations] *****************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:38

TASK [k8_component : Ensures orderer dir exists] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682203.9907331-12337-27844073591168 `" && echo ansible-tmp-1604682203.9907331-12337-27844073591168="` echo /root/.ansible/tmp/ansible-tmp-1604682203.9907331-12337-27844073591168 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp_2go9f8p TO /root/.ansible/tmp/ansible-tmp-1604682203.9907331-12337-27844073591168/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682203.9907331-12337-27844073591168/ /root/.ansible/tmp/ansible-tmp-1604682203.9907331-12337-27844073591168/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682203.9907331-12337-27844073591168/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682203.9907331-12337-27844073591168/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [k8_component : create vault-reviewer file for orderer] *******************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:15
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738 `" && echo ansible-tmp-1604682204.1963048-12363-149423042691738="` echo /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpy5sjw3lv TO /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/ /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpysw9zcdv/reviewer.tpl TO /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/ /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/source && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/copy.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmprl2wnski TO /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/AnsiballZ_copy.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/ /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "checksum": "9d128be9605e45ba4716f4ba8a39ae745f14db79",
    "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vault-reviewer.yaml",
    "diff": [],
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_original_basename": "reviewer.tpl",
            "attributes": null,
            "backup": false,
            "checksum": "9d128be9605e45ba4716f4ba8a39ae745f14db79",
            "content": null,
            "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vault-reviewer.yaml",
            "directory_mode": null,
            "follow": false,
            "force": true,
            "group": null,
            "local_follow": null,
            "mode": null,
            "owner": null,
            "remote_src": null,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/source",
            "unsafe_writes": false,
            "validate": null
        }
    },
    "md5sum": "c5daec1c3c097342e8e412880e157dd4",
    "mode": "0644",
    "owner": "root",
    "size": 97,
    "src": "/root/.ansible/tmp/ansible-tmp-1604682204.1963048-12363-149423042691738/source",
    "state": "file",
    "uid": 0
}

TASK [Create vault auth service account for Organizations] *********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:52

TASK [k8_component : Ensures orderer dir exists] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682204.5913887-12405-241304038911416 `" && echo ansible-tmp-1604682204.5913887-12405-241304038911416="` echo /root/.ansible/tmp/ansible-tmp-1604682204.5913887-12405-241304038911416 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp8k0m4x_1 TO /root/.ansible/tmp/ansible-tmp-1604682204.5913887-12405-241304038911416/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682204.5913887-12405-241304038911416/ /root/.ansible/tmp/ansible-tmp-1604682204.5913887-12405-241304038911416/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682204.5913887-12405-241304038911416/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682204.5913887-12405-241304038911416/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [k8_component : create vaultAuth file for orderer] ************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:15
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796 `" && echo ansible-tmp-1604682204.7957883-12431-212022848810796="` echo /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpcv6nve8p TO /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/ /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp4cbwbbu7/vault_auth.tpl TO /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/ /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/source && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/copy.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpozr426cx TO /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/AnsiballZ_copy.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/ /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "checksum": "a1900901e2836334aa654bf71990b01c437a0557",
    "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vaultAuth.yaml",
    "diff": [],
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_original_basename": "vault_auth.tpl",
            "attributes": null,
            "backup": false,
            "checksum": "a1900901e2836334aa654bf71990b01c437a0557",
            "content": null,
            "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vaultAuth.yaml",
            "directory_mode": null,
            "follow": false,
            "force": true,
            "group": null,
            "local_follow": null,
            "mode": null,
            "owner": null,
            "remote_src": null,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/source",
            "unsafe_writes": false,
            "validate": null
        }
    },
    "md5sum": "07219cd1d901d8c368736759bd1f8b18",
    "mode": "0644",
    "owner": "root",
    "size": 93,
    "src": "/root/.ansible/tmp/ansible-tmp-1604682204.7957883-12431-212022848810796/source",
    "state": "file",
    "uid": 0
}

TASK [Create clusterrolebinding for Ordrers] ***********************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:66

TASK [k8_component : Ensures orderer dir exists] *******************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:8
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682205.200768-12473-195064297473833 `" && echo ansible-tmp-1604682205.200768-12473-195064297473833="` echo /root/.ansible/tmp/ansible-tmp-1604682205.200768-12473-195064297473833 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpiy05brug TO /root/.ansible/tmp/ansible-tmp-1604682205.200768-12473-195064297473833/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682205.200768-12473-195064297473833/ /root/.ansible/tmp/ansible-tmp-1604682205.200768-12473-195064297473833/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682205.200768-12473-195064297473833/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682205.200768-12473-195064297473833/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [k8_component : create reviewer_rbac file for orderer] ********************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/k8_component/tasks/main.yaml:15
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027 `" && echo ansible-tmp-1604682205.4080858-12499-177012639320027="` echo /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpmfx1e64a TO /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/ /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp64devcfy/reviewer_rbac.tpl TO /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/ /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/source && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/copy.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpvten65tl TO /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/AnsiballZ_copy.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/ /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/AnsiballZ_copy.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/ > /dev/null 2>&1 && sleep 0'
changed: [localhost] => {
    "changed": true,
    "checksum": "a367bfe0512ceff5f1b8540d1fe765d8ddb132f1",
    "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/reviewer_rbac.yaml",
    "diff": [],
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_original_basename": "reviewer_rbac.tpl",
            "attributes": null,
            "backup": false,
            "checksum": "a367bfe0512ceff5f1b8540d1fe765d8ddb132f1",
            "content": null,
            "dest": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../platforms/hyperledger-fabric/releases/dev/supplychain/orderer/reviewer_rbac.yaml",
            "directory_mode": null,
            "follow": false,
            "force": true,
            "group": null,
            "local_follow": null,
            "mode": null,
            "owner": null,
            "remote_src": null,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": "/root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/source",
            "unsafe_writes": false,
            "validate": null
        }
    },
    "md5sum": "e260abafd7db9e5d5765a4c9a8db9574",
    "mode": "0644",
    "owner": "root",
    "size": 332,
    "src": "/root/.ansible/tmp/ansible-tmp-1604682205.4080858-12499-177012639320027/source",
    "state": "file",
    "uid": 0
}

TASK [Git Push] ****************************************************************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:74

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/git_push : Check if directory: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../ exists] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/git_push/tasks/main.yaml:3
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682205.806068-12541-241046029291638 `" && echo ansible-tmp-1604682205.806068-12541-241046029291638="` echo /root/.ansible/tmp/ansible-tmp-1604682205.806068-12541-241046029291638 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/file.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpz2h1o3dp TO /root/.ansible/tmp/ansible-tmp-1604682205.806068-12541-241046029291638/AnsiballZ_file.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682205.806068-12541-241046029291638/ /root/.ansible/tmp/ansible-tmp-1604682205.806068-12541-241046029291638/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682205.806068-12541-241046029291638/AnsiballZ_file.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682205.806068-12541-241046029291638/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "changed": false,
    "diff": {
        "after": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../"
        },
        "before": {
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../"
        }
    },
    "gid": 0,
    "group": "root",
    "invocation": {
        "module_args": {
            "_diff_peek": null,
            "_original_basename": null,
            "access_time": null,
            "access_time_format": "%Y%m%d%H%M.%S",
            "attributes": null,
            "follow": true,
            "force": false,
            "group": null,
            "mode": null,
            "modification_time": null,
            "modification_time_format": "%Y%m%d%H%M.%S",
            "owner": null,
            "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../",
            "recurse": false,
            "selevel": null,
            "serole": null,
            "setype": null,
            "seuser": null,
            "src": null,
            "state": "directory",
            "unsafe_writes": false
        }
    },
    "mode": "0755",
    "owner": "root",
    "path": "/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../",
    "size": 4096,
    "state": "directory",
    "uid": 0
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/git_push : Execute git push via shell task] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/git_push/tasks/main.yaml:9
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682206.0062635-12567-129246795299266 `" && echo ansible-tmp-1604682206.0062635-12567-129246795299266="` echo /root/.ansible/tmp/ansible-tmp-1604682206.0062635-12567-129246795299266 `" ) && sleep 0'
Using module file /usr/local/lib/python3.6/dist-packages/ansible/modules/command.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpy_pmek3g TO /root/.ansible/tmp/ansible-tmp-1604682206.0062635-12567-129246795299266/AnsiballZ_command.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682206.0062635-12567-129246795299266/ /root/.ansible/tmp/ansible-tmp-1604682206.0062635-12567-129246795299266/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682206.0062635-12567-129246795299266/AnsiballZ_command.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682206.0062635-12567-129246795299266/ > /dev/null 2>&1 && sleep 0'
fatal: [localhost]: FAILED! => {
    "changed": true,
    "cmd": "cd \"/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../\"\necho \"---------------SHOW CONTENT OF DIR---------------\"\nls -a\necho \"---------------GIT PUSH---------------\"\ngit config user.email s.unil18031992@gmail.com\ngit config user.name bafsunsu\ngit --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git add -A .\n\n# To ignore a directory add it add reset path\nreset_path=platforms/hyperledger-fabric/configuration\nif [ -n \"$reset_path\" ]; then\n    git --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git reset \"platforms/hyperledger-fabric/configuration\"\nfi  \n\ngit --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git commit -s -m \"[ci skip] Pushing deployment files for namespace, service accounts and clusterrolebinding\" || true\ngit --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git push https://bafsunsu:bafsunsu2020@github.com/bafsunsu/blockchain-automation-framework.git HEAD:oreo\n",
    "delta": "0:00:00.639412",
    "end": "2020-11-06 17:03:26.780847",
    "invocation": {
        "module_args": {
            "_raw_params": "cd \"/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../../\"\necho \"---------------SHOW CONTENT OF DIR---------------\"\nls -a\necho \"---------------GIT PUSH---------------\"\ngit config user.email s.unil18031992@gmail.com\ngit config user.name bafsunsu\ngit --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git add -A .\n\n# To ignore a directory add it add reset path\nreset_path=platforms/hyperledger-fabric/configuration\nif [ -n \"$reset_path\" ]; then\n    git --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git reset \"platforms/hyperledger-fabric/configuration\"\nfi  \n\ngit --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git commit -s -m \"[ci skip] Pushing deployment files for namespace, service accounts and clusterrolebinding\" || true\ngit --git-dir=/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../..//.git push https://bafsunsu:bafsunsu2020@github.com/bafsunsu/blockchain-automation-framework.git HEAD:oreo\n",
            "_uses_shell": true,
            "argv": null,
            "chdir": null,
            "creates": null,
            "executable": null,
            "removes": null,
            "stdin": null,
            "stdin_add_newline": true,
            "strip_empty_ends": true,
            "warn": true
        }
    },
    "msg": "non-zero return code",
    "rc": 1,
    "start": "2020-11-06 17:03:26.141435",
    "stderr": "To https://github.com/bafsunsu/blockchain-automation-framework.git\n ! [rejected]          HEAD -> oreo (fetch first)\nerror: failed to push some refs to 'https://bafsunsu:bafsunsu2020@github.com/bafsunsu/blockchain-automation-framework.git'\nhint: Updates were rejected because the remote contains work that you do\nhint: not have locally. This is usually caused by another repository pushing\nhint: to the same ref. You may want to first integrate the remote changes\nhint: (e.g., 'git pull ...') before pushing again.\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.",
    "stderr_lines": [
        "To https://github.com/bafsunsu/blockchain-automation-framework.git",
        " ! [rejected]          HEAD -> oreo (fetch first)",
        "error: failed to push some refs to 'https://bafsunsu:bafsunsu2020@github.com/bafsunsu/blockchain-automation-framework.git'",
        "hint: Updates were rejected because the remote contains work that you do",
        "hint: not have locally. This is usually caused by another repository pushing",
        "hint: to the same ref. You may want to first integrate the remote changes",
        "hint: (e.g., 'git pull ...') before pushing again.",
        "hint: See the 'Note about fast-forwards' in 'git push --help' for details."
    ],
    "stdout": "---------------SHOW CONTENT OF DIR---------------\n.\n..\n.circleci\n.git\n.github\n.gitignore\n.travis.yml\nCODEOWNERS\nCODE_OF_CONDUCT.md\nCONTRIBUTING.md\nDockerfile\nLICENSE\nMAINTAINERS.md\nREADME.md\nautomation\nbuild\nconsole.out\ndocs\nexamples\nplatforms\nrelease-notes.md\nreset.sh\nrun.sh\n---------------GIT PUSH---------------\n[gorilla b54e22a6] [ci skip] Pushing deployment files for namespace, service accounts and clusterrolebinding\n 5 files changed, 11011 insertions(+), 25948 deletions(-)\n rewrite console.out (74%)\n create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/namespace.yaml\n create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/reviewer_rbac.yaml\n create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vault-reviewer.yaml\n create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vaultAuth.yaml",
    "stdout_lines": [
        "---------------SHOW CONTENT OF DIR---------------",
        ".",
        "..",
        ".circleci",
        ".git",
        ".github",
        ".gitignore",
        ".travis.yml",
        "CODEOWNERS",
        "CODE_OF_CONDUCT.md",
        "CONTRIBUTING.md",
        "Dockerfile",
        "LICENSE",
        "MAINTAINERS.md",
        "README.md",
        "automation",
        "build",
        "console.out",
        "docs",
        "examples",
        "platforms",
        "release-notes.md",
        "reset.sh",
        "run.sh",
        "---------------GIT PUSH---------------",
        "[gorilla b54e22a6] [ci skip] Pushing deployment files for namespace, service accounts and clusterrolebinding",
        " 5 files changed, 11011 insertions(+), 25948 deletions(-)",
        " rewrite console.out (74%)",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/namespace.yaml",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/reviewer_rbac.yaml",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vault-reviewer.yaml",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vaultAuth.yaml"
    ]
}
...ignoring

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/git_push : Output for gitpush] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/git_push/tasks/main.yaml:32
ok: [localhost] => {
    "msg": [
        "---------------SHOW CONTENT OF DIR---------------",
        ".",
        "..",
        ".circleci",
        ".git",
        ".github",
        ".gitignore",
        ".travis.yml",
        "CODEOWNERS",
        "CODE_OF_CONDUCT.md",
        "CONTRIBUTING.md",
        "Dockerfile",
        "LICENSE",
        "MAINTAINERS.md",
        "README.md",
        "automation",
        "build",
        "console.out",
        "docs",
        "examples",
        "platforms",
        "release-notes.md",
        "reset.sh",
        "run.sh",
        "---------------GIT PUSH---------------",
        "[gorilla b54e22a6] [ci skip] Pushing deployment files for namespace, service accounts and clusterrolebinding",
        " 5 files changed, 11011 insertions(+), 25948 deletions(-)",
        " rewrite console.out (74%)",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/namespace.yaml",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/reviewer_rbac.yaml",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vault-reviewer.yaml",
        " create mode 100644 platforms/hyperledger-fabric/releases/dev/supplychain/orderer/vaultAuth.yaml"
    ]
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/git_push : Error for git_push] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/git_push/tasks/main.yaml:37
ok: [localhost] => {
    "msg": [
        "To https://github.com/bafsunsu/blockchain-automation-framework.git",
        " ! [rejected]          HEAD -> oreo (fetch first)",
        "error: failed to push some refs to 'https://bafsunsu:bafsunsu2020@github.com/bafsunsu/blockchain-automation-framework.git'",
        "hint: Updates were rejected because the remote contains work that you do",
        "hint: not have locally. This is usually caused by another repository pushing",
        "hint: to the same ref. You may want to first integrate the remote changes",
        "hint: (e.g., 'git pull ...') before pushing again.",
        "hint: See the 'Note about fast-forwards' in 'git push --help' for details."
    ]
}

TASK [Checking for the supplychain-net-role-tokenreview-binding] ***************
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:90
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Check ClusterRoleBinding supplychain-net-role-tokenreview-binding is created] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:7
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ClusterRoleBinding supplychain-net-role-tokenreview-binding] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:17
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682207.0354095-12615-167820268745271 `" && echo ansible-tmp-1604682207.0354095-12615-167820268745271="` echo /root/.ansible/tmp/ansible-tmp-1604682207.0354095-12615-167820268745271 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpms9vndlz TO /root/.ansible/tmp/ansible-tmp-1604682207.0354095-12615-167820268745271/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682207.0354095-12615-167820268745271/ /root/.ansible/tmp/ansible-tmp-1604682207.0354095-12615-167820268745271/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682207.0354095-12615-167820268745271/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682207.0354095-12615-167820268745271/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ClusterRoleBinding",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "supplychain-net-role-tokenreview-binding",
            "namespace": null,
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [
        {
            "apiVersion": "rbac.authorization.k8s.io/v1",
            "kind": "ClusterRoleBinding",
            "metadata": {
                "annotations": {
                    "fluxcd.io/sync-checksum": "e8e69174d8fae5811887caa7cabb9236d45efc2d",
                    "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"rbac.authorization.k8s.io/v1beta1\",\"kind\":\"ClusterRoleBinding\",\"metadata\":{\"annotations\":{\"fluxcd.io/sync-checksum\":\"e8e69174d8fae5811887caa7cabb9236d45efc2d\"},\"labels\":{\"fluxcd.io/sync-gc-mark\":\"sha256.ELKV0kW2GiS34476-0RLg5-XmvhPpQ7_f7G3we-rJHw\"},\"name\":\"supplychain-net-role-tokenreview-binding\"},\"roleRef\":{\"apiGroup\":\"rbac.authorization.k8s.io\",\"kind\":\"ClusterRole\",\"name\":\"system:auth-delegator\"},\"subjects\":[{\"kind\":\"ServiceAccount\",\"name\":\"vault-reviewer\",\"namespace\":\"supplychain-net\"}]}\n"
                },
                "creationTimestamp": "2020-10-28T06:59:47Z",
                "labels": {
                    "fluxcd.io/sync-gc-mark": "sha256.ELKV0kW2GiS34476-0RLg5-XmvhPpQ7_f7G3we-rJHw"
                },
                "name": "supplychain-net-role-tokenreview-binding",
                "resourceVersion": "1990397",
                "selfLink": "/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/supplychain-net-role-tokenreview-binding",
                "uid": "b89aea82-0494-441d-9a22-9cf0de129356"
            },
            "roleRef": {
                "apiGroup": "rbac.authorization.k8s.io",
                "kind": "ClusterRole",
                "name": "system:auth-delegator"
            },
            "subjects": [
                {
                    "kind": "ServiceAccount",
                    "name": "vault-reviewer",
                    "namespace": "supplychain-net"
                }
            ]
        }
    ]
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ClusterRoleBinding supplychain-net-role-tokenreview-binding] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:32
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ClusterRoleBinding supplychain-net-role-tokenreview-binding] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:45
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [Including the check for ServiceAccount vault-reviewer in supplychain-net] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/roles/create/namespace_vaultauth/tasks/main.yaml:103
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Check ServiceAccount vault-reviewer is created] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:7
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ServiceAccount vault-reviewer] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:17
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ServiceAccount vault-reviewer] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:32
skipping: [localhost] => {
    "changed": false,
    "skip_reason": "Conditional result was False"
}

TASK [/Users/s0s0dit/project/blockchain-automation-framework/platforms/hyperledger-fabric/configuration/../../shared/configuration/roles/check/k8_component : Wait for ServiceAccount vault-reviewer] ***
task path: /Users/s0s0dit/project/blockchain-automation-framework/platforms/shared/configuration/roles/check/k8_component/tasks/main.yaml:45
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682207.8963447-12655-133855815799844 `" && echo ansible-tmp-1604682207.8963447-12655-133855815799844="` echo /root/.ansible/tmp/ansible-tmp-1604682207.8963447-12655-133855815799844 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpphmvs4ha TO /root/.ansible/tmp/ansible-tmp-1604682207.8963447-12655-133855815799844/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682207.8963447-12655-133855815799844/ /root/.ansible/tmp/ansible-tmp-1604682207.8963447-12655-133855815799844/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682207.8963447-12655-133855815799844/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682207.8963447-12655-133855815799844/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (20 retries left).Result was: {
    "attempts": 1,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682243.5146124-12655-98998163810907 `" && echo ansible-tmp-1604682243.5146124-12655-98998163810907="` echo /root/.ansible/tmp/ansible-tmp-1604682243.5146124-12655-98998163810907 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmp01tspuz0 TO /root/.ansible/tmp/ansible-tmp-1604682243.5146124-12655-98998163810907/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682243.5146124-12655-98998163810907/ /root/.ansible/tmp/ansible-tmp-1604682243.5146124-12655-98998163810907/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682243.5146124-12655-98998163810907/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682243.5146124-12655-98998163810907/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (19 retries left).Result was: {
    "attempts": 2,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682279.1258032-12655-34266412744434 `" && echo ansible-tmp-1604682279.1258032-12655-34266412744434="` echo /root/.ansible/tmp/ansible-tmp-1604682279.1258032-12655-34266412744434 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpog2vlqi5 TO /root/.ansible/tmp/ansible-tmp-1604682279.1258032-12655-34266412744434/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682279.1258032-12655-34266412744434/ /root/.ansible/tmp/ansible-tmp-1604682279.1258032-12655-34266412744434/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682279.1258032-12655-34266412744434/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682279.1258032-12655-34266412744434/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (18 retries left).Result was: {
    "attempts": 3,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682314.772617-12655-61867016973470 `" && echo ansible-tmp-1604682314.772617-12655-61867016973470="` echo /root/.ansible/tmp/ansible-tmp-1604682314.772617-12655-61867016973470 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpnl0qmvaq TO /root/.ansible/tmp/ansible-tmp-1604682314.772617-12655-61867016973470/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682314.772617-12655-61867016973470/ /root/.ansible/tmp/ansible-tmp-1604682314.772617-12655-61867016973470/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682314.772617-12655-61867016973470/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682314.772617-12655-61867016973470/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (17 retries left).Result was: {
    "attempts": 4,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682350.4006553-12655-12683631044031 `" && echo ansible-tmp-1604682350.4006553-12655-12683631044031="` echo /root/.ansible/tmp/ansible-tmp-1604682350.4006553-12655-12683631044031 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpl7bymx80 TO /root/.ansible/tmp/ansible-tmp-1604682350.4006553-12655-12683631044031/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682350.4006553-12655-12683631044031/ /root/.ansible/tmp/ansible-tmp-1604682350.4006553-12655-12683631044031/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682350.4006553-12655-12683631044031/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682350.4006553-12655-12683631044031/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (16 retries left).Result was: {
    "attempts": 5,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682386.0264263-12655-102303801225319 `" && echo ansible-tmp-1604682386.0264263-12655-102303801225319="` echo /root/.ansible/tmp/ansible-tmp-1604682386.0264263-12655-102303801225319 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpim9mpf70 TO /root/.ansible/tmp/ansible-tmp-1604682386.0264263-12655-102303801225319/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682386.0264263-12655-102303801225319/ /root/.ansible/tmp/ansible-tmp-1604682386.0264263-12655-102303801225319/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682386.0264263-12655-102303801225319/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682386.0264263-12655-102303801225319/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (15 retries left).Result was: {
    "attempts": 6,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682421.6495843-12655-59128479371738 `" && echo ansible-tmp-1604682421.6495843-12655-59128479371738="` echo /root/.ansible/tmp/ansible-tmp-1604682421.6495843-12655-59128479371738 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpth2yrf9o TO /root/.ansible/tmp/ansible-tmp-1604682421.6495843-12655-59128479371738/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682421.6495843-12655-59128479371738/ /root/.ansible/tmp/ansible-tmp-1604682421.6495843-12655-59128479371738/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682421.6495843-12655-59128479371738/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682421.6495843-12655-59128479371738/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (14 retries left).Result was: {
    "attempts": 7,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682457.3006961-12655-114536940336485 `" && echo ansible-tmp-1604682457.3006961-12655-114536940336485="` echo /root/.ansible/tmp/ansible-tmp-1604682457.3006961-12655-114536940336485 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpmdo1nwix TO /root/.ansible/tmp/ansible-tmp-1604682457.3006961-12655-114536940336485/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682457.3006961-12655-114536940336485/ /root/.ansible/tmp/ansible-tmp-1604682457.3006961-12655-114536940336485/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682457.3006961-12655-114536940336485/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682457.3006961-12655-114536940336485/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (13 retries left).Result was: {
    "attempts": 8,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682492.9356382-12655-134918286443306 `" && echo ansible-tmp-1604682492.9356382-12655-134918286443306="` echo /root/.ansible/tmp/ansible-tmp-1604682492.9356382-12655-134918286443306 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpgrolqgnd TO /root/.ansible/tmp/ansible-tmp-1604682492.9356382-12655-134918286443306/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682492.9356382-12655-134918286443306/ /root/.ansible/tmp/ansible-tmp-1604682492.9356382-12655-134918286443306/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682492.9356382-12655-134918286443306/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682492.9356382-12655-134918286443306/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (12 retries left).Result was: {
    "attempts": 9,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682528.5903926-12655-270192569067384 `" && echo ansible-tmp-1604682528.5903926-12655-270192569067384="` echo /root/.ansible/tmp/ansible-tmp-1604682528.5903926-12655-270192569067384 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpom6a23xv TO /root/.ansible/tmp/ansible-tmp-1604682528.5903926-12655-270192569067384/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682528.5903926-12655-270192569067384/ /root/.ansible/tmp/ansible-tmp-1604682528.5903926-12655-270192569067384/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682528.5903926-12655-270192569067384/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682528.5903926-12655-270192569067384/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (11 retries left).Result was: {
    "attempts": 10,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682564.2079644-12655-254776110146934 `" && echo ansible-tmp-1604682564.2079644-12655-254776110146934="` echo /root/.ansible/tmp/ansible-tmp-1604682564.2079644-12655-254776110146934 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpcxmki7by TO /root/.ansible/tmp/ansible-tmp-1604682564.2079644-12655-254776110146934/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682564.2079644-12655-254776110146934/ /root/.ansible/tmp/ansible-tmp-1604682564.2079644-12655-254776110146934/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682564.2079644-12655-254776110146934/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682564.2079644-12655-254776110146934/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (10 retries left).Result was: {
    "attempts": 11,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p "` echo /root/.ansible/tmp `"&& mkdir "` echo /root/.ansible/tmp/ansible-tmp-1604682599.8624413-12655-280614711618427 `" && echo ansible-tmp-1604682599.8624413-12655-280614711618427="` echo /root/.ansible/tmp/ansible-tmp-1604682599.8624413-12655-280614711618427 `" ) && sleep 0'
redirecting (type: modules) ansible.builtin.k8s_info to community.kubernetes.k8s_info
Using module file /usr/local/lib/python3.6/dist-packages/ansible_collections/community/kubernetes/plugins/modules/k8s_info.py
<localhost> PUT /root/.ansible/tmp/ansible-local-1015019fikmid/tmpiyln5s27 TO /root/.ansible/tmp/ansible-tmp-1604682599.8624413-12655-280614711618427/AnsiballZ_k8s_info.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1604682599.8624413-12655-280614711618427/ /root/.ansible/tmp/ansible-tmp-1604682599.8624413-12655-280614711618427/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1604682599.8624413-12655-280614711618427/AnsiballZ_k8s_info.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1604682599.8624413-12655-280614711618427/ > /dev/null 2>&1 && sleep 0'
FAILED - RETRYING: Wait for ServiceAccount vault-reviewer (9 retries left).Result was: {
    "attempts": 12,
    "changed": false,
    "invocation": {
        "module_args": {
            "api_key": null,
            "api_version": "v1",
            "ca_cert": null,
            "client_cert": null,
            "client_key": null,
            "context": "fabric-aks-dev1",
            "field_selectors": [],
            "host": null,
            "kind": "ServiceAccount",
            "kubeconfig": "/Users/s0s0dit/project/blockchain-automation-framework/build/kubeconfig.yaml",
            "label_selectors": [],
            "name": "vault-reviewer",
            "namespace": "supplychain-net",
            "password": null,
            "persist_config": null,
            "proxy": null,
            "username": null,
            "validate_certs": null,
            "wait": false,
            "wait_condition": null,
            "wait_sleep": 5,
            "wait_timeout": 120
        }
    },
    "resources": [],
    "retries": 21
}
